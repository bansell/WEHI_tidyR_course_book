[
["index.html", "Introduction to R - tidyverse Preface Before we begin", " Introduction to R - tidyverse Brendan R. E. Ansell @ansellbr3 Preface This document contains the material covered in the Introduction to R (tidyverse) course taught at the Walter and Eliza Hall Institute of Medical Research. The course is taught to biomedical scientists, but the material and the teaching examples are very broad. Skills taught in this workshop can be applied to many disciplines in academia and industry. Chapters 1 through 5 make use of popular (non-biological) teaching data sets available through R. Chapters 6 onwards introduce some types biological data. Our aim with this material is to improve the transparency, reproducibility and efficiency of scientific research by enabling scientists to conduct data analysis and visualization in R. This material is designed to be taught in a workshop setting over consecutive weeks, however we have now made it available online for those who cannot attend the workshop, or want to refresh or develop their skills. The majority of this material is inspired by / modified from from the excellent book R for Data Science by Hadley Wickham &amp; Garrett Grolemund. I thank WEHI for suppoprting this initiative, and the Melbourne University Research Platforms Unit, Prof Melanie Bahlo, A/Prof Marnie Blewitt, A/Prof Anne Voss, Dr Luke Gandolfo, Dr Saskia Freytag, Stuart Lee and Jacob Munro who helped with discussion and development of this material. Before we begin In order to use R interactively and easily, participants will need to install R and then download the RStudio software. More detailed instructions are available here. "],
["week-1-part-1.html", "Week 1. Part 1", " Week 1. Part 1 "],
["welcome-to-r.html", "1 Welcome to R! 1.1 A look around RStudio 1.2 Console Pane 1.3 Environment/History Pane 1.4 Plotting Pane 1.5 Open a new R script 1.6 Comments 1.7 Executing commands 1.8 Simple maths in R 1.9 Help!! 1.10 Variables 1.11 Vectors 1.12 Packages 1.13 The pipe %&gt;% 1.14 Data frames", " 1 Welcome to R! R is a computer programing language that is increasingly used for ‘data science’, that is, the manipulation, summarization, and visualization of large datasets. Data comes in many shapes and sizes, however this course is designed to teach you the skills to work with tabular data (rows and columns) such as is often handled in Microsoft Excel. An example of ‘tabular data’ is shown below. This data concerns different models of car, which we will return to later. ## # A tibble: 6 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 auto(l5) f 18 29 p compact ## 2 audi a4 1.8 1999 4 manual(m5) f 21 29 p compact ## 3 audi a4 2 2008 4 manual(m6) f 20 31 p compact ## 4 audi a4 2 2008 4 auto(av) f 21 30 p compact ## 5 audi a4 2.8 1999 6 auto(l5) f 16 26 p compact ## 6 audi a4 2.8 1999 6 manual(m5) f 18 26 p compact 1.1 A look around RStudio To get the best out of R, we recommend using the RStudio software which you should now have installed on your computer. Open RStudio. You will see 3 windows (aka ‘panes’). Each window has a different function. 1.2 Console Pane On the left hand side you have the ‘console’. You can enter commands (code that R can ‘understand’) in this window, and you will get a response to your commands (‘output’) here too. The console is useful for trying out code, but will not save any of your code, so we don’t recommend that you use it exclusively. 1.3 Environment/History Pane At the top right is the environment pane. Data that you create, or that you import from other places, will be listed here. This data is available for you to access at any time while your RStudio session is open. It is therefore said to be ‘in the working environment.’ The History pane contains a list of commands you have previously entered. 1.4 Plotting Pane At the bottom right is the plotting (‘Plots’) pane. Here you can immediately see the results of the R code you use to make graphs/charts. There are other tabs here as well which we will introduce later. 1.5 Open a new R script Because we want to save our code to return to and build on, or use to refresh our memory later, we want to save it in a text file. I recommend that you create a folder on your Desktop named WEHI_tidyR_course Go to File &gt; New File &gt; R Script. A new pane will appear at the top left. Save this empty text file as ‘Week_1_tidyverse.R’ within the new Desktop folder. From now on we will type commands in to the text file, and see the results of our commands either in the console pane, or the plotting pane. 1.6 Comments When working in R it is very handy to make notes to yourself about what the code is doing. In R, any text that appears after the hash symbol ‘#’ is called a ‘comment.’ R can’t see this text, and won’t try to run it as commands. Comments are useful for reminding your future self what you were aiming to do with a particular line of code, and what was or wasnt working. We will use comments extensively in this course. Try writing your first comment in your R text file (top left panel) #This is a comment. ignored by R but useful for me! 1.7 Executing commands Executing commands, also called ‘running code’ is the process of submitting a command to your computer, which does some computation and returns an answer. There are a few ways to do this in RStudio. We can: select the line(s) of code using the mouse, and then click ‘Run’ at the top right corner of the R text file. click anyware on the line of code and click ’Run click anyware on the line of code and type Cmd + Return (mac), or Ctrl + Return (pc) We suggest the third option, which is fastest. When you type in, and then run the commands shown in the grey boxes below, you should see the result in the Console pane at bottom left. 1.8 Simple maths in R We can use R as a caculator to do simple maths 1 + 100 ## [1] 101 More complex calculator functions are ‘built in’ to R, which is the reason it is popular among mathematicians and statisticians. To use these functions, we first type the function, then enter the number of interest between round brackets. For example, to take the log or square root of 100: log(100) ## [1] 4.60517 sqrt(100) ## [1] 10 Notice that the ‘square root’ function is abbreviated to ‘sqrt()’. This is to make writing R code faster, however the draw back is that some functions are hard to remember, or to interpret. 1.9 Help!! To find out more about what a function in R does, add a ‘?’ before the function name, and leave the round brackets empty. Then run the code: #get help on R functions by using &quot;?&quot; ?sqrt() You will see the ‘Help’ pane at bottom right springs to life. These help documents give detailed explanations about the function, including how it is used, what input it requires, and, most importantly at the bottom Examples! You can copy and paste these examples in to your R text file, select and then run them. You should see the output indended by the function authors. NB dont worry for now that the sqrt() example is quite complicated. NBB all R ‘functions’ are little programs that were written by other people. There are 1000s of functions available for R, which makes your life simpler because you dont have to program them all from scratch. 1.10 Variables A ‘variable’ is a bit of tricky concept, but very important for understanding R. Essentially, a variable is a symbol that we use in place of another value. Usually the other value is a larger/longer form of data. We can tell R to store a lot of data, for example, in a variable named ‘x’. When we execute the command ‘x’, R returns all of the data that we stored there. For now however we’ll just use a tiny data set: the number 5. To store some data in a variable, we need to use a special symbol ‘&lt;-’ which in our case tells R to ‘assign the value 5 to the variable x’. This is called the ‘assignment operator’. Let’s see how this works # create a variable called &#39;x&#39;, that will contain the number 5. x &lt;- 5 R won’t return anything in the Console, but note that you now have a new entry in the ‘Environment pane’. The variable name is at the left (‘x’) and the value that is stored in that variable, is displayed on the right (5). We can now use ‘x’ in place of 5: x + 20 ## [1] 25 x * 50 ## [1] 250 Can you work out what the * symbol is used for in R? 1.10.1 A note on variables Variables are sometimes refered to as ‘objects’. In R there are different conventions about how to name variables, but most importantly they: cannot begin with a number should begin with an alphabetical letter Variables are also case sensitive: X ## Error in eval(expr, envir, enclos): object &#39;X&#39; not found As we can see, ‘x’ is not the same as ‘X’. Variables can take any name, but its best to use something that makes sense to you, and will likely make sense to others who may read your code. R_at_WEHI &lt;- 100 For example, this code will work, but is not very intitive to humans: log(R_at_WEHI) ## [1] 4.60517 You may be wondering “why bother with assigning variables, when its less text to type ‘100’?” This is because we can store huge amounts of data in a single variable. For example, we can store a list of 50 numbers in a variable, and do maths on them all at once. First we create a list of 50 numbers, using a quick trick ‘1:50’ which means ‘every whole number from 1 to 50’. Let’s make a variable called ‘long_x’ that stores 1:50. long_x &lt;- 1:50 Now we can multiply every number by 10 long_x * 10 ## [1] 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 ## [20] 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 ## [39] 390 400 410 420 430 440 450 460 470 480 490 500 Here we are accessing the power of R, which is designed to do lots of computations based on a single line of code. 1.11 Vectors In making the long_x variable, we are making a ‘vector’. In this case, it is a sequence of numbers. A technical definition for a vector is ‘a sequence of values of the same data type.’ To better understand this we need to think about ‘types of data’. The three data types we need to understand for now are: numbers (‘numeric’) words (‘characters’), and TRUE/FALSE (‘logical’) For example, whole numbers can be added, subtracted and so forth. This ‘numeric’ data type is qualitatively different to a word. Words hold meaning, but can’t be sensibly used in a mathematical equation. TRUE and FALSE have specific, logical meaning for computers. Most of what we do in R is turned into TRUE/FALSE problems which are evaluated ‘under the hood.’ 1.11.1 Creating numeric vectors Above we used a shortcut to create a vector of 50 numbers ( 1:50 ). Ordinarily, we need to enclose values in brackets, separated by commas. The values also need to be ‘concatenated’ using a function called c(). #This new variable will contain a vector of numbers, which in this case is a concatenation of 5, 12 and 22. numeric_vector &lt;- c(5,12,22) 1.11.2 Character vectors Character values are written in quotation marks, and character vectors are also constructed using c(). char_vector &lt;- c(&#39;dog&#39;,&#39;cat&#39;,&#39;pidgeon&#39;) What happens when you add a character vector to a numeric vector? numeric_vector + char_vector ## Error in numeric_vector + char_vector: non-numeric argument to binary operator Nothing sensible. R will return an error. 1.11.3 Logical vectors Finally we can create a vector of logical values. Note that for TRUE and FALSE (always in upper case), quotation marks aren’t used. logi_vector &lt;- c(TRUE,TRUE,FALSE) TRUE and FALSE appear in coloured text, indicating that they have a special meaning in the R language. What happens when we add logical data to numeric data? numeric_vector + logi_vector ## [1] 6 13 22 Can you work out how R has calculated this answer? Essentially, the logical data has been automatically converted to numeric data. The TRUE values become 1, and FALSE become 0. Another thing to note is that the values in the vector have been added in their respective orders: position1: 5 + 1 = 6 position2: 12 + 1 = 13 position3: 22 + 0 = 22 This is called ‘type coercion,’ which we’ll return to later. 1.12 Packages As mentioned above, many developers have built 1000s of functions and shared them with the R user community to help make everyone’s work easier and more efficient. These functions (short programs) are generally packaged up together in (wait for it) ‘Packages’. For example, the ‘tidyverse’ package is a compilation of many different functions, all of which help with data transformation and visualization. Packages also contain data, which is often included to assist new users with learning the available functions. To access this wealth of pre-existing functions, we install packages from the Comprehensive R Archive Network (CRAN) …and if you want the all scripts from The Office (American series) in tabular form, there’s a package for that. 1.12.1 Installing packages To install a package from CRAN, use the ‘install.packages()’ function: #install packages using the package names in quotes install.packages(&#39;tidyverse&#39;) This will spit out a lot of text into the console as the package is being installed. Once complete you should have a message The downloaded binary packages are in... followed by a long directory name. To access the package functions in our RStudio session, we load the package like so: #load packages using library(package_name), and drop the quotes library(tidyverse) Note that to install a package requires the package name in quotations. Once installed, to load it we drop the quotation marks. 1.13 The pipe %&gt;% When using functions provided in the tidyverse package, we suggest to write your commands from left to right. This makes reading, and finding bugs in the code, a lot easier. To write code in this way requires a specific symbol, called the pipe which allows the code to be processed in a left-right manner. The pipe symbol looks like this: %&gt;% It is a pain to type manually, so we suggest you use a shortcut: CMD + SHIFT + M (mac) or CTRL + SHIFT + M (pc). It takes a little practice, but quickly enables a great increase in your coding speed. The pipe-based method of coding can help new users to become ‘fluent in R’. Let’s try using the pipe with some data that is packaged up with the tidyverse, called the ‘miles per gallon (mpg)’ data set. This is the data set you saw above, containing information on the mechanical features of different models of car. First we will assign the currently hidden mpg data set to an explicit variable ‘mpg_df’ in our environment. mpg_df &lt;- mpg Now we access the contents of mpg_df, and ‘send it into a function’ called head(). The head() function returns the first six rows of a data set (or first six values in a vector) to the console. #see the first six rows of the mpg data set #call mpg_df first, then &#39;send it into&#39; the head function, using the pipe %&gt;% mpg_df %&gt;% head() ## # A tibble: 6 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 auto(l5) f 18 29 p compact ## 2 audi a4 1.8 1999 4 manual(m5) f 21 29 p compact ## 3 audi a4 2 2008 4 manual(m6) f 20 31 p compact ## 4 audi a4 2 2008 4 auto(av) f 21 30 p compact ## 5 audi a4 2.8 1999 6 auto(l5) f 16 26 p compact ## 6 audi a4 2.8 1999 6 manual(m5) f 18 26 p compact Note that unlike the log() and c() functions we used earlier, here the brackets after head() are empty. This still works because the pipe %&gt;% is sending the mpg_df dataset into the head() function. It has the same outcome as: head(mpg_df) 1.14 Data frames The final concept we need to understand before starting to make plots in R, are ‘data frames’. The vectors we created above are a simple type of ‘data structure’. Whereas vectors can be thought of as a 1-dimensional data structure (a sequence of values), data frames are a 2D data structure. Data frames have both rows and columns. Each column is infact a vector, containing a single type of data. Data frames generally have column names, which we can treat in the same way as a variable. For example, let’s combine our three vectors into a data frame, using the data_frame() function: #combine vectors of the same length into a data frame new_df &lt;- data_frame(numeric_vector, char_vector, logi_vector) new_df ## # A tibble: 3 x 3 ## numeric_vector char_vector logi_vector ## &lt;dbl&gt; &lt;chr&gt; &lt;lgl&gt; ## 1 5 dog TRUE ## 2 12 cat TRUE ## 3 22 pidgeon FALSE Importantly, each column in a data frame must have the same number of values (i.e., the same number of rows). This will be a familiar data structure for those who use Microsoft Excel, and is very popular in data science. To make plots in R for this tutorial, we must provide our data in data frame form. "],
["week-1-part-2.html", "Week 1. Part 2", " Week 1. Part 2 "],
["making-beautiful-plots.html", "2 Making beautiful plots Introductory information 2.1 ggplot2. A grammar of graphics 2.2 Building a ggplot 2.3 Plot background 2.4 Aesthetics aes() 2.5 Geometric representations geom() 2.6 Adding colour 2.7 Adding layers 2.8 Facets 2.9 Coordinate space 2.10 Axis labels 2.11 Themes", " 2 Making beautiful plots Introductory information This tutorial leads on from the Week 1 Part 1 tutorial. If you have opened a new R session in RStudio, first create a new .R text file and save it as Week_2_tidyverse.R in your Desktop WEHI_tidyR_course folder. Now load the tidyverse package: library(tidyverse) 2.1 ggplot2. A grammar of graphics The ggplot2 package is widely used and valued for its simple, consistent approach to making plots. The ‘grammar’ of graphics relates to different components of a plot that function like different parts of linguistic grammar. For example, all plots require axes, so the x and y axes form one part of the ‘language’ of a plot. Similarly, all plots have data represented between the axes, often as points, lines or bars. The visual way that the data is represented forms another component of the grammar of graphics. Furthermore, the colour, shape or size of points and lines can be used to encode additional information in the plot. This information is usually clarified in a key, or legend, which can also be considered part of this ‘grammar’. The most common components of a ggplot are aesthetics geometric representations facets coordinate space coordinate labels plot theme We will cover each below. The philosophy of ggplot is much better explained by the package author, Hadley Wickham here. For now, we just need to be aware that ggplots are constructed by specifying the different components that we want to display, based on underlying information in a data frame. 2.2 Building a ggplot We are going to use the mpg_df data set created previously. If this is not visible in your environement pane, you can recreate it now: mpg_df &lt;- mpg Let’s check the first 6 rows of information contained in the mpg_df data frame, using the head() function: mpg_df %&gt;% head() ## # A tibble: 6 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 auto(l5) f 18 29 p compact ## 2 audi a4 1.8 1999 4 manual(m5) f 21 29 p compact ## 3 audi a4 2 2008 4 manual(m6) f 20 31 p compact ## 4 audi a4 2 2008 4 auto(av) f 21 30 p compact ## 5 audi a4 2.8 1999 6 auto(l5) f 16 26 p compact ## 6 audi a4 2.8 1999 6 manual(m5) f 18 26 p compact Here, we aim to produce a scatter plot of the engine volume (‘displacement’) vs fuel efficiency/mileage in the city (‘cty’), for each class of vehicle. The points on the plot will be coloured based on the vehicle class (right-most column). 2.3 Plot background To start building the plot, we first specify the data frame that contains the relevant data. Here we are ‘sending the mpg_df data set into the ggplot function’: #render plot background mpg_df %&gt;% ggplot() Running this command will produce an empty grey panel. This is because we need to specify how different columns of the data frame should be represented in the plot. 2.4 Aesthetics aes() We can call in different columns of data from mpg_df based on their column names. Column names are given as ‘aesthetic’ elements to the ggplot function, and are wrapped in the aes() function. Because we want a scatter plot, each point will have an x and a y coordinate. We want the x axis to represent engine volume ( x = displ ), and the y axis to represent the city mileage ( y = cty ). We give these specifications separated by a comma. Note that quotes are not required when giving variables within aes(). Those interested in why quotes aren’t required can read here about non-standard evaluation. mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) So far we have the gridlines for our x and y axis. ggplot knows the variables required for the plot, and thus the scale, but has no information about how to display the data points. 2.5 Geometric representations geom() Given we want a scatter plot, we need to specify that the geometric representation of the data will be in point form, using geom_point(). Here we are adding a layer (hence the + sign) of points to the plot. We can think of this as similar to e.g. Adobe Photoshop which uses layers of images that can be reordred and modified individually. For ggplot, each layer will be added over the plot according to its position in the code. mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) + geom_point() Now we have the scatter plot! Each row in the mpg_df data set now has an x coordinate, a y coordinate, and a designated geometric representation (point). From this we can see that vehicles with smaller engines (lower displacement) tend to have higher mileage in the city. 2.5.1 A note about %&gt;% and + ggplot2, an early component of the tidyverse package, was written before the pipe was introduced. The + sign in ggplot2 functions in a similar way to the pipe in other functions in the tidyverse: by allowing code to be written from left to right. 2.6 Adding colour The current plot could be more informative, to include information about the class of each vehicle. In order to achieve this we need to use aes() again, and specify which column in mpg_df we want to be represented as the colour of the points. Here, the aes() function containing the relevant column name, is given within the geom_point() function. mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) + geom_point(aes(colour = class)) So now we can see that the subcompact class (purple points) tends to have small engines and good city mileage, whereas the SUVs (pink points) have very low city mileage and larger engines. As commands get longer, we suggest to add carriage returns (new lines), which are best inserted after the %&gt;% or + symbols. In most cases, R is blind to white space and new lines, so this is simply to make our code more readable. 2.7 Adding layers We can see the relationship between engine size and mileage. But what if we want to model this relationship with a trend line? We can add another ‘layer’ to this plot, using a different geometric representation of the data. In this case a trend line, which is in fact a summary of the data rather than a representation of each point. The geom_smooth() function draws a trend line through the data. The default behaviour is to draw a local regression line (curve) through the points, however these can be hard to interpret. We want to add a straight line based on a linear model (‘lm’) of the relationship between x and y. #add another layer of data representation. mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) + geom_point(aes(colour = class)) + geom_smooth(method=&#39;lm&#39;) Note that the trend line is blocking out cetain points, because it is the ‘top layer’ of the plot. The geom layers that appear early in the command are drawn first, and can be obscured by the geom layers that come after them. What happens if you switch the order of the geom_point() and geom_smooth() functions above? What do you notice about the trend line? 2.8 Facets In some cases we want to break up a single plot into sub-plots, called ‘faceting’. Facets are commonly used when there is too much data to display clearly in a single plot. We will revisit faceting below, however for now, let’s try to facet the mpg_df plot according to vehicle engine size (displ). To do this we use the tilde symbol ‘~’ to indicate the column name that will form each facet. mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) + geom_point(aes(colour = class)) + geom_smooth(method=&#39;lm&#39;) + facet_wrap( ~ class) Note that the aesthetics and geoms including the regression line that were specified for the original plot, are applied to each of the facets. 2.9 Coordinate space ggplot will automatically pick the scale for each axis, and the type of coordinate space. Most plots are in cartesian (linear X vs linear Y) coordinate space. For the mpg_df plot, let’s say we want the x and y origin to be set at 0. To do this we can add in xlim() and ylim() functions, which define the limits of the axes: mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) + geom_point(aes(colour = class)) + geom_smooth(method=&#39;lm&#39;) + xlim(0,7) + ylim(0,40) Further, we can control the coordinate space using coord() functions. Say we want to flip the x and y axes, we add coord_flip(): mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) + geom_point(aes(colour = class)) + geom_smooth(method=&#39;lm&#39;) + xlim(0,7) + ylim(0,40) + coord_flip() 2.10 Axis labels By default, the axis labels will be the column names we gave as aesthetics aes(). We can change the axis labels using the xlab() and ylab() functions. Given that column names are often short and can be cryptic, this functionality is particularly important for effectively communicating results. mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) + geom_point(aes(colour = class)) + geom_smooth(method=&#39;lm&#39;) + xlim(0,7) + ylim(0,40) + xlab(&#39;Engine size (L)&#39;) + ylab(&#39;Miles per gallon in the city&#39;) We can also add a title and subtitle with ggtitle() mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) + geom_point(aes(colour = class)) + geom_smooth(method=&#39;lm&#39;) + xlim(0,7) + ylim(0,40) + xlab(&#39;Engine size (L)&#39;) + ylab(&#39;Miles per gallon in the city&#39;) + ggtitle(label = &#39;Engine size affects mileage&#39;, subtitle = &#39;Some extra info here too&#39;) 2.11 Themes Finally, the overall appearance of the plot can be modified using theme() functions. The default theme has a grey background which maximizes contrast with other contrasts. You may prefer a ‘classic’ theme, a black &amp; white theme or even theme_void(). Try them out. There ggthemes package has plenty of other options. mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) + geom_point(aes(colour = class)) + geom_smooth(method=&#39;lm&#39;) + xlim(0,7) + ylim(0,40) + xlab(&#39;Engine size (L)&#39;) + ylab(&#39;Miles per gallon in the city&#39;) + ggtitle(label = &#39;Engine size affects mileage&#39;, subtitle = &#39;Some extra info here too&#39;) + theme_bw() "],
["week-1-part-3.html", "Week 1. Part 3", " Week 1. Part 3 "],
["making-more-beautiful-plots.html", "3 Making more beautiful plots Introductory information 3.1 Big(ger) Data: 54,000 diamonds 3.2 Summary plots 3.3 Histograms 3.4 Density plots 3.5 Box plots 3.6 Saving plots 3.7 Challenge 3.8 Solution", " 3 Making more beautiful plots Introductory information This tutorial leads on from the Week 1 Part 2 tutorial. We now explore approaches for plotting large datasets. If you have opened a new R session in RStudio, you can open your Week_2_tidyverse.R file, and reload the tidyverse package: library(tidyverse) We now create a larger data set in the global environment, called ‘diamond_df’. This is based on the diamonds data set that is provided as part of the tidyverse diamond_df &lt;- diamonds N.B. If your computer is taking a long time to plot this data set in the steps below, then take a smaller sample of 2500 rows. I don’t recommend overwriting objects in general, but doing this will make the following section more accessible. Also note that your plots will look slightly different to those below. set.seed(1234) ; diamond_df &lt;- diamond_df %&gt;% sample_n(2500) 3.1 Big(ger) Data: 54,000 diamonds When ploting a small dataset such as mpg_df, its possible to visualize every individual data point. This is impractical for large datasets, where we run into the problem of ‘overplotting’. We therefore need approaches for managing over-plotting. These include but aren’t limited to: reducing density summing, and summarizing the data. To explore these options we will now move on to a much larger data set containing multiple measurements for 54,000 diamonds. The measurements appear in separate columns, and each diamond appears in a different row. As for mpg, this data is available through the tidyverse package. https://www.diamonds.pro/wp-content/uploads/2019/02/diamond-depth-and-table.png First let’s view the first 6 rows of the diamond_df dataset img from: https://www.diamond.pro/education/diamond-depth-and-table/ diamond_df %&gt;% head() ## # A tibble: 6 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.290 Premium I VS2 62.4 58 334 4.2 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 ## 6 0.24 Very Good J VVS2 62.8 57 336 3.94 3.96 2.48 You can read the definitions of each measurement (column name) in the help manual for the original (‘hidden’) dataset by typing ?diamonds We can get the number of rows and columns (the ‘dimensions’) of this dataset using the dim() function: diamond_df %&gt;% dim() ## [1] 53940 10 First let’s make a scatter plot comparing the price of diamonds (y) by cut (x): diamond_df %&gt;% ggplot(aes(x=cut, y=price)) + geom_point() Because there are 54K points here the plot is essentially useless. What can we do to get more information about the relationship? ## geom_jitter() This adds some random scatter to the points which can reduce over-plotting. Note that to avoid mis-representing the price, we should set the jitter height to 0. diamond_df %&gt;% ggplot(aes(x=cut, y=price)) + geom_jitter(height=0) This is somewhat improved but far from good. Next we will make the points more transparent using the ‘alpha’ setting within geom_jitter. diamond_df %&gt;% ggplot(aes(x=cut, y=price)) + geom_jitter(height=0, alpha=0.25) The density below $5000 can be further reduced by limiting the size of the points, again within the geom_jitter() command. diamond_df %&gt;% ggplot(aes(x=cut, y=price)) + geom_jitter(height=0, alpha=0.25, size=0.5) Now we can see much more detail in the data, including an interesting lack of data around the $3000 mark in the Very Good and Premium cut data. This could be due to other features such as size, carat or clarity. We will return to these possibilities later. 3.2 Summary plots Its clear that the cut group sizes are uneven. To get a quick summary of the numbers of diamonds per group, we can make a bar plot. Here we specify only the group we wish to count (i.e. the number of diamonds of each cut) as the x aesthetic. Importantly, the group size is summed and displayed automatically when we specify geom_bar(). diamond_df %&gt;% ggplot(aes(x=cut)) + geom_bar() Alternatively, if we want to find the total value of the diamonds in each group, we use a related geom that sums the values in a column (rather than the number of rows), called geom_col. Here we give price, that is, the column whose values we want to sum, as the y axis aesthetic. diamond_df %&gt;% ggplot(aes(x=cut, y=price)) + geom_col() From this we can see the total value of the Ideal cut diamonds alone is &gt; $70 million! 3.2.1 Free examples! If you are unsure how to use a function in R, the help page will usually have Example code at the bottom. ?geom_bar() You can copy and paste these examples and they should work first time. The code below is taken directly from the first example for geom_bar(): # geom_bar is designed to make it easy to create bar charts that show # counts (or sums of weights) g &lt;- ggplot(mpg, aes(class)) # Number of cars in each class: g + geom_bar() To add more information, we could count the clarity groups per cut group. Adding clarity into the aesthetic as the bar fill color will automatically calculate and display these sub-groups. diamond_df %&gt;% ggplot(aes(x = cut, fill=clarity)) + geom_bar() We can rearrange the clarity groups into adjascent (dodged) bars by specifying a different position within geom_bar(): diamond_df %&gt;% ggplot(aes(x = cut, fill=clarity)) + geom_bar(position=&#39;dodge&#39;) 3.3 Histograms When dealing with large datasets especially for statistical testing, histograms are essential for understanding the distribution of values. Like geom_bar() above, geom_histogram() requires only a single x aesthetic, specifying the values to be displayed. Further, the values will be automatically sorted into 30 bins and the number of rows of data per bin summed up. Here we plot the distribution of prices across the entire dataset. diamond_df %&gt;% ggplot(aes(x = price)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. To increase the resolution of the histogram, lets specify 200 bins: diamond_df %&gt;% ggplot(aes(x=price)) + geom_histogram(bins=200) Here we can see an interesting lack of data around $1000. Let’s zoom in using xlim, and add some fill color. diamond_df %&gt;% ggplot(aes(x = price)) + geom_histogram(bins=200, fill = &#39;dodgerblue&#39;) + xlim(0,2500) ## Warning: Removed 26398 rows containing non-finite values (stat_bin). ## Warning: Removed 2 rows containing missing values (geom_bar). There are virtually no diamonds around the $1500 mark. What could be the reason for this? R will give a warning that some data is not represented in the plot. This is part of the ggplot philosophy that ‘data should not go missing silently.’ 3.4 Density plots Whereas it can be difficult to represent multiple sub-groups in a histogram, density plots are another essential tool for exploring your data. These are essentially smoothed histograms, where the area under the curve for each sub-group will sum to 1. This allows us to compare sub-groups of different size. diamond_df %&gt;% ggplot(aes(x = price)) + geom_density(aes(colour =cut)) 3.5 Box plots img from: https://miro.medium.com/max/18000/1*2c21SkzJMf3frPXPAR_gZA.png Box plots, or ‘box &amp; wisker plots’ are another essential tool for data analysis, which are related to histograms and density plots. Box plots summarize the distribution of a set of values by displaying the minimum and maximum values, the median (i.e. middle-ranked value), and the range of the middle 50% of values (interquartile range). The wisker line extending above and below the IQR box define Q3 + (1.5 x IQR), and Q1 - (1.5 x IQR) respectively. You can read more about box plots here. To create box plot from our data we use (no prizes here) geom_boxplot()! diamond_df %&gt;% ggplot(aes(x=cut, y=price)) + geom_boxplot() The points indicate outlier values [i.e., those greater than Q3 + (1.5xIQR) ]. We can overlay a boxplot on the scatterplot for the entire dataset, to fully communicate both the raw and summary data. Here we reduce the width of the jitter points slightly, and set the IQR box to be fully transparent using alpha. Note that this setting also hides the outlier points in geom_boxplot. diamond_df %&gt;% ggplot(aes(x=cut, y=price)) + geom_jitter(height=0, alpha=0.25, size=0.5, width=0.3) + geom_boxplot(alpha=0) Because its now difficult to see the box plots, we can colour only the geom_boxplot by setting the colour aesthetic within that geom: diamond_df %&gt;% ggplot(aes(x=cut, y=price)) + geom_jitter(height=0, alpha=0.25, size=0.5, width=0.3) + geom_boxplot(alpha=0, aes(colour =cut)) The legend contains the same information as the x axis, and is therefore redundant. We can drop the legend by giving an additional command to geom_boxplot: diamond_df %&gt;% ggplot(aes(x=cut, y=price)) + geom_jitter(height=0, alpha=0.25, size=0.5, width=0.3) + geom_boxplot(alpha=0, aes(colour =cut), show.legend = FALSE) In fact, a box plot displays very similar information to a density plot, rotated 90°. Violin plots, which reflect the sample density, can be used together with a box plot to convey even more detail about the distribution of a set of values. Here we limit the width of geom_boxplot to sit within geom_violin. Because both geoms will be coloured in the same way, we can give the color aesthetic directly to ggplot(). Similarly, because we dont want the legend, we will remove it using the theme() function. diamond_df %&gt;% ggplot(aes(x=cut, y=price, colour =cut)) + geom_boxplot(alpha=0, width=0.15) + geom_violin(alpha=0) + theme(legend.position = &#39;none&#39;) 3.6 Saving plots ggplot includes a neat function ggsave() which allows us to save plots in many formats By default ggsave() will save the most recent plot. It writes a file depending on the extension you provide. To save the plot that is currently in your Plots window: ggsave(&#39;~/Desktop/WEHI_tidyR_course/my_ggplot.pdf&#39;, width=5,height=4) To save a specific plot, its possible to store the plot as a variable, which is given to ggsave(): myplot &lt;- mpg %&gt;% ggplot(aes(x=displ, y=cty)) + geom_point(aes(colour =class)) ggsave(plot = myplot, &#39;~/Desktop/WEHI_tidyR_course/my_ggplot.pdf&#39;, width = 5, height = 4) In general, if you want to increase the size of points and text, then reduce the dimensions of the plot; and vice versa. 3.7 Challenge Based on what you’ve learnt, can you make a scatter plot that shows the relationship between diamond carat and price, with points coloured by clarity (reduced in size to 0.2), and faceted by cut? What do you notice about the distribution of carat? More generally, what has this exploratory data analysis taught us about human psychology when it comes to diamonds? 3.8 Solution diamond_df %&gt;% ggplot(aes(x=carat, y=price, colour =clarity)) + geom_point(size=0.2) + facet_wrap(~cut) "],
["week-2-part-1.html", "Week 2. Part 1", " Week 2. Part 1 "],
["subsetting-vectors.html", "4 Subsetting vectors 4.1 Subset by position 4.2 Adding names 4.3 Subset by condition 4.4 Challenge 4.5 Possible solutions", " 4 Subsetting vectors A very common task in data wrangling is filtering or ‘subsetting’ down to a smaller set of potentially interesting values. This short chapter is intended to give you a basic understanding of the operations that R is performing when filtering and evaluating data using the functions introduced in Chapter 5. Note that it is not necessary to have the tidyverse package loaded to complete this chapter - we are using ‘base R’ functions. First we will create a vector named ‘beatles’ containing the years of birth of The Beatles: John Lennon: 1940, Ringo Starr: 1940, Paul McCartney: 1942 and George Harrison: 1943. beatles &lt;- c(1940,1940,1942,1943) 4.1 Subset by position To hone in on different values in this vector we can request them based on their position in order 1 through 4. The position is given in square brackets beatles[1] ## [1] 1940 Returns just the value at the first position in the vector. Importantly, we can subset for values at position 2 and 3 by including a vector of numbers defining those positions. beatles[c(2,3)] ## [1] 1940 1942 We can also request everything but the value at a certain position, using the minus sign beatles[-3] ## [1] 1940 1940 1943 4.2 Adding names To add additional information to the values we can give each a name, supplied as a vector of words: names(beatles) &lt;- c(&#39;John&#39;,&#39;Ringo&#39;,&#39;Paul&#39;,&#39;George&#39;) Notice how the beatles variable has now changed slightly in the Environment panel. From now on every time a value is returned from the beatles vector, the Beatle member associated with that value is also returned. beatles[-3] ## John Ringo George ## 1940 1940 1943 4.3 Subset by condition In addition to subsetting a vector by the position of values, we can ‘pose questions’ about the set of values to R, which will be returned with TRUE or FALSE answers. ‘Which Beatles date of birth is 1940’? To code this we ask for values ‘exactly equal to’ 1940, using the == sign. beatles == 1940 ## John Ringo Paul George ## TRUE TRUE FALSE FALSE R returns ‘TRUE’ for values that satisfy our ‘condition’, and FALSE for those that don’t. ‘Which member(s) date of birth is before 1943?’ To code this we use the less-than &lt; sign. beatles &lt; 1943 ## John Ringo Paul George ## TRUE TRUE TRUE FALSE R is assessing the value at each position, and returning an answer to our conditional question. A way to directly subset this vector is to directly provide a vector of TRUE and FALSE values within square brackets, in a similar manner to specifying the positions, above. beatles[c(TRUE,FALSE,FALSE,TRUE)] ## John George ## 1940 1943 Note that the only values returned are in the ‘TRUE’ positions, in this case the values at position 1 and 4. We can see that subsetting a vector is based on the presence of a ‘TRUE’ or ‘FALSE’ statement at each position along the vector. In most cases when subsetting data, we want the values themselves, rather than the TRUE/FALSE evaluations. Now that we know that i) conditional requests return TRUE/FALSE values, and ii) TRUE/FALSE values are the basis of sub-setting vectors, we can substitute the TRUE/FALSE vector in the brackets above for a conditional statement: beatles[beatles &gt; 1940] ## Paul George ## 1942 1943 To check this, try running just the code within the square brackets. It is timely to mention that in R, code is processed from the inside- to outside of brackets. Here, the conditional statement is evaluated and produces a vector of four TRUE / FALSE values. This logical vector is then used to sub-set the original vector, returning a subset of named numeric values. ‘Which Beatles were not born in 1942?.’ To answer this we need to use a ! symbol that ‘negates’, or inverts the condition: beatles[ beatles!=1942 ] ## John Ringo George ## 1940 1940 1943 To get an even more succinct answer, we could request only the names associated with the numeric values: names( beatles[ beatles != 1942] ) ## [1] &quot;John&quot; &quot;Ringo&quot; &quot;George&quot; You will use these types of conditional statments regularly in the next chapter. 4.4 Challenge Create three different commands to return information about the Beatles born before 1943. You can use positional information, and/or conditional requests. 4.5 Possible solutions beatles[beatles &lt; 1943] ## John Ringo Paul ## 1940 1940 1942 beatles[beatles != 1943] ## John Ringo Paul ## 1940 1940 1942 beatles[-4] ## John Ringo Paul ## 1940 1940 1942 beatles[c(1,2,3)] ## John Ringo Paul ## 1940 1940 1942 beatles[names(beatles) != &#39;George&#39;] ## John Ringo Paul ## 1940 1940 1942 "],
["week-2-part-2.html", "Week 2. Part 2", " Week 2. Part 2 "],
["manipulating-data-with-dplyr.html", "5 Manipulating data with dplyr 5.1 filter() 5.2 select() 5.3 arrange() 5.4 Chaining dplyr functions 5.5 Writing data to a file 5.6 Chaining dplyr and ggplot 5.7 mutate() 5.8 summarize() 5.9 group_by() helper 5.10 Challenges 5.11 Solutions 5.12 Summary 5.13 Extra resources", " 5 Manipulating data with dplyr The dplyr package, part of the tidyverse, is designed to make manipulating and transforming data as simple and intuitive as possible. A guiding principle for tidyverse packages (and RStudio), is to minimize the number of keystrokes and characters required to get the results you want. To this end, as for ggplot, in dplyr, quotation marks for the column names of data frames are often not required. Another key feature of the tidyverse data wrangling packages such as dplyr, is that the input to and output from all functions, are data frames. dplyr features a handful of key functions, also termed ‘verbs’, which can be combined to achieve very specific results. You will notice similarities to the functions available in Microsoft Excel. We will explore the first of these verbs using the mpg_df dataset created earlier. If starting from a new Rstudio session you should open Week_2_tidyverse.R and run the following code: 5.1 filter() The filter() function subsets the rows in a data frame by testing against a conditional statement. The output from a successful filter() will be a data frame with fewer rows than the input data frame. Let’s filter the mpg_df data for cars manufacturered in the year 1999: mpg_df %&gt;% filter(year == 1999) ## # A tibble: 117 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 auto(l… f 18 29 p comp… ## 2 audi a4 1.8 1999 4 manual… f 21 29 p comp… ## 3 audi a4 2.8 1999 6 auto(l… f 16 26 p comp… ## 4 audi a4 2.8 1999 6 manual… f 18 26 p comp… ## 5 audi a4 quatt… 1.8 1999 4 manual… 4 18 26 p comp… ## 6 audi a4 quatt… 1.8 1999 4 auto(l… 4 16 25 p comp… ## 7 audi a4 quatt… 2.8 1999 6 auto(l… 4 15 25 p comp… ## 8 audi a4 quatt… 2.8 1999 6 manual… 4 17 25 p comp… ## 9 audi a6 quatt… 2.8 1999 6 auto(l… 4 15 24 p mids… ## 10 chevrolet c1500 su… 5.7 1999 8 auto(l… r 13 17 r suv ## # … with 107 more rows Here we are ‘sending’ the mpg_df data frame into the function filter(), which tests each value in the year column for the number 1999, and returns those rows where the filter() condition is TRUE. If you are working in an R text document (.R format) or directly in the console, after running this command you will see the dimensions of the output data frame printed in grey text above the column names. Alternatively you can ‘send’ the output of filter (a data frame) into the dim() function. mpg_df %&gt;% filter(year==1999) %&gt;% dim() ## [1] 117 11 We can also filter on character data. For example, let’s take all vehicles in the ‘midsize’ class: mpg_df %&gt;% filter(class==&#39;midsize&#39;) ## # A tibble: 41 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a6 quat… 2.8 1999 6 auto(l… 4 15 24 p midsi… ## 2 audi a6 quat… 3.1 2008 6 auto(s… 4 17 25 p midsi… ## 3 audi a6 quat… 4.2 2008 8 auto(s… 4 16 23 p midsi… ## 4 chevrolet malibu 2.4 1999 4 auto(l… f 19 27 r midsi… ## 5 chevrolet malibu 2.4 2008 4 auto(l… f 22 30 r midsi… ## 6 chevrolet malibu 3.1 1999 6 auto(l… f 18 26 r midsi… ## 7 chevrolet malibu 3.5 2008 6 auto(l… f 18 29 r midsi… ## 8 chevrolet malibu 3.6 2008 6 auto(s… f 17 26 r midsi… ## 9 hyundai sonata 2.4 1999 4 auto(l… f 18 26 r midsi… ## 10 hyundai sonata 2.4 1999 4 manual… f 18 27 r midsi… ## # … with 31 more rows Can you filter mpg_df for all vehicles except the hyundais? 5.1.1 Logical operations 5.1.1.1 &amp; and We can achieve more specific filters by combining conditions across columns. For example, we use the “&amp;” sign to filter for vehicles built in 1999 and with mileage in the city (cty) greater than 18. mpg_df %&gt;% filter(year == 1999 &amp; cty &gt; 18) ## # A tibble: 33 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 manual(… f 21 29 p compact ## 2 chevrolet malibu 2.4 1999 4 auto(l4) f 19 27 r midsize ## 3 honda civic 1.6 1999 4 manual(… f 28 33 r subcom… ## 4 honda civic 1.6 1999 4 auto(l4) f 24 32 r subcom… ## 5 honda civic 1.6 1999 4 manual(… f 25 32 r subcom… ## 6 honda civic 1.6 1999 4 manual(… f 23 29 p subcom… ## 7 honda civic 1.6 1999 4 auto(l4) f 24 32 r subcom… ## 8 hyundai tibur… 2 1999 4 auto(l4) f 19 26 r subcom… ## 9 hyundai tibur… 2 1999 4 manual(… f 19 29 r subcom… ## 10 nissan altima 2.4 1999 4 manual(… f 21 29 r compact ## # … with 23 more rows To see the entire output you can pipe the output from filter into a View() commmand mpg_df %&gt;% filter(year==1999 &amp; cty &gt; 18) %&gt;% View() 5.1.1.2 | or Alternatively we might want to filter for vehicles (i.e., rows) where the manufacturer is chevrolet or the class is ‘suv’. This requires the “|” symbol (shift + \\) mpg_df %&gt;% filter(manufacturer==&#39;chevrolet&#39; | class==&#39;suv&#39;) ## # A tibble: 72 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 chevrolet c1500 su… 5.3 2008 8 auto(l… r 14 20 r suv ## 2 chevrolet c1500 su… 5.3 2008 8 auto(l… r 11 15 e suv ## 3 chevrolet c1500 su… 5.3 2008 8 auto(l… r 14 20 r suv ## 4 chevrolet c1500 su… 5.7 1999 8 auto(l… r 13 17 r suv ## 5 chevrolet c1500 su… 6 2008 8 auto(l… r 12 17 r suv ## 6 chevrolet corvette 5.7 1999 8 manual… r 16 26 p 2sea… ## 7 chevrolet corvette 5.7 1999 8 auto(l… r 15 23 p 2sea… ## 8 chevrolet corvette 6.2 2008 8 manual… r 16 26 p 2sea… ## 9 chevrolet corvette 6.2 2008 8 auto(s… r 15 25 p 2sea… ## 10 chevrolet corvette 7 2008 8 manual… r 15 24 p 2sea… ## # … with 62 more rows 5.1.1.3 and/or To take it a step further we can combine &amp; and | in the same filter command. Adding curved brackets will help to clarify the order of operations. Let’s filter for the vehicles where the manufacturer is chevrolet or the class is ‘suv’, and all vehicles with highway mileage less than 20. mpg_df %&gt;% filter( (manufacturer==&#39;chevrolet&#39; | class==&#39;suv&#39;) &amp; hwy &lt; 20) ## # A tibble: 48 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 chevrolet c1500 sub… 5.3 2008 8 auto(… r 11 15 e suv ## 2 chevrolet c1500 sub… 5.7 1999 8 auto(… r 13 17 r suv ## 3 chevrolet c1500 sub… 6 2008 8 auto(… r 12 17 r suv ## 4 chevrolet k1500 tah… 5.3 2008 8 auto(… 4 14 19 r suv ## 5 chevrolet k1500 tah… 5.3 2008 8 auto(… 4 11 14 e suv ## 6 chevrolet k1500 tah… 5.7 1999 8 auto(… 4 11 15 r suv ## 7 chevrolet k1500 tah… 6.5 1999 8 auto(… 4 14 17 d suv ## 8 dodge durango 4… 3.9 1999 6 auto(… 4 13 17 r suv ## 9 dodge durango 4… 4.7 2008 8 auto(… 4 13 17 r suv ## 10 dodge durango 4… 4.7 2008 8 auto(… 4 9 12 e suv ## # … with 38 more rows 5.1.2 str_detect() helper function Often we want to capture rows containing a particular sequence of letters. For example, there are 10 different vehicle models containing the letters ‘4wd’. We don’t want to have to write an ‘or’ command with 10 alternatives. A much better way is to ‘detect’ the letters ‘4wd’ in the model column, and return all rows where they are present, using str_detect(). str_detect() is a command within filter() which requires the column name, followed by the letters (in quotes) to search for mpg_df %&gt;% filter(str_detect(model,&#39;4wd&#39;)) ## # A tibble: 74 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 chevrolet k1500 ta… 5.3 2008 8 auto(l… 4 14 19 r suv ## 2 chevrolet k1500 ta… 5.3 2008 8 auto(l… 4 11 14 e suv ## 3 chevrolet k1500 ta… 5.7 1999 8 auto(l… 4 11 15 r suv ## 4 chevrolet k1500 ta… 6.5 1999 8 auto(l… 4 14 17 d suv ## 5 dodge dakota p… 3.7 2008 6 manual… 4 15 19 r pick… ## 6 dodge dakota p… 3.7 2008 6 auto(l… 4 14 18 r pick… ## 7 dodge dakota p… 3.9 1999 6 auto(l… 4 13 17 r pick… ## 8 dodge dakota p… 3.9 1999 6 manual… 4 14 17 r pick… ## 9 dodge dakota p… 4.7 2008 8 auto(l… 4 14 19 r pick… ## 10 dodge dakota p… 4.7 2008 8 auto(l… 4 14 19 r pick… ## # … with 64 more rows Note that the letter order and case have to be matched exactly. How would you filter for all vehicles with automatic transmission? 5.1.3 is.na() helper If there are NA (missing) values in a particular column, we can inspect or drop them using the is.na() helper. To check for the presence of NA values in the year column, for example: mpg %&gt;% filter(is.na(year)) ## # A tibble: 0 x 11 ## # … with 11 variables: manufacturer &lt;chr&gt;, model &lt;chr&gt;, displ &lt;dbl&gt;, year &lt;int&gt;, ## # cyl &lt;int&gt;, trans &lt;chr&gt;, drv &lt;chr&gt;, cty &lt;int&gt;, hwy &lt;int&gt;, fl &lt;chr&gt;, ## # class &lt;chr&gt; The mpg data set doesn’t contain any missing values, however in later chapters we will encounter them. Any rows with a missing value in the year column would be dropped using the code mpg %&gt;% filter(!is.na(year)) ## # A tibble: 234 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 auto(l… f 18 29 p compa… ## 2 audi a4 1.8 1999 4 manual… f 21 29 p compa… ## 3 audi a4 2 2008 4 manual… f 20 31 p compa… ## 4 audi a4 2 2008 4 auto(a… f 21 30 p compa… ## 5 audi a4 2.8 1999 6 auto(l… f 16 26 p compa… ## 6 audi a4 2.8 1999 6 manual… f 18 26 p compa… ## 7 audi a4 3.1 2008 6 auto(a… f 18 27 p compa… ## 8 audi a4 quat… 1.8 1999 4 manual… 4 18 26 p compa… ## 9 audi a4 quat… 1.8 1999 4 auto(l… 4 16 25 p compa… ## 10 audi a4 quat… 2 2008 4 manual… 4 20 28 p compa… ## # … with 224 more rows 5.1.4 complete.cases() helper Similar to is.na(), we can check for the presence of NA values across all columns of a dataframe using complete.cases(). This function is not part of the tidyverse package, so it requires a period . within the brackets, to indicate that we want to search across the entire dataframe. To filter for only the rows with no missing values: mpg %&gt;% filter( complete.cases(.) ) ## # A tibble: 234 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 auto(l… f 18 29 p compa… ## 2 audi a4 1.8 1999 4 manual… f 21 29 p compa… ## 3 audi a4 2 2008 4 manual… f 20 31 p compa… ## 4 audi a4 2 2008 4 auto(a… f 21 30 p compa… ## 5 audi a4 2.8 1999 6 auto(l… f 16 26 p compa… ## 6 audi a4 2.8 1999 6 manual… f 18 26 p compa… ## 7 audi a4 3.1 2008 6 auto(a… f 18 27 p compa… ## 8 audi a4 quat… 1.8 1999 4 manual… 4 18 26 p compa… ## 9 audi a4 quat… 1.8 1999 4 auto(l… 4 16 25 p compa… ## 10 audi a4 quat… 2 2008 4 manual… 4 20 28 p compa… ## # … with 224 more rows And to filter for all rows with a missing value in at least one column: mpg %&gt;% filter( !complete.cases(.) ) ## # A tibble: 0 x 11 ## # … with 11 variables: manufacturer &lt;chr&gt;, model &lt;chr&gt;, displ &lt;dbl&gt;, year &lt;int&gt;, ## # cyl &lt;int&gt;, trans &lt;chr&gt;, drv &lt;chr&gt;, cty &lt;int&gt;, hwy &lt;int&gt;, fl &lt;chr&gt;, ## # class &lt;chr&gt; 5.2 select() Whereas filter() subsets a dataframe by row, select() returns a subset of the columns. This function can take column names (even without quotes), or the column position number beginning at left. Further, unlike in base R, commands within the brackets in select() do not need to be concatenated using c(). Let’s extract the car model, engine volume (displ) and highway mileage (hwy) from mpg_df: mpg_df %&gt;% select(model, displ, hwy) ## # A tibble: 234 x 3 ## model displ hwy ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 a4 1.8 29 ## 2 a4 1.8 29 ## 3 a4 2 31 ## 4 a4 2 30 ## 5 a4 2.8 26 ## 6 a4 2.8 26 ## 7 a4 3.1 27 ## 8 a4 quattro 1.8 26 ## 9 a4 quattro 1.8 25 ## 10 a4 quattro 2 28 ## # … with 224 more rows We can use ‘-’ to extract all except particular column(s). For example, to drop the model and year columns: mpg_df %&gt;% select(-model, -year) ## # A tibble: 234 x 9 ## manufacturer displ cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi 1.8 4 auto(l5) f 18 29 p compact ## 2 audi 1.8 4 manual(m5) f 21 29 p compact ## 3 audi 2 4 manual(m6) f 20 31 p compact ## 4 audi 2 4 auto(av) f 21 30 p compact ## 5 audi 2.8 6 auto(l5) f 16 26 p compact ## 6 audi 2.8 6 manual(m5) f 18 26 p compact ## 7 audi 3.1 6 auto(av) f 18 27 p compact ## 8 audi 1.8 4 manual(m5) 4 18 26 p compact ## 9 audi 1.8 4 auto(l5) 4 16 25 p compact ## 10 audi 2 4 manual(m6) 4 20 28 p compact ## # … with 224 more rows We can also specify column positions. Take the data in columns number 1,5 and 11 mpg_df %&gt;% select(1,5,11) ## # A tibble: 234 x 3 ## manufacturer cyl class ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 audi 4 compact ## 2 audi 4 compact ## 3 audi 4 compact ## 4 audi 4 compact ## 5 audi 6 compact ## 6 audi 6 compact ## 7 audi 6 compact ## 8 audi 4 compact ## 9 audi 4 compact ## 10 audi 4 compact ## # … with 224 more rows Or combine column positions and names: mpg_df %&gt;% select(1,3, cty, hwy) ## # A tibble: 234 x 4 ## manufacturer displ cty hwy ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 audi 1.8 18 29 ## 2 audi 1.8 21 29 ## 3 audi 2 20 31 ## 4 audi 2 21 30 ## 5 audi 2.8 16 26 ## 6 audi 2.8 18 26 ## 7 audi 3.1 18 27 ## 8 audi 1.8 18 26 ## 9 audi 1.8 16 25 ## 10 audi 2 20 28 ## # … with 224 more rows 5.2.1 contains() helper function contains() is a helper function used with select(), which is analagous to the str_detect() helper used with filter(). To select only columns with names containing the letter ‘y’: mpg_df %&gt;% select(contains(&#39;y&#39;)) ## # A tibble: 234 x 4 ## year cyl cty hwy ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1999 4 18 29 ## 2 1999 4 21 29 ## 3 2008 4 20 31 ## 4 2008 4 21 30 ## 5 1999 6 16 26 ## 6 1999 6 18 26 ## 7 2008 6 18 27 ## 8 1999 4 18 26 ## 9 1999 4 16 25 ## 10 2008 4 20 28 ## # … with 224 more rows contains() is also useful for selecting all column names featuring a certain character, e.g. contains(’_’) 5.2.2 starts_with() helper function start_with() and ends_with() offer more specificity for select(). If we want all columns begining with the letter ‘c’: mpg_df %&gt;% select(starts_with(&#39;c&#39;)) ## # A tibble: 234 x 3 ## cyl cty class ## &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 4 18 compact ## 2 4 21 compact ## 3 4 20 compact ## 4 4 21 compact ## 5 6 16 compact ## 6 6 18 compact ## 7 6 18 compact ## 8 4 18 compact ## 9 4 16 compact ## 10 4 20 compact ## # … with 224 more rows Happily we can even mix these helper functions with the standard select commands: mpg_df %&gt;% select( 2, 1, class, contains(&#39;y&#39;)) ## # A tibble: 234 x 7 ## model manufacturer class year cyl cty hwy ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 a4 audi compact 1999 4 18 29 ## 2 a4 audi compact 1999 4 21 29 ## 3 a4 audi compact 2008 4 20 31 ## 4 a4 audi compact 2008 4 21 30 ## 5 a4 audi compact 1999 6 16 26 ## 6 a4 audi compact 1999 6 18 26 ## 7 a4 audi compact 2008 6 18 27 ## 8 a4 quattro audi compact 1999 4 18 26 ## 9 a4 quattro audi compact 1999 4 16 25 ## 10 a4 quattro audi compact 2008 4 20 28 ## # … with 224 more rows 5.2.3 everything() helper function Lastly for select(), a very useful helper is the everything() function, which returns all column names that have not been specified. It is often used when reordering all columns in a dataframe: mpg_df %&gt;% select(class,displ,year,everything()) ## # A tibble: 234 x 11 ## class displ year manufacturer model cyl trans drv cty hwy fl ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 compa… 1.8 1999 audi a4 4 auto(l… f 18 29 p ## 2 compa… 1.8 1999 audi a4 4 manual… f 21 29 p ## 3 compa… 2 2008 audi a4 4 manual… f 20 31 p ## 4 compa… 2 2008 audi a4 4 auto(a… f 21 30 p ## 5 compa… 2.8 1999 audi a4 6 auto(l… f 16 26 p ## 6 compa… 2.8 1999 audi a4 6 manual… f 18 26 p ## 7 compa… 3.1 2008 audi a4 6 auto(a… f 18 27 p ## 8 compa… 1.8 1999 audi a4 quat… 4 manual… 4 18 26 p ## 9 compa… 1.8 1999 audi a4 quat… 4 auto(l… 4 16 25 p ## 10 compa… 2 2008 audi a4 quat… 4 manual… 4 20 28 p ## # … with 224 more rows Note that the dimensions of the dataframe have not changed, merely the column order. 5.3 arrange() arrange() is the simplest of the dplyr functions, which orders rows according to values in a given column. The default is to order numbers from lowest -&gt; highest. Let’s try ordering the vehicles by engine size (displ) mpg_df %&gt;% arrange(displ) ## # A tibble: 234 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 honda civic 1.6 1999 4 manual… f 28 33 r subcom… ## 2 honda civic 1.6 1999 4 auto(l… f 24 32 r subcom… ## 3 honda civic 1.6 1999 4 manual… f 25 32 r subcom… ## 4 honda civic 1.6 1999 4 manual… f 23 29 p subcom… ## 5 honda civic 1.6 1999 4 auto(l… f 24 32 r subcom… ## 6 audi a4 1.8 1999 4 auto(l… f 18 29 p compact ## 7 audi a4 1.8 1999 4 manual… f 21 29 p compact ## 8 audi a4 qua… 1.8 1999 4 manual… 4 18 26 p compact ## 9 audi a4 qua… 1.8 1999 4 auto(l… 4 16 25 p compact ## 10 honda civic 1.8 2008 4 manual… f 26 34 r subcom… ## # … with 224 more rows We can refine the order by giving additional columns of data. To order rows by manufacturer name (alphabetical), then by engine size then by city mileage: mpg_df %&gt;% arrange(manufacturer, displ, cty ) ## # A tibble: 234 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 quat… 1.8 1999 4 auto(l… 4 16 25 p compa… ## 2 audi a4 1.8 1999 4 auto(l… f 18 29 p compa… ## 3 audi a4 quat… 1.8 1999 4 manual… 4 18 26 p compa… ## 4 audi a4 1.8 1999 4 manual… f 21 29 p compa… ## 5 audi a4 quat… 2 2008 4 auto(s… 4 19 27 p compa… ## 6 audi a4 2 2008 4 manual… f 20 31 p compa… ## 7 audi a4 quat… 2 2008 4 manual… 4 20 28 p compa… ## 8 audi a4 2 2008 4 auto(a… f 21 30 p compa… ## 9 audi a4 quat… 2.8 1999 6 auto(l… 4 15 25 p compa… ## 10 audi a6 quat… 2.8 1999 6 auto(l… 4 15 24 p midsi… ## # … with 224 more rows 5.3.1 desc() helper function To invert the standard order, we can use the ‘descending’ desc() helper function. To find the most fuel-efficient vehicles when on the highway, we could use: mpg_df %&gt;% arrange(desc(hwy)) ## # A tibble: 234 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 volkswagen jetta 1.9 1999 4 manual… f 33 44 d compact ## 2 volkswagen new be… 1.9 1999 4 manual… f 35 44 d subcom… ## 3 volkswagen new be… 1.9 1999 4 auto(l… f 29 41 d subcom… ## 4 toyota corolla 1.8 2008 4 manual… f 28 37 r compact ## 5 honda civic 1.8 2008 4 auto(l… f 25 36 r subcom… ## 6 honda civic 1.8 2008 4 auto(l… f 24 36 c subcom… ## 7 toyota corolla 1.8 1999 4 manual… f 26 35 r compact ## 8 toyota corolla 1.8 2008 4 auto(l… f 26 35 r compact ## 9 honda civic 1.8 2008 4 manual… f 26 34 r subcom… ## 10 honda civic 1.6 1999 4 manual… f 28 33 r subcom… ## # … with 224 more rows 5.4 Chaining dplyr functions Coding from left-to-right using the pipe %&gt;% allows us to make ‘chains’ of commands to achieve very specific results. Let’s filter for the midsize vehicles, then select the columns class, manufacturer, displ and year, and arrange on engine size (displ): mpg_df %&gt;% filter(class==&#39;midsize&#39;) %&gt;% select(class,manufacturer,displ,year) %&gt;% arrange(displ) ## # A tibble: 41 x 4 ## class manufacturer displ year ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 midsize volkswagen 1.8 1999 ## 2 midsize volkswagen 1.8 1999 ## 3 midsize volkswagen 2 2008 ## 4 midsize volkswagen 2 2008 ## 5 midsize toyota 2.2 1999 ## 6 midsize toyota 2.2 1999 ## 7 midsize chevrolet 2.4 1999 ## 8 midsize chevrolet 2.4 2008 ## 9 midsize hyundai 2.4 1999 ## 10 midsize hyundai 2.4 1999 ## # … with 31 more rows Using line-breaks makes the order of operations very easy to read (and fix if necessary). Once we’re happy with the output of this chain of functions, we can assign it to a new object (aka variable) in the environment: mpg_slim &lt;- mpg_df %&gt;% filter(class==&#39;midsize&#39;) %&gt;% select(class,manufacturer,displ,year) %&gt;% arrange(displ) Note that all of the functions will be performed before the output is assigned into mpg_slim. Therefore even though mpg_slim is at the top of the code, it will contain the final output dataframe. 5.5 Writing data to a file The new mpg_slim data frame could be saved to a file outside of the R session using write_tsv() write_tsv() creates a tab-separated file that can be read by applications like Excel. We first give the variable name, then the file name (ideally with a full directory location): On Mac: write_tsv(mpg_slim, &#39;~/Desktop/mpg_slim_dataframe.tsv&#39;) On PC: write_tsv(mpg_slim, &#39;C:/Users/ansell.b/Desktop/mpg_slim_dataframe.tsv&#39;) We will learn how to read data in to R in the next chapter. 5.6 Chaining dplyr and ggplot We can also send the dplyr output directly into ggplot! mpg_df %&gt;% filter(class==&#39;midsize&#39;) %&gt;% select(class,manufacturer,displ,year) %&gt;% arrange(displ) %&gt;% ggplot(aes(x=class,y=displ)) + geom_boxplot() Whereas this is very useful for quickly manipulating and plotting data, for readability you might prefer to separate the dplyr commands from the ggplot commands like so: #first create smaller dataset mpg_slim &lt;- mpg_df %&gt;% filter(class==&#39;midsize&#39;) %&gt;% select(class,manufacturer,displ,year) %&gt;% arrange(displ) #then plot the distribution of engine volumes of &#39;midsize&#39; cars mpg_slim %&gt;% ggplot(aes(x=class,y=displ)) + geom_boxplot() 5.7 mutate() Whereas the the verbs we’ve covered so far modify the dimensions and order of the existing data frame, mutate() adds new columns of data, thus ‘mutating’ the contents and dimensions of the input data frame. To explore mutate we will use the diamond_df data frame from earlier. You can recreate if necessary: diamond_df &lt;- ggplot2::diamonds The price column for these diamonds is in US dollars. If we want to convert the price to Australian dollars we can (optimistically) multiply USD by 1.25. Here we create a new column called AUD, which will contain a new column where each row = price * 1.25. Because the number of columns is expanding, to easily see the results we can first drop the x/y/z dimension columns using select() diamond_df %&gt;% select(-x, -y, -z) %&gt;% mutate(AUD = price * 1.25) ## # A tibble: 53,940 x 8 ## carat cut color clarity depth table price AUD ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 408. ## 2 0.21 Premium E SI1 59.8 61 326 408. ## 3 0.23 Good E VS1 56.9 65 327 409. ## 4 0.290 Premium I VS2 62.4 58 334 418. ## 5 0.31 Good J SI2 63.3 58 335 419. ## 6 0.24 Very Good J VVS2 62.8 57 336 420 ## 7 0.24 Very Good I VVS1 62.3 57 336 420 ## 8 0.26 Very Good H SI1 61.9 55 337 421. ## 9 0.22 Fair E VS2 65.1 61 337 421. ## 10 0.23 Very Good H VS1 59.4 61 338 422. ## # … with 53,930 more rows We can also perform operations using only the data in existing columns. Here as above, the newly created column will contain the results of a mathematical operation, performed row by row. Let’s calculate the US dollars per carat (‘ppc’) by dividing the price column by the carat column diamond_df %&gt;% select(-x,-y,-z) %&gt;% mutate(ppc = price/carat) ## # A tibble: 53,940 x 8 ## carat cut color clarity depth table price ppc ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 1417. ## 2 0.21 Premium E SI1 59.8 61 326 1552. ## 3 0.23 Good E VS1 56.9 65 327 1422. ## 4 0.290 Premium I VS2 62.4 58 334 1152. ## 5 0.31 Good J SI2 63.3 58 335 1081. ## 6 0.24 Very Good J VVS2 62.8 57 336 1400 ## 7 0.24 Very Good I VVS1 62.3 57 336 1400 ## 8 0.26 Very Good H SI1 61.9 55 337 1296. ## 9 0.22 Fair E VS2 65.1 61 337 1532. ## 10 0.23 Very Good H VS1 59.4 61 338 1470. ## # … with 53,930 more rows 5.7.1 Challenge One carat weighs 0.2 grams. Can you chain multiple mutate() functions together to calculate for each diamond, the Australian Dollars per gram? 5.7.2 Solution diamond_df %&gt;% select(-x,-y,-z) %&gt;% mutate(grams = 0.2 * carat) %&gt;% mutate(AUD = price * 1.25) %&gt;% mutate(aud_per_gram = AUD/grams) ## # A tibble: 53,940 x 10 ## carat cut color clarity depth table price grams AUD aud_per_gram ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 0.046 408. 8859. ## 2 0.21 Premium E SI1 59.8 61 326 0.042 408. 9702. ## 3 0.23 Good E VS1 56.9 65 327 0.046 409. 8886. ## 4 0.290 Premium I VS2 62.4 58 334 0.0580 418. 7198. ## 5 0.31 Good J SI2 63.3 58 335 0.062 419. 6754. ## 6 0.24 Very Good J VVS2 62.8 57 336 0.048 420 8750 ## 7 0.24 Very Good I VVS1 62.3 57 336 0.048 420 8750 ## 8 0.26 Very Good H SI1 61.9 55 337 0.052 421. 8101. ## 9 0.22 Fair E VS2 65.1 61 337 0.044 421. 9574. ## 10 0.23 Very Good H VS1 59.4 61 338 0.046 422. 9185. ## # … with 53,930 more rows 5.7.3 ifelse() helper The mutate() function is very useful for making a new column of labels for the existing data. For example, to label outliers, or a sub-set of genes with particular characteristics. This is where ifelse() comes in. ifelse() is a function that tests each value in a column of data for a particular condition (a logical test), and returns one answer when the condition==TRUE, and another when the condition==FALSE. Specifically, ifelse() takes three commands: the condition to test, the output when TRUE, and the output when FALSE. To see how this works let’s create a label for each diamond depending on whether we consider it ‘expensive’ (&gt; $5000) or ‘cheap’ (&lt; $5000). diamond_df %&gt;% select(-x,-y,-z) %&gt;% mutate(price_label = ifelse(price &gt; 5000, &#39;expensive&#39;, &#39;cheap&#39;)) ## # A tibble: 53,940 x 8 ## carat cut color clarity depth table price price_label ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 cheap ## 2 0.21 Premium E SI1 59.8 61 326 cheap ## 3 0.23 Good E VS1 56.9 65 327 cheap ## 4 0.290 Premium I VS2 62.4 58 334 cheap ## 5 0.31 Good J SI2 63.3 58 335 cheap ## 6 0.24 Very Good J VVS2 62.8 57 336 cheap ## 7 0.24 Very Good I VVS1 62.3 57 336 cheap ## 8 0.26 Very Good H SI1 61.9 55 337 cheap ## 9 0.22 Fair E VS2 65.1 61 337 cheap ## 10 0.23 Very Good H VS1 59.4 61 338 cheap ## # … with 53,930 more rows Remember that we need two closing brackets, one for the mutate() function, and one for the ifelse() inside it. It seems that the ifelse() function has worked. All the rows we can see are price &lt; 5000 and labeled ‘cheap’. But how can we be sure? One option to check the new labels is to plot the price column as a histogram, and fill the bars according to price_label: diamond_df %&gt;% select(-x,-y,-z) %&gt;% mutate(price_label = ifelse(price &gt; 5000,&#39;expensive&#39;,&#39;cheap&#39;)) %&gt;% ggplot(aes(x=price, fill = price_label)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Now we can be confident that ifelse() command has worked as intended. Another option for checking output is to use count(), which will be introduced below. 5.7.4 case_when() helper This function is useful but quite involved. I’m including it here for completeness, however beginners can feel free to skip down to the summarize() section and return to case_when() later. At times we want to create a label column that tests multiple conditions. We can either put multiple ifelse() commands inside each other (and go mad), or use case_when()! This command takes multiple conditions and tests them in order. This is important to remember as all rows that satisfy the first condition will be tagged as such. There may be rows that satisfy more than one condition, so you should order the tests from specific to general, and keep track of how those ambiguous rows are being treated. case_when() takes a conditional command in the same format as the first command in ifelse(), however only the action for the TRUE condition is given, separated with a tilde ~. The catch-all command for rows that do not satisfy any other conditions, is given at the end. Let’s use case_when() to make a label for diamonds based on their clarity super-groups. For simplicy, we select only the clarity column as input. The current clarity categories are: IF: internally flawless VVS1 and 2: very very slight impurity 1 and 2 VS1 and 2: very slight impurity 1 and 2 SI1 and 2: slight impurity 1 and 2 I1: impurity Note that we are searching for similar conditions (‘VVS’ contains ‘VS’) and will have to be careful with the order of conditions. To create the super-groupings we will use a combination of str_detect() and equality == conditions. diamond_df %&gt;% select(clarity) %&gt;% mutate(clarity_group = case_when(clarity == &#39;IF&#39; ~ &#39;flawless&#39;, str_detect(clarity, &#39;VVS&#39;) ~ &#39;VV_slight&#39;, str_detect(clarity, &#39;VS&#39;) ~ &#39;V_slight&#39;, str_detect(clarity, &#39;SI&#39;) ~ &#39;slight&#39;, clarity == &#39;I1&#39; ~ &#39;impurity&#39;, TRUE ~ &#39;other&#39;)) ## # A tibble: 53,940 x 2 ## clarity clarity_group ## &lt;ord&gt; &lt;chr&gt; ## 1 SI2 slight ## 2 SI1 slight ## 3 VS1 V_slight ## 4 VS2 V_slight ## 5 SI2 slight ## 6 VVS2 VV_slight ## 7 VVS1 VV_slight ## 8 SI1 slight ## 9 VS2 V_slight ## 10 VS1 V_slight ## # … with 53,930 more rows Note that both VS1 and VS2 diamonds are now taged as ‘V_slight’, and similarliy VVS1 and VVS2 are taged as ‘VV_slight’. Because we have captured all clarity categories within the list of conditions, we dont expect the catch-all output, “other”, to be present in the clarity_group column. We could use %&gt;% count(clarity_group), introduced below, to check for the presence of unintended values such as ‘other’ or NA. These super-groups could now be used for coloring or faceting data in a plot, or creating summary statistics (see below). 5.8 summarize() The last of the dplyr verbs is summarize(), which as the name suggests, creates individual summary statistics from larger data sets. As for mutate(), the output of summarize() is qualitatively different from the input: it is generally a smaller dataframe with a reduced representation of the input data. Importantly, even though the output of summarize() can be very small, it is still a dataframe. Although not essential, it is also a good idea to specify new column names for the summary statistics that this function creates. First we will calculate the mean price for the diamond_df dataframe by specifying a name for the new data, and then the function we want to apply to the price column: diamond_df %&gt;% summarize(mean_price = mean(price)) ## # A tibble: 1 x 1 ## mean_price ## &lt;dbl&gt; ## 1 3933. The output is the smallest possible dataframe: 1 row X 1 column. We can create additional summary statistics by adding them in a comma-separated sequence. For example, to calculate the standard deviation, mininum and maximum values, we create three additional columns: “sd_price”, “min_price”, and “max_price” diamond_df %&gt;% summarize(mean_price = mean(price), sd_price = sd(price), min_price = min(price), max_price = max(price)) ## # A tibble: 1 x 4 ## mean_price sd_price min_price max_price ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 3933. 3989. 326 18823 5.8.1 n() helper When using summarize(), we can also count the number of rows being summarized, which can be important for interpreting the associated statistics. The simple function n() never takes any additional code, but simply counts rows: diamond_df %&gt;% summarize(mean_price = mean(price), sd_price = sd(price), min_price = min(price), max_price = max(price), n_rows = n()) ## # A tibble: 1 x 5 ## mean_price sd_price min_price max_price n_rows ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 3933. 3989. 326 18823 53940 So far so good, however this seems like quite a lot of code to get the simple summary statistics. The power of this function is really amplified in conjuction with the group_by() helper. 5.9 group_by() helper Although I’ve called group_by() a helper function, it is key to unleashing the power of nearly all dplyr functions. group_by() allows us to create sub-groups based on labels in a particular column, and to run subsequent functions on all sub-groups. It is conceptually similar to facet_wrap() in ggplot, which applies the same plotting command to multiple subsets of the input dataframe. For example the figure below is using group_by() as the first arrow, and summarize() as the second arrow. Three sub-groups, corresponding to e.g. three categories in column 1, are represented in the light grey, blue and green rows. A summarize() command is then run on each sub-group, producing a results dataframe with only three rows, and new (dark blue) column names indicating the summary statistic. For those interested in more details, group_by() is essentially creating a separate dataframe for each category in a specified column. To see this at work, look the structure str() of the diamonds data before and after grouping: diamond_df %&gt;% str() ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 53940 obs. of 10 variables: ## $ carat : num 0.23 0.21 0.23 0.29 0.31 0.24 0.24 0.26 0.22 0.23 ... ## $ cut : Ord.factor w/ 5 levels &quot;Fair&quot;&lt;&quot;Good&quot;&lt;..: 5 4 2 4 2 3 3 3 1 3 ... ## $ color : Ord.factor w/ 7 levels &quot;D&quot;&lt;&quot;E&quot;&lt;&quot;F&quot;&lt;&quot;G&quot;&lt;..: 2 2 2 6 7 7 6 5 2 5 ... ## $ clarity: Ord.factor w/ 8 levels &quot;I1&quot;&lt;&quot;SI2&quot;&lt;&quot;SI1&quot;&lt;..: 2 3 5 4 2 6 7 3 4 5 ... ## $ depth : num 61.5 59.8 56.9 62.4 63.3 62.8 62.3 61.9 65.1 59.4 ... ## $ table : num 55 61 65 58 58 57 57 55 61 61 ... ## $ price : int 326 326 327 334 335 336 336 337 337 338 ... ## $ x : num 3.95 3.89 4.05 4.2 4.34 3.94 3.95 4.07 3.87 4 ... ## $ y : num 3.98 3.84 4.07 4.23 4.35 3.96 3.98 4.11 3.78 4.05 ... ## $ z : num 2.43 2.31 2.31 2.63 2.75 2.48 2.47 2.53 2.49 2.39 ... We have a single dataframe with 54K rows. Now we group by cut: diamond_df %&gt;% group_by(cut) %&gt;% str() ## Classes &#39;grouped_df&#39;, &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 53940 obs. of 10 variables: ## $ carat : num 0.23 0.21 0.23 0.29 0.31 0.24 0.24 0.26 0.22 0.23 ... ## $ cut : Ord.factor w/ 5 levels &quot;Fair&quot;&lt;&quot;Good&quot;&lt;..: 5 4 2 4 2 3 3 3 1 3 ... ## $ color : Ord.factor w/ 7 levels &quot;D&quot;&lt;&quot;E&quot;&lt;&quot;F&quot;&lt;&quot;G&quot;&lt;..: 2 2 2 6 7 7 6 5 2 5 ... ## $ clarity: Ord.factor w/ 8 levels &quot;I1&quot;&lt;&quot;SI2&quot;&lt;&quot;SI1&quot;&lt;..: 2 3 5 4 2 6 7 3 4 5 ... ## $ depth : num 61.5 59.8 56.9 62.4 63.3 62.8 62.3 61.9 65.1 59.4 ... ## $ table : num 55 61 65 58 58 57 57 55 61 61 ... ## $ price : int 326 326 327 334 335 336 336 337 337 338 ... ## $ x : num 3.95 3.89 4.05 4.2 4.34 3.94 3.95 4.07 3.87 4 ... ## $ y : num 3.98 3.84 4.07 4.23 4.35 3.96 3.98 4.11 3.78 4.05 ... ## $ z : num 2.43 2.31 2.31 2.63 2.75 2.48 2.47 2.53 2.49 2.39 ... ## - attr(*, &quot;groups&quot;)=Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 5 obs. of 2 variables: ## ..$ cut : Ord.factor w/ 5 levels &quot;Fair&quot;&lt;&quot;Good&quot;&lt;..: 1 2 3 4 5 ## ..$ .rows:List of 5 ## .. ..$ : int 9 92 98 124 125 129 130 205 228 242 ... ## .. ..$ : int 3 5 11 18 19 21 36 37 38 43 ... ## .. ..$ : int 6 7 8 10 20 22 23 24 25 26 ... ## .. ..$ : int 2 4 13 15 16 27 46 54 55 57 ... ## .. ..$ : int 1 12 14 17 40 41 42 52 53 56 ... ## ..- attr(*, &quot;.drop&quot;)= logi TRUE The output of group_by() is a ‘grouped_df’ and all functions following will be applied separately to each sub-dataframe. 5.9.1 group_by() %&gt;% summarize() Returning to the above summarize() function, we can now quickly generate summary statistics for the diamonds in each clarity category by first grouping on this column name. diamond_df %&gt;% group_by(clarity) %&gt;% summarize(mean_price = mean(price), sd_price = sd(price), min_price = min(price), max_price = max(price), n_rows = n()) ## # A tibble: 8 x 6 ## clarity mean_price sd_price min_price max_price n_rows ## &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 I1 3924. 2807. 345 18531 741 ## 2 SI2 5063. 4260. 326 18804 9194 ## 3 SI1 3996. 3799. 326 18818 13065 ## 4 VS2 3925. 4042. 334 18823 12258 ## 5 VS1 3839. 4012. 327 18795 8171 ## 6 VVS2 3284. 3822. 336 18768 5066 ## 7 VVS1 2523. 3335. 336 18777 3655 ## 8 IF 2865. 3920. 369 18806 1790 Huzzah! By adding this simple command before summarize() we’ve created detailed statistics on each clarity category. We could split the input data further by grouping on more than one column. For example, what are the summary statistics for each clarity category within each cut? diamond_df %&gt;% group_by(clarity, cut) %&gt;% summarize(mean_price = mean(price), sd_price = sd(price), min_price = min(price), max_price = max(price), n_rows = n()) ## # A tibble: 40 x 7 ## # Groups: clarity [8] ## clarity cut mean_price sd_price min_price max_price n_rows ## &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 I1 Fair 3704. 3099. 584 18531 210 ## 2 I1 Good 3597. 2285. 361 11548 96 ## 3 I1 Very Good 4078. 2720. 511 15984 84 ## 4 I1 Premium 3947. 2827. 345 16193 205 ## 5 I1 Ideal 4336. 2671. 413 16538 146 ## 6 SI2 Fair 5174. 3928. 536 18308 466 ## 7 SI2 Good 4580. 3901. 335 18788 1081 ## 8 SI2 Very Good 4989. 4126. 383 18692 2100 ## 9 SI2 Premium 5546. 4488. 345 18784 2949 ## 10 SI2 Ideal 4756. 4252. 326 18804 2598 ## # … with 30 more rows We now have 40 rows of summary statistics which gives a higher-resolution representation of the input data. 5.9.2 group_by() %&gt;% mutate() As mentioned, group_by() is compatible with all other dplyr functions. Sometimes we want both the original data and the summary statistics in the output data frame. To do this, group_by() can be combined with mutate(), to make a new column of summary statistics (repeated many times) corresponding to the sub-grouping of interest. The new column of summary statistics is represented in darker colours in the right panel below. To create a column containing the mean price for diamonds in each cut category in addition to the input data, we can use group_by() before mutate(): diamond_df %&gt;% select(-x,-y,-z) %&gt;% group_by(cut) %&gt;% mutate(cut_meanprice = mean(price)) ## # A tibble: 53,940 x 8 ## # Groups: cut [5] ## carat cut color clarity depth table price cut_meanprice ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3458. ## 2 0.21 Premium E SI1 59.8 61 326 4584. ## 3 0.23 Good E VS1 56.9 65 327 3929. ## 4 0.290 Premium I VS2 62.4 58 334 4584. ## 5 0.31 Good J SI2 63.3 58 335 3929. ## 6 0.24 Very Good J VVS2 62.8 57 336 3982. ## 7 0.24 Very Good I VVS1 62.3 57 336 3982. ## 8 0.26 Very Good H SI1 61.9 55 337 3982. ## 9 0.22 Fair E VS2 65.1 61 337 4359. ## 10 0.23 Very Good H VS1 59.4 61 338 3982. ## # … with 53,930 more rows The new column now contains one of five possible values depending on the cut column. From this we could then use a second mutate() to calculate the difference between each diamond price and the mean price for its cut category: diamond_df %&gt;% select(-x,-y,-z) %&gt;% group_by(cut) %&gt;% mutate(cut_meanprice = mean(price)) %&gt;% mutate(price_diff = price - cut_meanprice) ## # A tibble: 53,940 x 9 ## # Groups: cut [5] ## carat cut color clarity depth table price cut_meanprice price_diff ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3458. -3132. ## 2 0.21 Premium E SI1 59.8 61 326 4584. -4258. ## 3 0.23 Good E VS1 56.9 65 327 3929. -3602. ## 4 0.290 Premium I VS2 62.4 58 334 4584. -4250. ## 5 0.31 Good J SI2 63.3 58 335 3929. -3594. ## 6 0.24 Very Good J VVS2 62.8 57 336 3982. -3646. ## 7 0.24 Very Good I VVS1 62.3 57 336 3982. -3646. ## 8 0.26 Very Good H SI1 61.9 55 337 3982. -3645. ## 9 0.22 Fair E VS2 65.1 61 337 4359. -4022. ## 10 0.23 Very Good H VS1 59.4 61 338 3982. -3644. ## # … with 53,930 more rows 5.9.3 ungroup() helper When running longer dplyr chains it is good practice to ungroup the data after the group_by() operations are run. To do this simply add %&gt;% ungroup() at the end of the code block. Inappropriate preservation of groupings can sometimes cause your code to run very slowly and give unexpected results. 5.9.4 count() helper count() is a shortcut function that combines group_by() and summarize(), which is useful for counting ‘character data’, e.g. labels. To quickly count the number of diamonds in each cut category: diamond_df %&gt;% count(cut) ## # A tibble: 5 x 2 ## cut n ## &lt;ord&gt; &lt;int&gt; ## 1 Fair 1610 ## 2 Good 4906 ## 3 Very Good 12082 ## 4 Premium 13791 ## 5 Ideal 21551 And to count the number of diamonds in each cut and clarity category: diamond_df %&gt;% count(cut,clarity) ## # A tibble: 40 x 3 ## cut clarity n ## &lt;ord&gt; &lt;ord&gt; &lt;int&gt; ## 1 Fair I1 210 ## 2 Fair SI2 466 ## 3 Fair SI1 408 ## 4 Fair VS2 261 ## 5 Fair VS1 170 ## 6 Fair VVS2 69 ## 7 Fair VVS1 17 ## 8 Fair IF 9 ## 9 Good I1 96 ## 10 Good SI2 1081 ## # … with 30 more rows Note that the count summary output column name is ‘n’. This reflects that count() is using a summarize(n = n()) function in the background. 5.9.5 sample_n() helper The final helper for this session is sample_n() which takes a random sample of rows according to the number specified. To sample 10 rows from the entire diamond_df dataset: diamond_df %&gt;% sample_n(10) ## # A tibble: 10 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.42 Ideal I SI1 61 56 914 4.86 4.83 2.96 ## 2 1.01 Fair F SI2 65.2 57 3837 6.33 6.24 4.1 ## 3 1.13 Premium G IF 61.2 59 9525 6.71 6.78 4.13 ## 4 0.37 Very Good H VVS1 61.9 55 774 4.6 4.66 2.86 ## 5 1.34 Premium G VS2 61 60 7780 7.13 7.07 4.33 ## 6 0.33 Ideal G VS1 61.5 56 699 4.45 4.48 2.74 ## 7 0.41 Good F SI1 63.9 56 969 4.74 4.68 3.01 ## 8 0.4 Ideal D VS2 62.8 57 1050 4.72 4.68 2.95 ## 9 0.3 Very Good H SI1 62.6 58 421 4.22 4.28 2.66 ## 10 0.31 Good H SI1 63.6 57 573 4.33 4.32 2.75 It can be more useful to sample rows from within sub-groups, by combining group_by() and sample_n(). Let’s take 2 rows at random from each cut category: diamond_df %&gt;% group_by(cut) %&gt;% sample_n(2) ## # A tibble: 10 x 10 ## # Groups: cut [5] ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1.5 Fair H I1 69.3 61 3175 6.99 6.81 4.78 ## 2 0.99 Fair J I1 73.6 60 1789 6.01 5.8 4.35 ## 3 0.580 Good F VVS2 62.2 61 2494 5.37 5.44 3.36 ## 4 0.32 Good E VS2 64.1 54 658 4.32 4.36 2.78 ## 5 0.7 Very Good I SI1 61.1 56 2021 5.74 5.75 3.51 ## 6 1.09 Very Good F VVS1 61.4 58 10463 6.6 6.65 4.07 ## 7 1.6 Premium H VS1 62.5 58 12084 7.47 7.37 4.64 ## 8 0.82 Premium E SI2 62 59 2593 6.02 5.94 3.71 ## 9 2.19 Ideal H SI2 62 56 17433 8.36 8.48 5.22 ## 10 0.33 Ideal E VS1 62.6 57 1002 4.42 4.4 2.76 5.10 Challenges What is the weight of the most expensive diamond in each clarity category? Summarize the standard deviation of diamond weight in each cut category. A z score is the (sample value - mean)/sd. Can you create a z score for the weight of each diamond relative to others of that cut? What does the density distribution of z scores look like for each cut? 5.11 Solutions diamond_df %&gt;% group_by(clarity) %&gt;% summarize(maxPrice = max(price)) ## # A tibble: 8 x 2 ## clarity maxPrice ## &lt;ord&gt; &lt;int&gt; ## 1 I1 18531 ## 2 SI2 18804 ## 3 SI1 18818 ## 4 VS2 18823 ## 5 VS1 18795 ## 6 VVS2 18768 ## 7 VVS1 18777 ## 8 IF 18806 diamond_df %&gt;% group_by(cut) %&gt;% summarize(sdWt = sd(carat)) ## # A tibble: 5 x 2 ## cut sdWt ## &lt;ord&gt; &lt;dbl&gt; ## 1 Fair 0.516 ## 2 Good 0.454 ## 3 Very Good 0.459 ## 4 Premium 0.515 ## 5 Ideal 0.433 weight_z &lt;- diamond_df %&gt;% group_by(cut) %&gt;% mutate(meanWt=mean(carat), sdWt = sd(carat), z = (carat - meanWt)/sdWt) weight_z %&gt;% ggplot(aes(x=z)) + geom_density(aes(col=cut)) 5.12 Summary Now you have worked through the key verbs of dplyr, and the associated helper functions which, together, allow you to efficiently subset, transform and summarize your data. Whereas the diamond_df and mpg_df dataframes we have worked with so far are self-contained, readily available within R and clean, in the next chapter we will learn to read in external datasets, join different datasets and clean data. 5.13 Extra resources There are several great resources for consolidating and building on the material above. R for Data Science Ch. 5 ‘Data transformation’ Tidyverse resources Introduction to open data science (Ocean Health Index) Jenny Bryan’s STAT545 course notes "],
["week-3.html", "Week 3", " Week 3 "],
["reading-tidying-joining-data.html", "6 Reading, tidying &amp; joining data 6.1 Reading in data 6.2 Reshaping data 6.3 Separating and uniting columns 6.4 Removing variables 6.5 Joining dataframes 6.6 Plotting challenge 6.7 Solution 6.8 Summary", " 6 Reading, tidying &amp; joining data This session will focus on reading information into R and ‘tidying’ it into a form that makes manipulation and plotting as easy as possible. The tidyr functions within the eponymous tidyverse are designed to help users to convert data into a ‘tidy format’. There are three simple principals for tidy data: each column represents a single measurement type each row represents a single observation each cell contains a single value The context for this session is that your colleague hears that you have successfully completed the first sessions of the WEHI tidyverse R course 😊, and asks you to plot some data for their upcoming lab talk. They send you results from a differential gene expression experiment, and want you to plot the significant genes according to their Gene Ontology (GO) terms. They send you four files: entrez_logFC.xlsx, a results table containing the entrez gene ID, log2 fold-change (logFC) and adjusted P value for each significant gene (Microsoft Excel format) Hs_entrez_annot.csv, the gene names and descriptions for each entrez gene ID (comma-separated values) GO_entrez.txt, the entrez IDs corresponding to different GO terms (space-separated values); and, GO_term_defin.tsv, a table of descriptions for each GO term (tab-separated values) To access these files, download and unzip this folder into your Desktop WEHI_tidyR_course folder. Feel free to open the text files (.csv ; .txt ; .tsv) in TextEdit or another editor to see the data, but make sure not to make any changes. Unfortunately not all of the files come in a tidy form, so we will need to improve them according to the tidy data principals using the functions below, and then join them together to make the final plot. First let’s create a new .R text file, save as ‘Week_3_tidyverse.R’ in the WEHI_tidyR_course folder, and load the tidyverse package library(tidyverse) Now we can read the data files into R. 6.1 Reading in data 6.1.1 read_excel() Broadly speaking there are two ways to read an excel file into R. You can click ‘Import Dataset’ in the Environment tab (top right pane) &gt;&gt; ‘From Excel…’ &gt;&gt; ‘Browse…’ &gt;&gt; navigate to your WEHI_tidyR_course folder and select the file ‘entrez_logFC.xlsx’. In the ‘Options’ section check ‘First row as names’, then click ‘Import’. The excel table is now imported into a variable called ‘entrez_logFC’ and you will see that code appears in the console similar to this: library(readxl) entrez_logFC &lt;- read_excel(&quot;~/Desktop/WEHI_tidyR_course/data_files/entrez_logFC.xlsx&quot;) You can copy and paste this code into your R text file so that next time you run your code, the table is imported without you having to go through the point-and-click route. The alternative way is to directly type and run the code as it appears above. Your colleague has also provide text files in the form of csv (comma-separated values), tsv (tab-separated values), and txt (space-separated values), which require slightly different read functions. 6.1.2 read_csv() The read_csv() function from tidyr is used when you select ‘Import Dataset’ &gt;&gt; ‘From text (readr)…’ and set the ‘Import Options’ Delimeter to ‘comma’. Alternatively you can directly call read_csv() as follows, and assign the output into a new variable ‘Hs_entrez_annot’ Hs_entrez_annot &lt;- read_csv(&quot;~/Desktop/WEHI_tidyR_course/data_files/Hs_entrez_annot.csv&quot;) ## Parsed with column specification: ## cols( ## entrez_id = col_double(), ## annot_type = col_character(), ## annot_text = col_character() ## ) This message indicates the names and type of data that has been assigned for each column. col_double() denotes a type of numeric data. 6.1.3 read_delim() For the white space-separated file “GO_entrez.txt” (which is far from tidy), it is best to use a more flexible read function called read_delim(). This function allows us to directly specify the delimiter (i.e., the character used to separate the columns). In this case we will use delim=' ' to indicate that the columns are separated by a white space, and assign the output into a new variable ‘GO_entrez’ GO_entrez &lt;- read_delim(&#39;~/Desktop/WEHI_tidyR_course/data_files/GO_entrez.txt&#39;, delim = &#39; &#39;) ## Parsed with column specification: ## cols( ## rowname = col_double(), ## go_entrez = col_character() ## ) We can see that the GO_entrez variable contains two columns, ‘rowname’ and ‘go_entrez’. 6.1.4 read_tsv() Lastly we will read the “GO_term_defin.tsv” which is tab-separated (aka ‘tab-delimited’), using read_tsv(). The data will be assigned to a new variable ‘GO_terms’ GO_terms &lt;- read_tsv(&#39;~/Desktop/WEHI_tidyR_course/data_files/GO_term_defin.tsv&#39;) ## Parsed with column specification: ## cols( ## GOID = col_character(), ## DEFINITION = col_character(), ## BP = col_character(), ## CC = col_character(), ## MF = col_character() ## ) We see that the new variable contains a dataframe with five columns, all of which are character data. Note that this tsv file could also be read in using read_delim(), specifying the tab delimeter as delim = '\\t'. The .csv file could be read using the same function, with delim = ','. 6.2 Reshaping data Let’s have a look at the newly created dataframes. Starting with entrez_logFC entrez_logFC %&gt;% head() ## # A tibble: 6 x 3 ## entrez_id logFC adj_Pval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 722 3.54 0.00113 ## 2 725 5.62 0.0295 ## 3 1378 3.46 0.0315 ## 4 2302 3.37 0.0486 ## 5 5777 3.93 0.0204 ## 6 55061 2.76 0.0225 This dataframe conforms to the tidy data principals. Each row represents an ‘observation’ (a different entrez gene ID), and each column represents a different measurement type (log fold-change in RNA abundance, and adjusted p. value). Further, each cell contains a single value. This is what we are aiming for with the other data sets. Now to check Hs_entrez_annot Hs_entrez_annot %&gt;% head() ## # A tibble: 6 x 3 ## entrez_id annot_type annot_text ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 21 symbol ABCA3 ## 2 21 gene_name ATP binding cassette subfamily A member 3 ## 3 90 symbol ACVR1 ## 4 90 gene_name activin A receptor type 1 ## 5 91 symbol ACVR1B ## 6 91 gene_name activin A receptor type 1B This is not tidy, because each observation (the entrez_id) is duplicated into 2 rows. The annotation type (‘annot_type’: symbol or gene name) should ideally be individual columns, containing the correpsonding annotation_text (‘annot_text’). 6.2.1 pivot_wider() To modify this table so that it conforms to the tidy principals, we need to ‘reshape’ it. We need a function that can convert the labels in the ‘annot_type’ column into two new column names, and assort the data in ‘annot_text’ according to their respective new column names. The function for this job is pivot_wider() thinkr.fr/wp-content/uploads/long_wide.png pivot_wider() requires two commands, both of which are column names in the original table. names_from indicates the column containing the labels which will be come the new column names. values from indicates the column containing the values that will populate the the new columns. To transform the illustrative table above at left (df_long) into the result at right, would require: df_long %&gt;% pivot_wider(names_from = V1, values_from = V2). Note that the ‘shape’ of the dataframe is being converted from longer (more rows) to wider (more columns). In our case, to reshape Hs_entrez_annot, we will use the column names annot_type, and annot_text: Hs_entrez_annot %&gt;% pivot_wider(names_from = annot_type, values_from = annot_text) ## # A tibble: 153 x 3 ## entrez_id symbol gene_name ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 21 ABCA3 ATP binding cassette subfamily A member 3 ## 2 90 ACVR1 activin A receptor type 1 ## 3 91 ACVR1B activin A receptor type 1B ## 4 156 ADRBK1 adrenergic, beta, receptor kinase 1 ## 5 207 AKT1 v-akt murine thymoma viral oncogene homolog 1 ## 6 566 AZU1 azurocidin 1 ## 7 596 BCL2 B-cell CLL/lymphoma 2 ## 8 655 BMP7 bone morphogenetic protein 7 ## 9 722 C4BPA complement component 4 binding protein alpha ## 10 725 C4BPB complement component 4 binding protein beta ## # … with 143 more rows Whereas the original table has 306 rows, the output of pivot_wider() has only 153 rows. This is because the rows are de-duplicated as the new columns are created. Given that the output is in ‘tidy’ format, we can assign it to a new variable ‘Hs_entz_annot_tidy’ Hs_entz_annot_tidy &lt;- Hs_entrez_annot %&gt;% pivot_wider(names_from = annot_type, values_from = annot_text) Note that because we only have two labels in the annot_type column, we are replacing the existing two columns with only two new columns. As such the shape of the output technically isnt any wider than the input dataframe. However when there are more than two unique labels in the names_from column, the output will be wider than the input. 6.2.2 pivot_longer() The function that complements pivot_wider() is of course pivot_longer(). This function does not create tidy data, because it duplicates rows. However the ‘long format’ output from pivot_longer() is often required for ggplot, where each aesthetic or facet category must be a single column of values; and for left_join(), introduced below. thinkr.fr/wp-content/uploads/wide_long.png pivot_longer() takes three commands, specifying a vector of the names of the columns to convert to labels in long form cols =, a name for the new column containing the labels from 1: names_to =, a name for the new column containing the values corresponding to 1: values_to = Note that pivot_wider(), requires the new column names in quotes. So for the figure above, to convert from the left table (df_wide) to the long table at right, would require: df_wide %&gt;% pivot_longer(cols = c(X2,X3,X4), names_to = 'V1', values_to = 'V2') Let’s see how this can be applied to the GO_terms dataframe GO_terms ## # A tibble: 12 x 5 ## GOID DEFINITION BP CC MF ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 GO:190… Any process that stops, p… negative regulation … &lt;NA&gt; &lt;NA&gt; ## 2 GO:004… The directed movement of … vesicle transport al… &lt;NA&gt; &lt;NA&gt; ## 3 GO:001… The phosphorylation of pe… peptidyl-threonine p… &lt;NA&gt; &lt;NA&gt; ## 4 GO:000… Any process that stops, p… negative regulation … &lt;NA&gt; &lt;NA&gt; ## 5 GO:006… The series of molecular s… Wnt signaling pathwa… &lt;NA&gt; &lt;NA&gt; ## 6 GO:000… The chemical reactions an… ubiquinone metabolic… &lt;NA&gt; &lt;NA&gt; ## 7 GO:009… The lipid bilayer surroun… &lt;NA&gt; lamella… &lt;NA&gt; ## 8 GO:001… The cell cycle process in… female meiosis chrom… &lt;NA&gt; &lt;NA&gt; ## 9 GO:003… Catalysis of the transfer… &lt;NA&gt; &lt;NA&gt; kynurenine … ## 10 GO:190… Any process that activate… positive regulation … &lt;NA&gt; &lt;NA&gt; ## 11 GO:001… The chemical reactions an… fucose catabolic pro… &lt;NA&gt; &lt;NA&gt; ## 12 GO:004… Catalysis of the reaction… &lt;NA&gt; &lt;NA&gt; cysteine-S-… The BP, CC and MF columns relate to ‘Biological Process’, ‘Cellular Component’ and ‘Molecular Function’ ontologies within the Gene Ontology framework. We can see there are many NA values in these columns, as each GOID relates to a single type of ontology. That is, if there is text in BP, then CC and MF will be NA values. If we consider the text in this table as individual ‘values’ then the table is technically tidy, but the information is sparsely populated throughout. To eliminate the NA values we first use pivot_longer(), with the aim of converting to long format those columns containing ontology descriptions: BP,CC, and MF. The new column for labels will be ‘ONTOLOGY’, and the new column containing the associated text will be ‘DESCRIPTION’ GO_terms %&gt;% pivot_longer(cols = c(BP,CC,MF), names_to = &#39;ONTOLOGY&#39;, values_to = &#39;DESCRIPTION&#39;) ## # A tibble: 36 x 4 ## GOID DEFINITION ONTOLOGY DESCRIPTION ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 GO:190… Any process that stops, preve… BP negative regulation of vesicl… ## 2 GO:190… Any process that stops, preve… CC &lt;NA&gt; ## 3 GO:190… Any process that stops, preve… MF &lt;NA&gt; ## 4 GO:004… The directed movement of a ve… BP vesicle transport along micro… ## 5 GO:004… The directed movement of a ve… CC &lt;NA&gt; ## 6 GO:004… The directed movement of a ve… MF &lt;NA&gt; ## 7 GO:001… The phosphorylation of peptid… BP peptidyl-threonine phosphoryl… ## 8 GO:001… The phosphorylation of peptid… CC &lt;NA&gt; ## 9 GO:001… The phosphorylation of peptid… MF &lt;NA&gt; ## 10 GO:000… Any process that stops, preve… BP negative regulation of humora… ## # … with 26 more rows Now the data is in long form, with the GOID and DEFINITION columns duplicated. All of the NA values are now in a single column (DESCRIPTION). We can easily filter out these NA values, and assign the new dataframe to a variable ‘GO_terms_long’ GO_terms_long &lt;- GO_terms %&gt;% pivot_longer(cols = c(BP, CC, MF), names_to = &#39;ONTOLOGY&#39;, values_to = &#39;DESCRIPTION&#39;) %&gt;% filter(!is.na(DESCRIPTION)) Importantly, in cases where there are 10s of column names to convert to long format, it is simpler to use cols = to specify those columns that we don’t want to convert, which are usually the left-most columns. This is done with the - symbol we previously used with select(), and for negative vector sub-setting. To achieve the same result as above using this approach: GO_terms_long &lt;- GO_terms %&gt;% pivot_longer(cols = -c(GOID, DEFINITION), names_to = &#39;ONTOLOGY&#39;, values_to = &#39;DESCRIPTION&#39;) %&gt;% filter(!is.na(DESCRIPTION)) cols can also take the other helpers used with select(), such as starts_with(), contains() etc. 6.3 Separating and uniting columns So far we have reshaped data where the input conforms to the third principal of ‘tidiness’: each cell contains a single value. When this is not the case, we may need to split values into several columns, using separate(); or combine values into a single column using unite(). GO_entrez is certainly the messiest of the datasets we have been provided. Let’s take look: GO_entrez %&gt;% head() ## # A tibble: 6 x 2 ## rowname go_entrez ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 GO_0002924_722,725,1378,2302,5777,55061 ## 2 2 GO_0006743_3156,4704,10229,23590,27235,29914,51004,51117,51805,56997,5… ## 3 3 GO_0016321_4292,5347,728637 ## 4 4 GO_0018107_90,91,156,207,566,596,655,790,801,805,808,817,983,1020,1111… ## 5 5 GO_0019317_2523,2524,2526,2527,2528,2529,2530,10690,84750 ## 6 6 GO_0036137_883,2806,51166,56267 The dataframe has two columns: ‘rownames’ which is a meaningless sequence of integers, and ‘go_entrez’ which appears to contain GO IDs interspersed with underscores, and a long string of comma-separated entrez IDs. We will need to make several changes to produce a long-format table of GO terms and corresponding entrez IDs in consecutive rows. First, we should separate the go_entrez column into three, containing the ‘GO’ prefix, the code, and the string of entrez IDs. 6.3.1 separate() The tidyr separate() function takes a column name as the first command, and separates it into a number of new columns (a vector of names of our choosing, in quotes), according to a particular character delimiter, the ‘separator’ or ‘sep’. The sep = command has the same role as delim = in read_delim() above. Let’s split the go_entrez column into three new columns named ‘prefix’,‘code_only’ and ‘entrez_multi’, according to the underscore _ character: GO_entrez %&gt;% separate(go_entrez, into = c(&#39;prefix&#39;,&#39;code_only&#39;,&#39;entrez_multi&#39;), sep = &#39;_&#39;) ## # A tibble: 11 x 4 ## rowname prefix code_only entrez_multi ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 GO 0002924 722,725,1378,2302,5777,55061 ## 2 2 GO 0006743 3156,4704,10229,23590,27235,29914,51004,51117,51805,… ## 3 3 GO 0016321 4292,5347,728637 ## 4 4 GO 0018107 90,91,156,207,566,596,655,790,801,805,808,817,983,10… ## 5 5 GO 0019317 2523,2524,2526,2527,2528,2529,2530,10690,84750 ## 6 6 GO 0036137 883,2806,51166,56267 ## 7 7 GO 0047496 1176,1201,1780,2647,3064,3799,5048,5590,5861,6845,81… ## 8 8 GO 0061289 2625,55366 ## 9 9 GO 0097232 21,27074 ## 10 10 GO 1901609 254263 ## 11 11 GO 1903638 9141 Note that the code_only column contains only integers but remains encoded as ‘character data’. Its possible to allow R to guess the data types for newly created columns by including convert = TRUE at the end of the above command. Here however we want to preserve the leading 0s in code_only which would be dropped if this column was converted to the numeric data type. Let’s store the output of separate() as a new variable named ‘GO_entrez_sep’ GO_entrez_sep &lt;- GO_entrez %&gt;% separate(go_entrez, into = c(&#39;prefix&#39;,&#39;code_only&#39;,&#39;entrez_multi&#39;), sep = &#39;_&#39;) Next we have to deal with the long string of entrez IDs in the ‘entrez_multi’ column. This is particularly tricky as there are uneven numbers of entrez IDs associated with each GO term. A separate() function will run in to problems when columns are highly uneven, and the maximum length of values is unknown. 6.3.2 str_split() %&gt;% unnest() Alternatively, we can use a pair of functions called str_split() and unnest() to quickly solve the problem. str_split() stands for ‘string_split’ which relates to splitting a long sequence of characters (aka a ‘string’) according to a particular delimiter. str_split() is similar to separate(), but instead of creating new columns, it creates a ‘nested list’ of values which are hidden from us. To split up the values according to a particular delimeter we use pattern =, which functions similarly to separate() sep = and read_delim() delim =. The unnest() command that follows inserts each value in the nested list (corresponding to individual entrez IDs in our case) into is own row, and duplicates the data in other columns. In this way, unnest() essentially performs a pivot_longer() function in order to reveal all of the previously hidden values. Whereas the nested values aren’t visible in the console output, you can see them presented as a vector if you pipe your output to View(). First we give the str_split() command inside mutate() to create a new column containing the nested list of entrez IDs. GO_entrez_sep %&gt;% mutate(entz_nest = str_split(entrez_multi, pattern = &#39;,&#39;)) ## # A tibble: 11 x 5 ## rowname prefix code_only entrez_multi entz_nest ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;list&gt; ## 1 1 GO 0002924 722,725,1378,2302,5777,55061 &lt;chr [6]&gt; ## 2 2 GO 0006743 3156,4704,10229,23590,27235,29914,51004,51… &lt;chr [13… ## 3 3 GO 0016321 4292,5347,728637 &lt;chr [3]&gt; ## 4 4 GO 0018107 90,91,156,207,566,596,655,790,801,805,808,… &lt;chr [79… ## 5 5 GO 0019317 2523,2524,2526,2527,2528,2529,2530,10690,8… &lt;chr [9]&gt; ## 6 6 GO 0036137 883,2806,51166,56267 &lt;chr [4]&gt; ## 7 7 GO 0047496 1176,1201,1780,2647,3064,3799,5048,5590,58… &lt;chr [35… ## 8 8 GO 0061289 2625,55366 &lt;chr [2]&gt; ## 9 9 GO 0097232 21,27074 &lt;chr [2]&gt; ## 10 10 GO 1901609 254263 &lt;chr [1]&gt; ## 11 11 GO 1903638 9141 &lt;chr [1]&gt; Now we can drop the entrez_multi column because we have captured it in entz_nest, and check the output using View() GO_entrez_sep %&gt;% mutate(entz_nest = str_split(entrez_multi, pattern = &#39;,&#39;)) %&gt;% select( -entrez_multi ) %&gt;% View() Finally we can unnest() the entz_nest column, using col = entz_nest, which produces a long-form table GO_entrez_sep %&gt;% mutate(entz_nest = str_split(entrez_multi, pattern = &#39;,&#39;)) %&gt;% select( -entrez_multi ) %&gt;% unnest(col = entz_nest) ## # A tibble: 155 x 4 ## rowname prefix code_only entz_nest ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 GO 0002924 722 ## 2 1 GO 0002924 725 ## 3 1 GO 0002924 1378 ## 4 1 GO 0002924 2302 ## 5 1 GO 0002924 5777 ## 6 1 GO 0002924 55061 ## 7 2 GO 0006743 3156 ## 8 2 GO 0006743 4704 ## 9 2 GO 0006743 10229 ## 10 2 GO 0006743 23590 ## # … with 145 more rows 6.3.3 rename() Given that the entz_nest colum is no longer a nested list, we might want to rename it. The rename() function can help here. It simply takes the form ‘new column name’ = ‘existing name’: GO_entrez_sep %&gt;% mutate(entz_nest = str_split(entrez_multi, pattern = &#39;,&#39;)) %&gt;% select( -entrez_multi ) %&gt;% unnest(col = entz_nest) %&gt;% rename(entrez_id = entz_nest) ## # A tibble: 155 x 4 ## rowname prefix code_only entrez_id ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 GO 0002924 722 ## 2 1 GO 0002924 725 ## 3 1 GO 0002924 1378 ## 4 1 GO 0002924 2302 ## 5 1 GO 0002924 5777 ## 6 1 GO 0002924 55061 ## 7 2 GO 0006743 3156 ## 8 2 GO 0006743 4704 ## 9 2 GO 0006743 10229 ## 10 2 GO 0006743 23590 ## # … with 145 more rows We can write the results of this chain of commands into a new variable ‘GO_entrez_sep_long’ GO_entrez_sep_long &lt;- GO_entrez_sep %&gt;% mutate(entz_nest = str_split(entrez_multi, pattern = &#39;,&#39;)) %&gt;% select( -entrez_multi ) %&gt;% unnest(col = entz_nest) %&gt;% rename(entrez_id = entz_nest) 6.3.4 unite() The final step is to combine the GO prefix (‘GO’) and the code_only columns to produce a GO ID in the same form as that in the GOID column of GO_terms_long (created above). To check the desired output: GO_terms_long %&gt;% select(GOID) ## # A tibble: 12 x 1 ## GOID ## &lt;chr&gt; ## 1 GO:1901609 ## 2 GO:0047496 ## 3 GO:0018107 ## 4 GO:0002924 ## 5 GO:0061289 ## 6 GO:0006743 ## 7 GO:0097232 ## 8 GO:0016321 ## 9 GO:0036137 ## 10 GO:1903638 ## 11 GO:0019317 ## 12 GO:0047804 The unite() function is the complement of separate(), and requires two arguments: a name for the new column that will contain the united values, and a vector of the names of the columns to unite. We can optionally provide a separator (sep =) to insert between the combined values. If we don’t add a command here the values will be separated by underscores _. In this case we want to insert a colon : to reproduce the desired GOID GO_entrez_sep_long %&gt;% unite(GOID, c(prefix, code_only), sep=&quot;:&quot;) ## # A tibble: 155 x 3 ## rowname GOID entrez_id ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 GO:0002924 722 ## 2 1 GO:0002924 725 ## 3 1 GO:0002924 1378 ## 4 1 GO:0002924 2302 ## 5 1 GO:0002924 5777 ## 6 1 GO:0002924 55061 ## 7 2 GO:0006743 3156 ## 8 2 GO:0006743 4704 ## 9 2 GO:0006743 10229 ## 10 2 GO:0006743 23590 ## # … with 145 more rows Now we can drop the meaningless rowname column, store the result as “GO_entrez_long”, and we’re finally done with GO_entrez! GO_entrez_long &lt;- GO_entrez_sep_long %&gt;% unite(GOID, c(prefix, code_only), sep=&quot;:&quot;) %&gt;% select(-rowname) 6.4 Removing variables In the process of tidying up the data we created several variables in intermediates states of completeness. We can now remove these variables together with the original untidy input data, using the rm() function. Happily because all of our commands are saved in a text file (and backed up!!) we can reproduce these variables later on if required. rm(Hs_entrez_annot) rm(GO_terms) rm(GO_entrez) rm(GO_entrez_sep) rm(GO_entrez_sep_long) 6.5 Joining dataframes Now that we have converted the three untidy input datasets into tidy format (Hs_entz_annot_tidy), or long format (GO_entrez_long, GO_terms_long) we can begin joining them together into a single dataframe from which to plot the fold-change per gene, coloured by GO term. 6.5.1 left_join() Joining two or more different datasets can be a very tricky task in standard spreadsheeting programs, but is vastly simplified in the tidyverse. The main requirement is to have a ‘joint key’, that is, a column in both dataframes that contains at least one identical value. left_join() is the workhorse of the tidy R joining functions, so called because the first dataframe that is specified (in code from left to right) appears in the left-most columns of the resulting dataframe. In the image below, the dataframe ‘b’ is being joined to ‘a’ using left_join(), and the ‘joint key’ is x1. Note that the x1 column contains two identical values (A and B), but C is unique to ‘a’ and D is unique to ‘b’. The output of left_join(), will contain the entire left-side dataframe (‘a’), and the additional columns from ‘b’ populated with values for all rows where the joint key is matching. NA will appear in cells for which there is no match in ‘b’. The other important thing about left_join() is that any rows where the joint key is duplicated in the right-side dataframe, will also be duplicated in the left-side. For example, if ‘b’ contained the rows ‘B’ ‘F’ ‘B’ ‘T’ then the result would include the rows ‘B’ ‘2’ ‘F’ ‘B’ ‘2’ ‘T’ Our first task is to join the the entrez_logFC results table with the gene annotations in Hs_entz_annot_tidy. We will use the joint key ‘entrez_id’. Consistent with the previous sections, we will use the pipe %&gt;% to ‘send’ the left-side dataframe (entrez_logFC) into a left_join() where we specify the right-side dataframe. We give the column name of the joint key, in quotes, in the by = command. entrez_logFC %&gt;% left_join(Hs_entz_annot_tidy, by = &#39;entrez_id&#39;) ## # A tibble: 19 x 5 ## entrez_id logFC adj_Pval symbol gene_name ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 722 3.54 0.00113 C4BPA complement component 4 binding protein alpha ## 2 725 5.62 0.0295 C4BPB complement component 4 binding protein beta ## 3 1378 3.46 0.0315 CR1 complement component 3b/4b receptor 1 (Knops… ## 4 2302 3.37 0.0486 FOXJ1 forkhead box J1 ## 5 5777 3.93 0.0204 PTPN6 protein tyrosine phosphatase, non-receptor t… ## 6 55061 2.76 0.0225 SUSD4 sushi domain containing 4 ## 7 2523 -1.53 0.00091 FUT1 fucosyltransferase 1 (H blood group) ## 8 2524 -1.38 0.0434 FUT2 fucosyltransferase 2 ## 9 2526 -1.46 0.0268 FUT4 fucosyltransferase 4 ## 10 2527 -0.930 0.00605 FUT5 fucosyltransferase 5 ## 11 2528 -2.91 0.0494 FUT6 fucosyltransferase 6 ## 12 2529 -0.767 0.0185 FUT7 fucosyltransferase 7 (alpha (1,3) fucosyltra… ## 13 2530 -0.705 0.0213 FUT8 fucosyltransferase 8 (alpha (1,6) fucosyltra… ## 14 10690 -1.32 0.0396 FUT9 fucosyltransferase 9 (alpha (1,3) fucosyltra… ## 15 84750 -0.756 0.00960 FUT10 fucosyltransferase 10 (alpha (1,3) fucosyltr… ## 16 883 9.95 0.0483 CCBL1 cysteine conjugate-beta lyase, cytoplasmic ## 17 2806 4.26 0.0179 GOT2 glutamic-oxaloacetic transaminase 2 ## 18 51166 4.1 0.0417 AADAT aminoadipate aminotransferase ## 19 56267 3.73 0.0406 CCBL2 cysteine conjugate-beta lyase 2 The result contains the symbols and gene_names columns from Hs_entz_annot_tidy, appended to the entire entrez_logFC dataframe. We will store this result in a new variable ‘entrez_logFC_annot’ entrez_logFC_annot &lt;- entrez_logFC %&gt;% left_join(Hs_entz_annot_tidy, by = &#39;entrez_id&#39;) Let’s try the second of three left_join()s required to complete the data set. We will use the same code to join entrez_logFC_annot and GO_entrez_long, also using ‘entrez_id’ as the joint key. entrez_logFC_annot %&gt;% left_join(GO_entrez_long, by = &#39;entrez_id&#39;) ## Error: Can&#39;t join on &#39;entrez_id&#39; x &#39;entrez_id&#39; because of incompatible types (character / numeric) Okay that didnt work 😬 It looks like somewhere along the line the entrez_id in GO_entrez_long was converted from numeric data into character data. The joint key has to contain at least one identical value, down to the data type. To remedy this we will use mutate() to convert the entrez_id column in GO_entrez_long into numeric data, and overwrite the variable. GO_entrez_long &lt;- GO_entrez_long %&gt;% mutate(entrez_id = as.numeric(entrez_id)) ! Always be careful when overwriting variables. If you make a mistake it can produce incorrect results downstream. Now let’s try the left_join() using the identical data type for the joint key. entrez_logFC_annot %&gt;% left_join(GO_entrez_long, by = &#39;entrez_id&#39;) ## # A tibble: 19 x 6 ## entrez_id logFC adj_Pval symbol gene_name GOID ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 722 3.54 0.00113 C4BPA complement component 4 binding prote… GO:000… ## 2 725 5.62 0.0295 C4BPB complement component 4 binding prote… GO:000… ## 3 1378 3.46 0.0315 CR1 complement component 3b/4b receptor … GO:000… ## 4 2302 3.37 0.0486 FOXJ1 forkhead box J1 GO:000… ## 5 5777 3.93 0.0204 PTPN6 protein tyrosine phosphatase, non-re… GO:000… ## 6 55061 2.76 0.0225 SUSD4 sushi domain containing 4 GO:000… ## 7 2523 -1.53 0.00091 FUT1 fucosyltransferase 1 (H blood group) GO:001… ## 8 2524 -1.38 0.0434 FUT2 fucosyltransferase 2 GO:001… ## 9 2526 -1.46 0.0268 FUT4 fucosyltransferase 4 GO:001… ## 10 2527 -0.930 0.00605 FUT5 fucosyltransferase 5 GO:001… ## 11 2528 -2.91 0.0494 FUT6 fucosyltransferase 6 GO:001… ## 12 2529 -0.767 0.0185 FUT7 fucosyltransferase 7 (alpha (1,3) fu… GO:001… ## 13 2530 -0.705 0.0213 FUT8 fucosyltransferase 8 (alpha (1,6) fu… GO:001… ## 14 10690 -1.32 0.0396 FUT9 fucosyltransferase 9 (alpha (1,3) fu… GO:001… ## 15 84750 -0.756 0.00960 FUT10 fucosyltransferase 10 (alpha (1,3) f… GO:001… ## 16 883 9.95 0.0483 CCBL1 cysteine conjugate-beta lyase, cytop… GO:003… ## 17 2806 4.26 0.0179 GOT2 glutamic-oxaloacetic transaminase 2 GO:003… ## 18 51166 4.1 0.0417 AADAT aminoadipate aminotransferase GO:003… ## 19 56267 3.73 0.0406 CCBL2 cysteine conjugate-beta lyase 2 GO:003… Now we have a GO ID column, the gene annotations and the original entrez_logFC data. Let’s store the result of left_join() as a variable ‘entrez_logFC_GO’ entrez_logFC_GO &lt;- entrez_logFC_annot %&gt;% left_join(GO_entrez_long, by = &#39;entrez_id&#39;) Finally, we will create a variable ‘complete_table’ by joining in the GO term descriptions in GO_terms_long. This time, the joint key will be the ‘GOID’ column complete_table &lt;- entrez_logFC_GO %&gt;% left_join(GO_terms_long, by = &#39;GOID&#39;) 6.6 Plotting challenge With the input data tidied and joined we have all of the information required to make a nice plot illustrating the change in gene expression for genes beloning to different Gene Ontolgies. Your colleague has sketched out an idea for a plot. Can you now produce the plot below using complete_table and ggplot? 6.7 Solution complete_table %&gt;% ggplot(aes(x = symbol, y = logFC)) + geom_col(aes(fill = DESCRIPTION), show.legend = FALSE) + geom_hline(yintercept = 0, lty=2) + facet_wrap(~DESCRIPTION, scales=&#39;free_y&#39;, ncol=1) + ylim(-10,10) + coord_flip() 6.8 Summary Once you have finished the ☕ your grateful colleague has bought you, consider the skills you have acquired so far. You can make a wide variety of plots from datasets large and small; subset, transform and summarize data with dplyr, and tidy and join uncooperative datasets. Together these skills allow you to answer interesting questions about your data more quickly, and if necessary, reproduce hours of work instantly and exactly. The final piece of the puzzle is to be able to automate the drudge work of cleaning data and running the same analysis on multiple data sets — the subject of Week 4. "]
]
