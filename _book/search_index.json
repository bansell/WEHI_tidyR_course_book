[["index.html", "Introduction to R - tidyverse Preface How to use this book Before we begin", " Introduction to R - tidyverse Brendan R. E. Ansell @ansellbr3 Preface This document contains the material covered in the Introduction to R (tidyverse) course taught at the Walter and Eliza Hall Institute of Medical Research. The course is taught to biomedical scientists, but the material and the teaching examples are very broad. Skills taught in this workshop can be applied to many disciplines in academia and industry. There is no assumed knowledge of R or other computer languages - we start from scratch. Chapters 1 through 5 make use of popular (non-biological) teaching data sets available through R. Chapters 6 onwards introduce some types biological data. Our aim with this material is to improve the transparency, reproducibility and efficiency of scientific research by enabling scientists to conduct data analysis and visualization in R. This material is designed to be taught in a workshop setting over consecutive weeks, however we have now made it available online for those who cannot attend the workshop, or want to refresh or develop their skills. The majority of this material is inspired by / modified from from the excellent book R for Data Science by Hadley Wickham &amp; Garrett Grolemund. I thank WEHI for supporting this initiative, and the Melbourne University Research Platforms Unit, Prof. Melanie Bahlo, A/Prof. Marnie Blewitt, A/Prof. Anne Voss, Dr Luke Gandolfo, Dr Saskia Freytag, Stuart Lee, Shian Su and Jacob Munro who helped with discussion and development of this material. Thanks also to Kerry Ko and all of the tutors who have helped to organise, teach and promote the course. How to use this book To get the most out of this book, I encourage beginners to get your hands dirty with the actual work of coding in R. To do this its best to open a .R text file in RStudio (introduced in chapter 1) and type the code, presented in this book in grey boxes, directly into your text file. This ‘learning by doing’ is vastly more effective than just copying and pasting the code blocks. Furthermore, once you get more comfortable with coding in R, you can try to play around with the code (aka ‘reverse engineer’) to see what works, and whether you can fix it when it breaks. Remember you can always revert to the working code examples. Its normal to hit hurdles and experience frustration when learning a new language, which is essentially what you are doing here. WEHI staff and students who have run into R problems are encouraged to attend the R hacky hour drop-in sessions on Thursdays fortnightly in the tearoom, and all readers can get help through online resources listed in the text. I hope that the satisfaction of improving your skills, and the efficiencies you will gain in your work, will make persevering with R both worthwhile and enjoyable. Before we begin In order to use R interactively and easily, participants will need to install R and then download the RStudio software. More detailed instructions are available here. "],["week-1-part-1.html", "Week 1. Part 1", " Week 1. Part 1 "],["welcome-to-r.html", "1 Welcome to R! 1.1 A look around RStudio 1.2 Console Pane 1.3 Environment/History Pane 1.4 Plotting Pane 1.5 Open a new R script 1.6 Comments 1.7 Executing commands 1.8 Simple maths in R 1.9 Help!! 1.10 Variables 1.11 Vectors 1.12 Packages 1.13 The pipe %&gt;% 1.14 Data frames", " 1 Welcome to R! R is a computer programming language that is increasingly used for ‘data science’, that is, the manipulation, summarization, and visualization of large datasets. Data comes in many shapes and sizes, however this course is designed to teach you the skills to work with tabular data (rows and columns) such as is often handled in Microsoft Excel. An example of ‘tabular data’ is shown below. This data concerns different models of car, which we will return to later. ## # A tibble: 6 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 auto(l5) f 18 29 p compact ## 2 audi a4 1.8 1999 4 manual(m5) f 21 29 p compact ## 3 audi a4 2 2008 4 manual(m6) f 20 31 p compact ## 4 audi a4 2 2008 4 auto(av) f 21 30 p compact ## 5 audi a4 2.8 1999 6 auto(l5) f 16 26 p compact ## 6 audi a4 2.8 1999 6 manual(m5) f 18 26 p compact 1.1 A look around RStudio To get the best out of R, we recommend using the RStudio software which you should now have installed on your computer. Open RStudio. You will see 3 windows (aka ‘panes’). Each window has a different function. 1.2 Console Pane On the left hand side you have the ‘console’. You can enter commands (code that R can ‘understand’) in this window, and you will get a response to your commands (‘output’) here too. The console is useful for trying out code, but will not save any of your code, so we don’t recommend that you use it exclusively. 1.3 Environment/History Pane At the top right is the environment pane. Data that you create, or that you import from other places, will be listed here. This data is available for you to access at any time while your RStudio session is open. It is therefore said to be ‘in the working environment.’ The History pane contains a list of commands you have previously entered. 1.4 Plotting Pane At the bottom right is the plotting (‘Plots’) pane. Here you can immediately see the results of the R code you use to make graphs/charts. There are other tabs here as well which we will introduce later. 1.5 Open a new R script Because we want to save our code to return to and build on, or use to refresh our memory later, we want to save it in a text file. I recommend that you create a folder on your Desktop named WEHI_tidyR_course Go to File &gt; New File &gt; R Script. A new pane will appear at the top left. Save this empty text file as ‘Week_1_tidyverse.R’ within the new Desktop folder. From now on we will type commands in to the text file, and see the results of our commands either in the console pane, or the plotting pane. 1.6 Comments When working in R it is very handy to make notes to yourself about what the code is doing. In R, any text that appears after the hash symbol ‘#’ is called a ‘comment.’ R can’t see this text, and won’t try to run it as commands. Comments are useful for reminding your future self what you were aiming to do with a particular line of code, and what was or wasn’t working. We will use comments extensively in this course. Try writing your first comment in your R text file (top left panel) #This is a comment. ignored by R but useful for me! 1.7 Executing commands Executing commands, also called ‘running code’ is the process of submitting a command to your computer, which does some computation and returns an answer. There are a few ways to do this in RStudio. We can: select the line(s) of code using the mouse, and then click ‘Run’ at the top right corner of the R text file. click anywhere on the line of code and click ’Run click anywhere on the line of code and type Cmd + Return (mac), or Ctrl + Return (pc) We suggest the third option, which is fastest. When you type in, and then run the commands shown in the grey boxes below, you should see the result in the Console pane at bottom left. 1.8 Simple maths in R We can use R as a calculator to do simple maths 1 + 100 ## [1] 101 More complex calculator functions are ‘built in’ to R, which is the reason it is popular among mathematicians and statisticians. To use these functions, we first type the function, then enter the number of interest between round brackets. For example, to take the log or square root of 100: log(100) ## [1] 4.60517 sqrt(100) ## [1] 10 Notice that the ‘square root’ function is abbreviated to ‘sqrt()’. This is to make writing R code faster, however the draw back is that some functions are hard to remember, or to interpret. 1.9 Help!! To find out more about what a function in R does, add a ‘?’ before the function name, and leave the round brackets empty. Then run the code: #get help on R functions by using &quot;?&quot; ?sqrt() You will see the ‘Help’ pane at bottom right springs to life. These help documents give detailed explanations about the function, including how it is used, what input it requires, and, most importantly at the bottom Examples! You can copy and paste these examples in to your R text file, select and then run them. You should see the output intended by the function authors. NB don’t worry for now that the sqrt() example is quite complicated. NBB all R ‘functions’ are little programs that were written by other people. There are 1000s of functions available for R, which makes your life simpler because you don’t have to program them all from scratch. 1.10 Variables A ‘variable’ is a bit of tricky concept, but very important for understanding R. Essentially, a variable is a symbol that we use in place of another value. Usually the other value is a larger/longer form of data. We can tell R to store a lot of data, for example, in a variable named ‘x’. When we execute the command ‘x’, R returns all of the data that we stored there. For now however we’ll just use a tiny data set: the number 5. To store some data in a variable, we need to use a special symbol ‘&lt;-’ which in our case tells R to ‘assign the value 5 to the variable x’. This is called the ‘assignment operator’. Let’s see how this works # create a variable called &#39;x&#39;, that will contain the number 5. x &lt;- 5 R won’t return anything in the Console, but note that you now have a new entry in the ‘Environment pane’. The variable name is at the left (‘x’) and the value that is stored in that variable, is displayed on the right (5). We can now use ‘x’ in place of 5: x + 20 ## [1] 25 x * 50 ## [1] 250 Can you work out what the * symbol is used for in R? 1.10.1 A note on variables Variables are sometimes referred to as ‘objects’. In R there are different conventions about how to name variables, but most importantly they: cannot begin with a number should begin with an alphabetical letter Variables are also case sensitive: X ## Error in eval(expr, envir, enclos): object &#39;X&#39; not found As we can see, ‘x’ is not the same as ‘X’. Variables can take any name, but its best to use something that makes sense to you, and will likely make sense to others who may read your code. R_at_WEHI &lt;- 100 For example, this code will work, but is not very intuitive to humans: log(R_at_WEHI) ## [1] 4.60517 You may be wondering “why bother with assigning variables, when its less text to type ‘100’?” This is because we can store huge amounts of data in a single variable. For example, we can store a list of 50 numbers in a variable, and do maths on them all at once. First we create a list of 50 numbers, using a quick trick ‘1:50’ which means ‘every whole number from 1 to 50’. Let’s make a variable called ‘long_x’ that stores 1:50. long_x &lt;- 1:50 Now we can multiply every number by 10 long_x * 10 ## [1] 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 ## [28] 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 Here we are accessing the power of R, which is designed to do lots of computations based on a single line of code. 1.11 Vectors In making the long_x variable, we are making a ‘vector’. In this case, it is a sequence of numbers. A technical definition for a vector is ‘a sequence of values of the same data type.’ To better understand this we need to think about ‘types of data’. The three data types we need to understand for now are: numbers (‘numeric’) words (‘characters’), and TRUE/FALSE (‘logical’) For example, whole numbers can be added, subtracted and so forth. This ‘numeric’ data type is qualitatively different to a word. Words hold meaning, but can’t be sensibly used in a mathematical equation. TRUE and FALSE have specific, logical meaning for computers. Most of what we do in R is turned into TRUE/FALSE problems which are evaluated ‘under the hood.’ 1.11.1 Creating numeric vectors Above we used a shortcut to create a vector of 50 numbers ( 1:50 ). Ordinarily, we need to enclose values in brackets, separated by commas. The values also need to be ‘concatenated’ using a function called c(). #This new variable will contain a vector of numbers, which in this case is a concatenation of 5, 12 and 22. numeric_vector &lt;- c(5,12,22) 1.11.2 Character vectors Character values are written in quotation marks, and character vectors are also constructed using c(). char_vector &lt;- c(&#39;dog&#39;,&#39;cat&#39;,&#39;pigeon&#39;) What happens when you add a character vector to a numeric vector? numeric_vector + char_vector ## Error in numeric_vector + char_vector: non-numeric argument to binary operator Nothing sensible. R will return an error. 1.11.3 Logical vectors Finally we can create a vector of logical values. Note that for TRUE and FALSE (always in upper case), quotation marks aren’t used. Here we create a vector of three logical values: logi_vector &lt;- c(TRUE,TRUE,FALSE) TRUE and FALSE appear in coloured text, indicating that they have a special meaning in the R language. What happens when we add logical data to numeric data? numeric_vector + logi_vector ## [1] 6 13 22 Can you work out how R has calculated this answer? Essentially, the logical data has been automatically converted to numeric data. The TRUE values become 1, and FALSE become 0. Another thing to note is that the values in the vector have been added in their respective orders: position1: 5 + 1 = 6 position2: 12 + 1 = 13 position3: 22 + 0 = 22 This is called ‘type coercion,’ which we’ll return to later. 1.12 Packages As mentioned above, many developers have built 1000s of functions and shared them with the R user community to help make everyone’s work easier and more efficient. These functions (short programs) are generally packaged up together in (wait for it) ‘Packages’. For example, the ‘tidyverse’ package is a compilation of many different functions, all of which help with data transformation and visualization. Packages also contain data, which is often included to assist new users with learning the available functions. To access this wealth of pre-existing functions, we install packages from the Comprehensive R Archive Network (CRAN) …and if you want the all scripts from The Office (American series) in tabular form, there’s a package for that. 1.12.1 Installing packages To install a package from CRAN, use the ‘install.packages()’ function: #install packages using the package names in quotes install.packages(&#39;tidyverse&#39;) This will spit out a lot of text into the console as the package is being installed. Once complete you should have a message The downloaded binary packages are in... followed by a long directory name. To access the package functions in our RStudio session, we load the package like so: #load packages using library(package_name), and drop the quotes library(tidyverse) Note that to install a package requires the package name in quotations. Once installed, to load it we drop the quotation marks. 1.13 The pipe %&gt;% When using functions provided in the tidyverse package, we suggest to write your commands from left to right. This makes reading, and finding bugs in the code, a lot easier. To write code in this way requires a specific symbol, called the pipe which allows the code to be processed in a left-right manner. The pipe symbol looks like this: %&gt;% It is a pain to type manually, so we suggest you use a shortcut: CMD + SHIFT + M (mac) or CTRL + SHIFT + M (pc). It takes a little practice, but quickly enables a great increase in your coding speed. The pipe-based method of coding can help new users to become ‘fluent in R’. Let’s try using the pipe with some data that is packaged up with the tidyverse, called the ‘miles per gallon (mpg)’ data set. This is the data set you saw above, containing information on the mechanical features of different models of car. First we will assign the currently hidden mpg data set to an explicit variable ‘mpg_df’ in our environment. mpg_df &lt;- mpg Now we access the contents of mpg_df, and ‘send it into a function’ called head(). The head() function returns the first six rows of a data set (or first six values in a vector) to the console. #see the first six rows of the mpg data set #call mpg_df first, then &#39;send it into&#39; the head function, using the pipe %&gt;% mpg_df %&gt;% head() ## # A tibble: 6 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 auto(l5) f 18 29 p compact ## 2 audi a4 1.8 1999 4 manual(m5) f 21 29 p compact ## 3 audi a4 2 2008 4 manual(m6) f 20 31 p compact ## 4 audi a4 2 2008 4 auto(av) f 21 30 p compact ## 5 audi a4 2.8 1999 6 auto(l5) f 16 26 p compact ## 6 audi a4 2.8 1999 6 manual(m5) f 18 26 p compact Note that unlike the log() and c() functions we used earlier, here the brackets after head() are empty. This still works because the pipe %&gt;% is sending the mpg_df dataset into the head() function. It has the same outcome as: head(mpg_df) 1.14 Data frames The final concept we need to understand before starting to make plots in R, are ‘data frames’. The vectors we created above are a simple type of ‘data structure’. Whereas vectors can be thought of as a 1-dimensional data structure (a sequence of values), data frames are a 2D data structure. Data frames have both rows and columns. Each column is in fact a vector, containing a single type of data. Data frames generally have column names, which we can treat in the same way as a variable. For example, let’s combine our three vectors into a data frame, using the data_frame() function: #combine vectors of the same length into a data frame new_df &lt;- data_frame(numeric_vector, char_vector, logi_vector) new_df ## # A tibble: 3 x 3 ## numeric_vector char_vector logi_vector ## &lt;dbl&gt; &lt;chr&gt; &lt;lgl&gt; ## 1 5 dog TRUE ## 2 12 cat TRUE ## 3 22 pigeon FALSE Importantly, each column in a data frame must have the same number of values (i.e., the same number of rows). This will be a familiar data structure for those who use Microsoft Excel, and is very popular in data science. To make plots in R for this tutorial, we must provide our data in data frame form. "],["week-1-part-2.html", "Week 1. Part 2", " Week 1. Part 2 "],["making-beautiful-plots.html", "2 Making beautiful plots Introductory information ggplot2. A grammar of graphics 2.1 Building a ggplot 2.2 Plot background 2.3 Aesthetics aes() 2.4 Geometric representations geom() 2.5 Adding colour 2.6 Adding layers 2.7 Facets 2.8 Coordinate space 2.9 Axis labels 2.10 Themes", " 2 Making beautiful plots Introductory information This tutorial leads on from the Week 1 Part 1 tutorial. If you have opened a new R session in RStudio, you can open and continue to work in your Week_1_tidyverse.R file. First, reload the tidyverse package: library(tidyverse) ggplot2. A grammar of graphics The ggplot2 package is widely used and valued for its simple, consistent approach to making plots. The ‘grammar’ of graphics relates to the different components of a plot that function like different parts of linguistic grammar. For example, all plots require axes, so the x and y axes form one part of the ‘language’ of a plot. Similarly, all plots have data represented between the axes, often as points, lines or bars. The visual way that the data is represented forms another component of the grammar of graphics. Furthermore, the colour, shape or size of points and lines can be used to encode additional information in the plot. This information is usually clarified in a key, or legend, which can also be considered part of this ‘grammar’. The most common components of a ggplot are aesthetics geometric representations facets coordinate space coordinate labels plot theme We will cover each below. The philosophy of ggplot is much better explained by the package author, Hadley Wickham here. For now, we just need to be aware that ggplots are constructed by specifying the different components that we want to display, based on underlying information in a data frame. 2.1 Building a ggplot We are going to use the mpg_df data set created previously. If this is not visible in your environment pane, you can recreate it now: mpg_df &lt;- mpg Let’s check the first 6 rows of information contained in the mpg_df data frame, using the head() function: mpg_df %&gt;% head() ## # A tibble: 6 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 auto(l5) f 18 29 p compact ## 2 audi a4 1.8 1999 4 manual(m5) f 21 29 p compact ## 3 audi a4 2 2008 4 manual(m6) f 20 31 p compact ## 4 audi a4 2 2008 4 auto(av) f 21 30 p compact ## 5 audi a4 2.8 1999 6 auto(l5) f 16 26 p compact ## 6 audi a4 2.8 1999 6 manual(m5) f 18 26 p compact Here, we aim to produce a scatter plot of the engine volume (‘displacement’) vs fuel efficiency/mileage in the city (‘cty’), for each class of vehicle. The points on the plot will be coloured based on the vehicle class (right-most column). 2.2 Plot background To start building the plot, we first specify the data frame that contains the relevant data. Here we are ‘sending the mpg_df data set into the ggplot function’: #render plot background mpg_df %&gt;% ggplot() Running this command will produce an empty grey panel. This is because we need to specify how different columns of the data frame should be represented in the plot. 2.3 Aesthetics aes() We can call in different columns of data from mpg_df based on their column names. Column names are given as ‘aesthetic’ elements to the ggplot function, and are wrapped in the aes() function. Because we want a scatter plot, each point will have an x and a y coordinate. We want the x axis to represent engine volume ( x = displ ), and the y axis to represent the city mileage ( y = cty ). We give these specifications separated by a comma. Note that quotes are not required when giving variables within aes(). Those interested in why quotes aren’t required can read here about non-standard evaluation. mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) So far we have the grid lines for our x and y axis. ggplot knows the variables required for the plot, and thus the scale, but has no information about how to display the data points. 2.4 Geometric representations geom() Given we want a scatter plot, we need to specify that the geometric representation of the data will be in point form, using geom_point(). Here we are adding a layer (hence the + sign) of points to the plot. We can think of this as similar to e.g. Adobe Photoshop which uses layers of images that can be reordered and modified individually. For ggplot, each layer will be added over the plot according to its position in the code. mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) + geom_point() Now we have the scatter plot! Each row in the mpg_df data set now has an x coordinate, a y coordinate, and a designated geometric representation (point). From this we can see that vehicles with smaller engines (lower displacement) tend to have higher mileage in the city. 2.4.1 A note about %&gt;% and + ggplot2, an early component of the tidyverse package, was written before the pipe was introduced. The + sign in ggplot2 functions in a similar way to the pipe in other functions in the tidyverse: by allowing code to be written from left to right. 2.5 Adding colour The current plot could be more informative, to include information about the class of each vehicle. In order to achieve this we need to use aes() again, and specify which column in mpg_df we want to be represented as the colour of the points. Here, the aes() function containing the relevant column name, is given within the geom_point() function. mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) + geom_point(aes(colour = class)) So now we can see that the subcompact class (purple points) tends to have small engines and good city mileage, whereas the SUVs (pink points) have very low city mileage and larger engines. As commands get longer, we suggest to add carriage returns (new lines), which must be inserted after the %&gt;% or + symbols. In most cases, R is blind to white space and new lines, so this is simply to make our code more readable. 2.6 Adding layers We can see the relationship between engine size and mileage. But what if we want to model this relationship with a trend line? We can add another ‘layer’ to this plot, using a different geometric representation of the data. In this case a trend line, which is in fact a summary of the data rather than a representation of each point. The geom_smooth() function draws a trend line through the data. The default behaviour is to draw a local regression line (curve) through the points, however these can be hard to interpret. We want to add a straight line based on a linear model (‘lm’) of the relationship between x and y. #add another layer of data representation. mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) + geom_point(aes(colour = class)) + geom_smooth(method=&#39;lm&#39;) ## `geom_smooth()` using formula &#39;y ~ x&#39; Note that the trend line is blocking out certain points, because it is the ‘top layer’ of the plot. The geom layers that appear early in the command are drawn first, and can be obscured by the geom layers that come after them. What happens if you switch the order of the geom_point() and geom_smooth() functions above? What do you notice about the trend line? 2.7 Facets In some cases we want to break up a single plot into sub-plots, called ‘faceting’. Facets are commonly used when there is too much data to display clearly in a single plot. We will revisit faceting below, however for now, let’s try to facet the mpg_df plot according to vehicle engine size (displ). To do this we use the tilde symbol ‘~’ to indicate the column name that will form each facet. mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) + geom_point(aes(colour = class)) + geom_smooth(method=&#39;lm&#39;) + facet_wrap( ~ class) ## `geom_smooth()` using formula &#39;y ~ x&#39; Note that the aesthetics and geoms including the regression line that were specified for the original plot, are applied to each of the facets. 2.8 Coordinate space ggplot will automatically pick the scale for each axis, and the type of coordinate space. Most plots are in Cartesian (linear X vs linear Y) coordinate space. For the mpg_df plot, let’s say we want the x and y origin to be set at 0. To do this we can add in xlim() and ylim() functions, which define the limits of the axes: mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) + geom_point(aes(colour = class)) + geom_smooth(method=&#39;lm&#39;) + xlim(0,7) + ylim(0,40) ## `geom_smooth()` using formula &#39;y ~ x&#39; Further, we can control the coordinate space using coord() functions. Say we want to flip the x and y axes, we add coord_flip(): mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) + geom_point(aes(colour = class)) + geom_smooth(method=&#39;lm&#39;) + xlim(0,7) + ylim(0,40) + coord_flip() ## `geom_smooth()` using formula &#39;y ~ x&#39; 2.9 Axis labels By default, the axis labels will be the column names we gave as aesthetics aes(). We can change the axis labels using the xlab() and ylab() functions. Given that column names are often short and can be cryptic, this functionality is particularly important for effectively communicating results. mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) + geom_point(aes(colour = class)) + geom_smooth(method=&#39;lm&#39;) + xlim(0,7) + ylim(0,40) + xlab(&#39;Engine size (L)&#39;) + ylab(&#39;Miles per gallon in the city&#39;) ## `geom_smooth()` using formula &#39;y ~ x&#39; We can also add a title and subtitle with ggtitle() mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) + geom_point(aes(colour = class)) + geom_smooth(method=&#39;lm&#39;) + xlim(0,7) + ylim(0,40) + xlab(&#39;Engine size (L)&#39;) + ylab(&#39;Miles per gallon in the city&#39;) + ggtitle(label = &#39;Engine size affects mileage&#39;, subtitle = &#39;Some extra info here too&#39;) ## `geom_smooth()` using formula &#39;y ~ x&#39; 2.10 Themes Finally, the overall appearance of the plot can be modified using theme() functions. The default theme has a grey background which maximizes contrast with other contrasts. You may prefer a ‘classic’ theme, a black &amp; white theme or even theme_void(). Try them out. mpg_df %&gt;% ggplot(aes(x = displ, y = cty)) + geom_point(aes(colour = class)) + geom_smooth(method=&#39;lm&#39;) + xlim(0,7) + ylim(0,40) + xlab(&#39;Engine size (L)&#39;) + ylab(&#39;Miles per gallon in the city&#39;) + ggtitle(label = &#39;Engine size affects mileage&#39;, subtitle = &#39;Some extra info here too&#39;) + theme_bw() ## `geom_smooth()` using formula &#39;y ~ x&#39; "],["week-1-part-3.html", "Week 1. Part 3", " Week 1. Part 3 "],["making-more-beautiful-plots.html", "3 Making more beautiful plots Introductory information 3.1 Big(ger) Data: 54,000 diamonds 3.2 geom_jitter() 3.3 Summary plots 3.4 Histograms 3.5 Density plots 3.6 Box plots 3.7 Saving plots 3.8 Challenge 3.9 Solution", " 3 Making more beautiful plots Introductory information This tutorial leads on from the Week 1 Part 2 tutorial. We now explore approaches for plotting large datasets. If you have opened a new R session in RStudio, you can open your Week_1_tidyverse.R file, and reload the tidyverse package: library(tidyverse) We now create a larger data set in the global environment, called ‘diamond_df’. This is based on the diamonds data set that is provided as part of the tidyverse diamond_df &lt;- diamonds N.B. If your computer is taking a long time to plot this data set in the steps below, then take a smaller sample of 2500 rows. I don’t recommend overwriting objects in general, but doing this will make the following section more accessible. Also note that your plots will look slightly different to those below. set.seed(1234) ; diamond_df &lt;- diamond_df %&gt;% sample_n(2500) 3.1 Big(ger) Data: 54,000 diamonds When plotting a small dataset such as mpg_df, its possible to visualize every individual data point. This is impractical for large datasets, where we run into the problem of ‘over-plotting’. We therefore need approaches for managing over-plotting. These include but aren’t limited to: reducing density summing, and summarizing the data. To explore these options we will now move on to a much larger data set containing multiple measurements for 54,000 diamonds. The measurements appear in separate columns, and each diamond appears in a different row. As for mpg, this data is available through the tidyverse package. https://www.diamonds.pro/wp-content/uploads/2019/02/diamond-depth-and-table.png First let’s view the first 6 rows of the diamond_df dataset diamond anatomy img from: https://www.diamond.pro/education/diamond-depth-and-table/ diamond_df %&gt;% head() ## # A tibble: 6 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.29 Premium I VS2 62.4 58 334 4.2 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 ## 6 0.24 Very Good J VVS2 62.8 57 336 3.94 3.96 2.48 You can read the definitions of each measurement (column name) in the help manual for the original (‘hidden’) dataset by typing ?diamonds We can get the number of rows and columns (the ‘dimensions’) of this dataset using the dim() function: diamond_df %&gt;% dim() ## [1] 53940 10 First let’s make a scatter plot comparing the price of diamonds (y) by cut (x): diamond_df %&gt;% ggplot(aes(x=cut, y=price)) + geom_point() Because there are 54K points here the plot is essentially useless. What can we do to get more information about the relationship? 3.2 geom_jitter() The geom_jitter() command adds some random scatter to the points which can reduce over-plotting. Note that to avoid mis-representing the price, we should set the jitter height to 0. diamond_df %&gt;% ggplot(aes(x=cut, y=price)) + geom_jitter(height=0) This is somewhat improved but far from good. Next we will make the points more transparent using the ‘alpha’ setting within geom_jitter. diamond_df %&gt;% ggplot(aes(x=cut, y=price)) + geom_jitter(height=0, alpha=0.25) The density below $5000 can be further reduced by limiting the size of the points, again within the geom_jitter() command. diamond_df %&gt;% ggplot(aes(x=cut, y=price)) + geom_jitter(height=0, alpha=0.25, size=0.5) Now we can see much more detail in the data, including an interesting lack of data around the $3000 mark in the Very Good and Premium cut data. This could be due to other features such as size, carat or clarity. We will return to these possibilities later. 3.3 Summary plots Its clear that the cut group sizes are uneven. To get a quick summary of the numbers of diamonds per group, we can make a bar plot. Here we specify only the group we wish to count (i.e. the number of diamonds of each cut) as the x aesthetic. Importantly, the group size is summed and displayed automatically when we specify geom_bar(). diamond_df %&gt;% ggplot(aes(x=cut)) + geom_bar() Alternatively, if we want to find the total value of the diamonds in each group, we use a related geom that sums the values in a column (rather than the number of rows), called geom_col. Here we give price, that is, the column whose values we want to sum, as the y axis aesthetic. diamond_df %&gt;% ggplot(aes(x=cut, y=price)) + geom_col() From this we can see the total value of the Ideal cut diamonds alone is &gt; $70 million! 3.3.1 Free examples! If you are unsure how to use a function in R, the help page will usually have Example code at the bottom. ?geom_bar() You can copy and paste these examples and they should work first time. The code below is taken directly from the first example for geom_bar(): # geom_bar is designed to make it easy to create bar charts that show # counts (or sums of weights) g &lt;- ggplot(mpg, aes(class)) # Number of cars in each class: g + geom_bar() To add more information, we could count the clarity groups per cut group. Adding clarity into the aesthetic as the bar fill colour will automatically calculate and display these sub-groups. diamond_df %&gt;% ggplot(aes(x = cut, fill=clarity)) + geom_bar() We can rearrange the clarity groups into adjacent (dodged) bars by specifying a different position within geom_bar(): diamond_df %&gt;% ggplot(aes(x = cut, fill=clarity)) + geom_bar(position=&#39;dodge&#39;) 3.4 Histograms When dealing with large datasets especially for statistical testing, histograms are essential for understanding the distribution of values. Like geom_bar() above, geom_histogram() requires only a single x aesthetic, specifying the values to be displayed. Further, the values will be automatically sorted into 30 bins and the number of rows of data per bin summed up. Here we plot the distribution of prices across the entire dataset. diamond_df %&gt;% ggplot(aes(x = price)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. To increase the resolution of the histogram, lets specify 200 bins: diamond_df %&gt;% ggplot(aes(x=price)) + geom_histogram(bins=200) Here we can see an interesting lack of data around $1000. Let’s zoom in using xlim, and add some fill colour. diamond_df %&gt;% ggplot(aes(x = price)) + geom_histogram(bins=200, fill = &#39;dodgerblue&#39;) + xlim(0,2500) ## Warning: Removed 26398 rows containing non-finite values (stat_bin). ## Warning: Removed 2 rows containing missing values (geom_bar). There are virtually no diamonds around the $1500 mark. What could be the reason for this? R will give a warning that some data is not represented in the plot. This is part of the ggplot philosophy that ‘data should not go missing silently.’ 3.5 Density plots Whereas it can be difficult to represent multiple sub-groups in a histogram, density plots are another essential tool for exploring your data. These are essentially smoothed histograms, where the area under the curve for each sub-group will sum to 1. This allows us to compare sub-groups of different size. diamond_df %&gt;% ggplot(aes(x = price)) + geom_density(aes(colour =cut)) 3.6 Box plots img from: https://miro.medium.com/max/18000/1*2c21SkzJMf3frPXPAR_gZA.png Box plots, or ‘box &amp; whisker plots’ are another essential tool for data analysis, which are related to histograms and density plots. Box plots summarize the distribution of a set of values by displaying the minimum and maximum values, the median (i.e. middle-ranked value), and the range of the middle 50% of values (inter-quartile range). The whisker line extending above and below the IQR box define Q3 + (1.5 x IQR), and Q1 - (1.5 x IQR) respectively. You can read more about box plots here. To create box plot from our data we use (no prizes here) geom_boxplot()! diamond_df %&gt;% ggplot(aes(x=cut, y=price)) + geom_boxplot() The points indicate outlier values [i.e., those greater than Q3 + (1.5 x IQR)]. We can overlay a boxplot on the scatter plot for the entire dataset, to fully communicate both the raw and summary data. Here we reduce the width of the jitter points slightly, and set the IQR box to be fully transparent using alpha. Note that this setting also hides the outlier points in geom_boxplot. diamond_df %&gt;% ggplot(aes(x=cut, y=price)) + geom_jitter(height=0, alpha=0.25, size=0.5, width=0.3) + geom_boxplot(alpha=0) Because its now difficult to see the box plots, we can colour only the geom_boxplot by setting the colour aesthetic within that geom: diamond_df %&gt;% ggplot(aes(x=cut, y=price)) + geom_jitter(height=0, alpha=0.25, size=0.5, width=0.3) + geom_boxplot(alpha=0, aes(colour =cut)) The legend contains the same information as the x axis, and is therefore redundant. We can drop the legend by giving an additional command to geom_boxplot: diamond_df %&gt;% ggplot(aes(x=cut, y=price)) + geom_jitter(height=0, alpha=0.25, size=0.5, width=0.3) + geom_boxplot(alpha=0, aes(colour =cut), show.legend = FALSE) In fact, a box plot displays very similar information to a density plot, rotated 90°. Violin plots, which reflect the sample density, can be used together with a box plot to convey even more detail about the distribution of a set of values. Here we limit the width of geom_boxplot to sit within geom_violin. Because both geoms will be coloured in the same way, we can give the colour aesthetic directly to ggplot(). Similarly, because we don’t want the legend, we will remove it using the theme() function. diamond_df %&gt;% ggplot(aes(x=cut, y=price, colour =cut)) + geom_boxplot(alpha=0, width=0.15) + geom_violin(alpha=0) + theme(legend.position = &#39;none&#39;) 3.7 Saving plots ggplot includes a neat function ggsave() which allows us to save plots in many formats By default ggsave() will save the most recent plot. It writes a file depending on the extension you provide. To save the plot that is currently in your Plots window: ggsave(&#39;~/Desktop/WEHI_tidyR_course/my_ggplot.pdf&#39;, width=5,height=4) To save a specific plot, its possible to store the plot as a variable, which is given to ggsave(): myplot &lt;- mpg %&gt;% ggplot(aes(x=displ, y=cty)) + geom_point(aes(colour = class)) ggsave(plot = myplot, &#39;~/Desktop/WEHI_tidyR_course/my_ggplot.pdf&#39;, width = 5, height = 4) In general, if you want to increase the size of points and text, then reduce the dimensions of the plot; and vice versa. 3.8 Challenge Based on what you’ve learnt, can you make a scatter plot that shows the relationship between diamond carat and price, with points coloured by clarity (reduced in size to 0.2), and faceted by cut? What do you notice about the distribution of carat? More generally, what has this exploratory data analysis taught us about human psychology when it comes to diamonds? 3.9 Solution diamond_df %&gt;% ggplot(aes(x=carat, y=price, colour =clarity)) + geom_point(size=0.2) + facet_wrap(~cut) "],["week-2-part-1.html", "Week 2. Part 1", " Week 2. Part 1 "],["sub-setting-vectors.html", "4 Sub-setting vectors 4.1 Subset by position 4.2 Adding names 4.3 Subset by condition 4.4 Challenge 4.5 Possible solutions", " 4 Sub-setting vectors A very common task in data wrangling is filtering or ‘sub-setting’ down to a smaller set of potentially interesting values. This short chapter is intended to give you a basic understanding of the operations that R is performing when filtering and evaluating data using the functions introduced in Chapter 5. Note that it is not necessary to have the tidyverse package loaded to complete this chapter - we are using ‘base R’ functions. First create a new .R file, and save as ‘Week_2_tidyverse.R’ in your Desktop WEHI_tidyR_course folder. wegotthiscovered.com/wp-content/uploads/the-beatles.jpg To start, we will create a vector named ‘beatles’ containing the years of birth of The Beatles: John Lennon: 1940, Ringo Starr: 1940, Paul McCartney: 1942 and George Harrison: 1943. beatles &lt;- c(1940,1940,1942,1943) 4.1 Subset by position To hone in on different values in this vector we can request them based on their position in order 1 through 4. We give the position of the value we want in square brackets. To print the value in position 1: beatles[1] ## [1] 1940 Importantly, we can subset for values at position 2 and 3 by including a vector of numbers defining those positions. beatles[c(2,3)] ## [1] 1940 1942 We can also request everything but the value at a certain position, using the minus sign beatles[-3] ## [1] 1940 1940 1943 4.2 Adding names To add additional information to the values we can give each a name, supplied as a vector of words: names(beatles) &lt;- c(&#39;John&#39;,&#39;Ringo&#39;,&#39;Paul&#39;,&#39;George&#39;) Notice how the beatles variable has now changed slightly in the Environment panel. From now on every time a value is returned from the beatles vector, the Beatle member associated with that value is also returned. beatles[-3] ## John Ringo George ## 1940 1940 1943 4.3 Subset by condition In addition to sub-setting a vector by the position of values, we can ‘pose questions’ about the set of values to R, which will be returned with TRUE or FALSE answers. ‘Which Beatles date of birth is 1940’? To code this we ask for values ‘exactly equal to’ 1940, using the == sign. beatles == 1940 ## John Ringo Paul George ## TRUE TRUE FALSE FALSE R returns ‘TRUE’ for values that satisfy our ‘condition’, and FALSE for those that don’t. ‘Which member(s) date of birth is before 1943?’ To code this we use the less-than &lt; sign. beatles &lt; 1943 ## John Ringo Paul George ## TRUE TRUE TRUE FALSE R is assessing the value at each position, and returning an answer to our conditional question. A way to directly subset this vector is to directly provide a vector of TRUE and FALSE values within square brackets, in a similar manner to specifying the positions, above. beatles[c(TRUE,FALSE,FALSE,TRUE)] ## John George ## 1940 1943 Note that the only values returned are in the ‘TRUE’ positions, in this case the values at position 1 and 4. We can see that the process of sub-setting depends on the presence of ‘TRUE’ or ‘FALSE’ at each position along the vector. In most cases when sub-setting data, we want the values themselves, rather than the TRUE/FALSE evaluations. Now that we know that i) conditional requests return TRUE/FALSE values, and ii) TRUE/FALSE values are the basis of sub-setting vectors, we can substitute the TRUE/FALSE vector in the brackets above for a conditional statement: beatles[beatles &gt; 1940] ## Paul George ## 1942 1943 To check this, try running just the code within the square brackets. It is timely to mention that in R, code is processed from the inside- to outside of brackets. Here, the conditional statement is evaluated and produces a vector of four TRUE / FALSE values. This logical vector is then used to sub-set the original vector, returning a subset of named numeric values. ‘Which Beatles were not born in 1942?’ To answer this we need to use a ! symbol that ‘negates’, or inverts the condition: beatles[ beatles!=1942 ] ## John Ringo George ## 1940 1940 1943 To get an even more succinct answer, we could request only the names associated with the numeric values: names( beatles[ beatles != 1942] ) ## [1] &quot;John&quot; &quot;Ringo&quot; &quot;George&quot; You will use these types of conditional statements regularly in the next chapter. 4.4 Challenge Create three different commands to return information about the Beatles born before 1943. You can use positional information, and/or conditional requests. 4.5 Possible solutions beatles[beatles &lt; 1943] ## John Ringo Paul ## 1940 1940 1942 beatles[beatles != 1943] ## John Ringo Paul ## 1940 1940 1942 beatles[-4] ## John Ringo Paul ## 1940 1940 1942 beatles[c(1,2,3)] ## John Ringo Paul ## 1940 1940 1942 beatles[names(beatles) != &#39;George&#39;] ## John Ringo Paul ## 1940 1940 1942 "],["week-2-part-2.html", "Week 2. Part 2", " Week 2. Part 2 "],["manipulating-data-with-dplyr.html", "5 Manipulating data with dplyr 5.1 filter() 5.2 select() 5.3 arrange() 5.4 Chaining dplyr functions 5.5 Writing data to a file 5.6 Chaining dplyr and ggplot 5.7 mutate() 5.8 summarize() 5.9 group_by() helper 5.10 Challenges 5.11 Solutions 5.12 Summary 5.13 Cheat sheets! 5.14 Extra resources", " 5 Manipulating data with dplyr The dplyr package, part of the tidyverse, is designed to make manipulating and transforming data as simple and intuitive as possible. A guiding principle for tidyverse packages (and RStudio), is to minimize the number of keystrokes and characters required to get the results you want. To this end, as for ggplot, in dplyr, quotation marks for the column names of data frames are often not required. Another key feature of the tidyverse data wrangling packages such as dplyr, is that the input to and output from all functions, are data frames. dplyr features a handful of key functions, also termed ‘verbs’, which can be combined to achieve very specific results. You will notice similarities to the functions available in Microsoft Excel. We will explore the first of these verbs using the mpg_df dataset created earlier. If starting from a new Rstudio session you should open Week_2_tidyverse.R and run the following code: library(tidyverse) mpg_df &lt;- mpg 5.1 filter() The filter() function subsets the rows in a data frame by testing against a conditional statement. The output from a successful filter() will be a data frame with fewer rows than the input data frame. Let’s filter the mpg_df data for cars manufactured in the year 1999: mpg_df %&gt;% filter(year == 1999) ## # A tibble: 117 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 auto(l5) f 18 29 p compact ## 2 audi a4 1.8 1999 4 manual(m5) f 21 29 p compact ## 3 audi a4 2.8 1999 6 auto(l5) f 16 26 p compact ## 4 audi a4 2.8 1999 6 manual(m5) f 18 26 p compact ## 5 audi a4 quattro 1.8 1999 4 manual(m5) 4 18 26 p compact ## 6 audi a4 quattro 1.8 1999 4 auto(l5) 4 16 25 p compact ## 7 audi a4 quattro 2.8 1999 6 auto(l5) 4 15 25 p compact ## 8 audi a4 quattro 2.8 1999 6 manual(m5) 4 17 25 p compact ## 9 audi a6 quattro 2.8 1999 6 auto(l5) 4 15 24 p midsize ## 10 chevrolet c1500 suburban 2wd 5.7 1999 8 auto(l4) r 13 17 r suv ## # … with 107 more rows Here we are ‘sending’ the mpg_df data frame into the function filter(), which tests each value in the year column for the number 1999, and returns those rows where the filter() condition is TRUE. If you are working in an R text document (.R format) or directly in the console, after running this command you will see the dimensions of the output data frame printed in grey text above the column names. Alternatively you can ‘send’ the output of filter (a data frame) into the dim() function. mpg_df %&gt;% filter(year==1999) %&gt;% dim() ## [1] 117 11 We can also filter on character data. For example, let’s take all vehicles in the ‘midsize’ class: mpg_df %&gt;% filter(class==&#39;midsize&#39;) ## # A tibble: 41 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a6 quattro 2.8 1999 6 auto(l5) 4 15 24 p midsize ## 2 audi a6 quattro 3.1 2008 6 auto(s6) 4 17 25 p midsize ## 3 audi a6 quattro 4.2 2008 8 auto(s6) 4 16 23 p midsize ## 4 chevrolet malibu 2.4 1999 4 auto(l4) f 19 27 r midsize ## 5 chevrolet malibu 2.4 2008 4 auto(l4) f 22 30 r midsize ## 6 chevrolet malibu 3.1 1999 6 auto(l4) f 18 26 r midsize ## 7 chevrolet malibu 3.5 2008 6 auto(l4) f 18 29 r midsize ## 8 chevrolet malibu 3.6 2008 6 auto(s6) f 17 26 r midsize ## 9 hyundai sonata 2.4 1999 4 auto(l4) f 18 26 r midsize ## 10 hyundai sonata 2.4 1999 4 manual(m5) f 18 27 r midsize ## # … with 31 more rows Can you filter mpg_df for all vehicles except the Hyundais? 5.1.1 Logical operations 5.1.1.1 &amp; and We can achieve more specific filters by combining conditions across columns. For example, we use the “&amp;” sign to filter for vehicles built in 1999 and with mileage in the city (cty) greater than 18. mpg_df %&gt;% filter(year == 1999 &amp; cty &gt; 18) ## # A tibble: 33 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 manual(m5) f 21 29 p compact ## 2 chevrolet malibu 2.4 1999 4 auto(l4) f 19 27 r midsize ## 3 honda civic 1.6 1999 4 manual(m5) f 28 33 r subcompact ## 4 honda civic 1.6 1999 4 auto(l4) f 24 32 r subcompact ## 5 honda civic 1.6 1999 4 manual(m5) f 25 32 r subcompact ## 6 honda civic 1.6 1999 4 manual(m5) f 23 29 p subcompact ## 7 honda civic 1.6 1999 4 auto(l4) f 24 32 r subcompact ## 8 hyundai tiburon 2 1999 4 auto(l4) f 19 26 r subcompact ## 9 hyundai tiburon 2 1999 4 manual(m5) f 19 29 r subcompact ## 10 nissan altima 2.4 1999 4 manual(m5) f 21 29 r compact ## # … with 23 more rows To see the entire output you can pipe the output from filter into a View() command mpg_df %&gt;% filter(year==1999 &amp; cty &gt; 18) %&gt;% View() 5.1.1.2 | or Alternatively we might want to filter for vehicles (i.e., rows) where the manufacturer is Chevrolet or the class is ‘suv’. This requires the “|” symbol (shift + \\) mpg_df %&gt;% filter(manufacturer==&#39;chevrolet&#39; | class==&#39;suv&#39;) ## # A tibble: 72 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 chevrolet c1500 suburban 2wd 5.3 2008 8 auto(l4) r 14 20 r suv ## 2 chevrolet c1500 suburban 2wd 5.3 2008 8 auto(l4) r 11 15 e suv ## 3 chevrolet c1500 suburban 2wd 5.3 2008 8 auto(l4) r 14 20 r suv ## 4 chevrolet c1500 suburban 2wd 5.7 1999 8 auto(l4) r 13 17 r suv ## 5 chevrolet c1500 suburban 2wd 6 2008 8 auto(l4) r 12 17 r suv ## 6 chevrolet corvette 5.7 1999 8 manual(m6) r 16 26 p 2seater ## 7 chevrolet corvette 5.7 1999 8 auto(l4) r 15 23 p 2seater ## 8 chevrolet corvette 6.2 2008 8 manual(m6) r 16 26 p 2seater ## 9 chevrolet corvette 6.2 2008 8 auto(s6) r 15 25 p 2seater ## 10 chevrolet corvette 7 2008 8 manual(m6) r 15 24 p 2seater ## # … with 62 more rows 5.1.1.3 and/or To take it a step further we can combine &amp; and | in the same filter command. Adding curved brackets will help to clarify the order of operations. Let’s filter for the vehicles where the manufacturer is Chevrolet or the class is ‘suv’, and all vehicles with highway mileage less than 20. mpg_df %&gt;% filter( (manufacturer==&#39;chevrolet&#39; | class==&#39;suv&#39;) &amp; hwy &lt; 20) ## # A tibble: 48 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 chevrolet c1500 suburban 2wd 5.3 2008 8 auto(l4) r 11 15 e suv ## 2 chevrolet c1500 suburban 2wd 5.7 1999 8 auto(l4) r 13 17 r suv ## 3 chevrolet c1500 suburban 2wd 6 2008 8 auto(l4) r 12 17 r suv ## 4 chevrolet k1500 tahoe 4wd 5.3 2008 8 auto(l4) 4 14 19 r suv ## 5 chevrolet k1500 tahoe 4wd 5.3 2008 8 auto(l4) 4 11 14 e suv ## 6 chevrolet k1500 tahoe 4wd 5.7 1999 8 auto(l4) 4 11 15 r suv ## 7 chevrolet k1500 tahoe 4wd 6.5 1999 8 auto(l4) 4 14 17 d suv ## 8 dodge durango 4wd 3.9 1999 6 auto(l4) 4 13 17 r suv ## 9 dodge durango 4wd 4.7 2008 8 auto(l5) 4 13 17 r suv ## 10 dodge durango 4wd 4.7 2008 8 auto(l5) 4 9 12 e suv ## # … with 38 more rows 5.1.2 str_detect() helper function Often we want to capture rows containing a particular sequence of letters. For example, there are 10 different vehicle models containing the letters ‘4wd’. We don’t want to have to write an ‘or’ command with 10 alternatives. A much better way is to ‘detect’ the letters ‘4wd’ in the model column, and return all rows where they are present, using str_detect(). str_detect() is a command within filter() which requires the column name, followed by the letters (in quotes) to search for mpg_df %&gt;% filter(str_detect(model,&#39;4wd&#39;)) ## # A tibble: 74 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 chevrolet k1500 tahoe 4wd 5.3 2008 8 auto(l4) 4 14 19 r suv ## 2 chevrolet k1500 tahoe 4wd 5.3 2008 8 auto(l4) 4 11 14 e suv ## 3 chevrolet k1500 tahoe 4wd 5.7 1999 8 auto(l4) 4 11 15 r suv ## 4 chevrolet k1500 tahoe 4wd 6.5 1999 8 auto(l4) 4 14 17 d suv ## 5 dodge dakota pickup 4wd 3.7 2008 6 manual(m6) 4 15 19 r pickup ## 6 dodge dakota pickup 4wd 3.7 2008 6 auto(l4) 4 14 18 r pickup ## 7 dodge dakota pickup 4wd 3.9 1999 6 auto(l4) 4 13 17 r pickup ## 8 dodge dakota pickup 4wd 3.9 1999 6 manual(m5) 4 14 17 r pickup ## 9 dodge dakota pickup 4wd 4.7 2008 8 auto(l5) 4 14 19 r pickup ## 10 dodge dakota pickup 4wd 4.7 2008 8 auto(l5) 4 14 19 r pickup ## # … with 64 more rows Note that the letter order and case have to be matched exactly. How would you filter for all vehicles with automatic transmission? 5.1.3 %in% helper When we are interested in a subset of rows that can contain several different values, instead of writing a long OR command, its useful to just give a vector of values of interest. For example, to take the subset of the vehicles in mpg_df that have 4, 5, or 6 cylinders, we can specify cyl %in% c(4,5,6) mpg_df %&gt;% filter(cyl %in% c(4,5,6)) ## # A tibble: 164 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 auto(l5) f 18 29 p compact ## 2 audi a4 1.8 1999 4 manual(m5) f 21 29 p compact ## 3 audi a4 2 2008 4 manual(m6) f 20 31 p compact ## 4 audi a4 2 2008 4 auto(av) f 21 30 p compact ## 5 audi a4 2.8 1999 6 auto(l5) f 16 26 p compact ## 6 audi a4 2.8 1999 6 manual(m5) f 18 26 p compact ## 7 audi a4 3.1 2008 6 auto(av) f 18 27 p compact ## 8 audi a4 quattro 1.8 1999 4 manual(m5) 4 18 26 p compact ## 9 audi a4 quattro 1.8 1999 4 auto(l5) 4 16 25 p compact ## 10 audi a4 quattro 2 2008 4 manual(m6) 4 20 28 p compact ## # … with 154 more rows 5.1.4 is.na() helper If there are NA (missing) values in a particular column, we can inspect or drop them using the is.na() helper. To check for the presence of NA values in the year column, for example: mpg %&gt;% filter(is.na(year)) ## # A tibble: 0 x 11 ## # … with 11 variables: manufacturer &lt;chr&gt;, model &lt;chr&gt;, displ &lt;dbl&gt;, year &lt;int&gt;, cyl &lt;int&gt;, trans &lt;chr&gt;, ## # drv &lt;chr&gt;, cty &lt;int&gt;, hwy &lt;int&gt;, fl &lt;chr&gt;, class &lt;chr&gt; The mpg data set doesn’t contain any missing values, however in later chapters we will encounter them. Any rows with a missing value in the year column would be dropped using the code mpg %&gt;% filter(!is.na(year)) 5.1.5 complete.cases() helper Similar to is.na(), we can check for the presence of NA values across all columns of a dataframe using complete.cases(). This function is not part of the tidyverse package, so it requires a period . within the brackets, to indicate that we want to search across the entire dataframe. To filter for only the rows with no missing values: mpg %&gt;% filter( complete.cases(.) ) ## # A tibble: 234 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 auto(l5) f 18 29 p compact ## 2 audi a4 1.8 1999 4 manual(m5) f 21 29 p compact ## 3 audi a4 2 2008 4 manual(m6) f 20 31 p compact ## 4 audi a4 2 2008 4 auto(av) f 21 30 p compact ## 5 audi a4 2.8 1999 6 auto(l5) f 16 26 p compact ## 6 audi a4 2.8 1999 6 manual(m5) f 18 26 p compact ## 7 audi a4 3.1 2008 6 auto(av) f 18 27 p compact ## 8 audi a4 quattro 1.8 1999 4 manual(m5) 4 18 26 p compact ## 9 audi a4 quattro 1.8 1999 4 auto(l5) 4 16 25 p compact ## 10 audi a4 quattro 2 2008 4 manual(m6) 4 20 28 p compact ## # … with 224 more rows And to filter for all rows with a missing value in at least one column: mpg %&gt;% filter( !complete.cases(.) ) ## # A tibble: 0 x 11 ## # … with 11 variables: manufacturer &lt;chr&gt;, model &lt;chr&gt;, displ &lt;dbl&gt;, year &lt;int&gt;, cyl &lt;int&gt;, trans &lt;chr&gt;, ## # drv &lt;chr&gt;, cty &lt;int&gt;, hwy &lt;int&gt;, fl &lt;chr&gt;, class &lt;chr&gt; 5.2 select() Whereas filter() subsets a dataframe by row, select() returns a subset of the columns. This function can take column names (even without quotes), or the column position number beginning at left. Further, unlike in base R, commands within the brackets in select() do not need to be concatenated using c(). Let’s extract the car model, engine volume (displ) and highway mileage (hwy) from mpg_df: mpg_df %&gt;% select(model, displ, hwy) ## # A tibble: 234 x 3 ## model displ hwy ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 a4 1.8 29 ## 2 a4 1.8 29 ## 3 a4 2 31 ## 4 a4 2 30 ## 5 a4 2.8 26 ## 6 a4 2.8 26 ## 7 a4 3.1 27 ## 8 a4 quattro 1.8 26 ## 9 a4 quattro 1.8 25 ## 10 a4 quattro 2 28 ## # … with 224 more rows We can use ‘-’ to extract all except particular column(s). For example, to drop the model and year columns: mpg_df %&gt;% select(-model, -year) ## # A tibble: 234 x 9 ## manufacturer displ cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi 1.8 4 auto(l5) f 18 29 p compact ## 2 audi 1.8 4 manual(m5) f 21 29 p compact ## 3 audi 2 4 manual(m6) f 20 31 p compact ## 4 audi 2 4 auto(av) f 21 30 p compact ## 5 audi 2.8 6 auto(l5) f 16 26 p compact ## 6 audi 2.8 6 manual(m5) f 18 26 p compact ## 7 audi 3.1 6 auto(av) f 18 27 p compact ## 8 audi 1.8 4 manual(m5) 4 18 26 p compact ## 9 audi 1.8 4 auto(l5) 4 16 25 p compact ## 10 audi 2 4 manual(m6) 4 20 28 p compact ## # … with 224 more rows We can also specify column positions. Take the data in columns number 1,5 and 11 mpg_df %&gt;% select(1,5,11) ## # A tibble: 234 x 3 ## manufacturer cyl class ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 audi 4 compact ## 2 audi 4 compact ## 3 audi 4 compact ## 4 audi 4 compact ## 5 audi 6 compact ## 6 audi 6 compact ## 7 audi 6 compact ## 8 audi 4 compact ## 9 audi 4 compact ## 10 audi 4 compact ## # … with 224 more rows Or combine column positions and names: mpg_df %&gt;% select(1,3, cty, hwy) ## # A tibble: 234 x 4 ## manufacturer displ cty hwy ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 audi 1.8 18 29 ## 2 audi 1.8 21 29 ## 3 audi 2 20 31 ## 4 audi 2 21 30 ## 5 audi 2.8 16 26 ## 6 audi 2.8 18 26 ## 7 audi 3.1 18 27 ## 8 audi 1.8 18 26 ## 9 audi 1.8 16 25 ## 10 audi 2 20 28 ## # … with 224 more rows 5.2.1 contains() helper function contains() is a helper function used with select(), which is analogous to the str_detect() helper used with filter(). To select only columns with names containing the letter ‘y’: mpg_df %&gt;% select(contains(&#39;y&#39;)) ## # A tibble: 234 x 4 ## year cyl cty hwy ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1999 4 18 29 ## 2 1999 4 21 29 ## 3 2008 4 20 31 ## 4 2008 4 21 30 ## 5 1999 6 16 26 ## 6 1999 6 18 26 ## 7 2008 6 18 27 ## 8 1999 4 18 26 ## 9 1999 4 16 25 ## 10 2008 4 20 28 ## # … with 224 more rows contains() is also useful for selecting all column names featuring a certain character, e.g. contains(’_’) 5.2.2 starts_with() helper function start_with() and ends_with() offer more specificity for select(). If we want all columns beginning with the letter ‘c’: mpg_df %&gt;% select(starts_with(&#39;c&#39;)) ## # A tibble: 234 x 3 ## cyl cty class ## &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 4 18 compact ## 2 4 21 compact ## 3 4 20 compact ## 4 4 21 compact ## 5 6 16 compact ## 6 6 18 compact ## 7 6 18 compact ## 8 4 18 compact ## 9 4 16 compact ## 10 4 20 compact ## # … with 224 more rows Happily we can even mix these helper functions with the standard select commands: mpg_df %&gt;% select( 2, 1, class, contains(&#39;y&#39;)) ## # A tibble: 234 x 7 ## model manufacturer class year cyl cty hwy ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 a4 audi compact 1999 4 18 29 ## 2 a4 audi compact 1999 4 21 29 ## 3 a4 audi compact 2008 4 20 31 ## 4 a4 audi compact 2008 4 21 30 ## 5 a4 audi compact 1999 6 16 26 ## 6 a4 audi compact 1999 6 18 26 ## 7 a4 audi compact 2008 6 18 27 ## 8 a4 quattro audi compact 1999 4 18 26 ## 9 a4 quattro audi compact 1999 4 16 25 ## 10 a4 quattro audi compact 2008 4 20 28 ## # … with 224 more rows 5.2.3 everything() helper function Lastly for select(), a very useful helper is the everything() function, which returns all column names that have not been specified. It is often used when reordering all columns in a dataframe: mpg_df %&gt;% select(class,displ,year,everything()) ## # A tibble: 234 x 11 ## class displ year manufacturer model cyl trans drv cty hwy fl ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 compact 1.8 1999 audi a4 4 auto(l5) f 18 29 p ## 2 compact 1.8 1999 audi a4 4 manual(m5) f 21 29 p ## 3 compact 2 2008 audi a4 4 manual(m6) f 20 31 p ## 4 compact 2 2008 audi a4 4 auto(av) f 21 30 p ## 5 compact 2.8 1999 audi a4 6 auto(l5) f 16 26 p ## 6 compact 2.8 1999 audi a4 6 manual(m5) f 18 26 p ## 7 compact 3.1 2008 audi a4 6 auto(av) f 18 27 p ## 8 compact 1.8 1999 audi a4 quattro 4 manual(m5) 4 18 26 p ## 9 compact 1.8 1999 audi a4 quattro 4 auto(l5) 4 16 25 p ## 10 compact 2 2008 audi a4 quattro 4 manual(m6) 4 20 28 p ## # … with 224 more rows Note that the dimensions of the dataframe have not changed, merely the column order. 5.3 arrange() arrange() is the simplest of the dplyr functions, which orders rows according to values in a given column. The default is to order numbers from lowest -&gt; highest. Let’s try ordering the vehicles by engine size (displ) mpg_df %&gt;% arrange(displ) ## # A tibble: 234 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 honda civic 1.6 1999 4 manual(m5) f 28 33 r subcompact ## 2 honda civic 1.6 1999 4 auto(l4) f 24 32 r subcompact ## 3 honda civic 1.6 1999 4 manual(m5) f 25 32 r subcompact ## 4 honda civic 1.6 1999 4 manual(m5) f 23 29 p subcompact ## 5 honda civic 1.6 1999 4 auto(l4) f 24 32 r subcompact ## 6 audi a4 1.8 1999 4 auto(l5) f 18 29 p compact ## 7 audi a4 1.8 1999 4 manual(m5) f 21 29 p compact ## 8 audi a4 quattro 1.8 1999 4 manual(m5) 4 18 26 p compact ## 9 audi a4 quattro 1.8 1999 4 auto(l5) 4 16 25 p compact ## 10 honda civic 1.8 2008 4 manual(m5) f 26 34 r subcompact ## # … with 224 more rows We can refine the order by giving additional columns of data. To order rows by manufacturer name (alphabetical), then by engine size then by city mileage: mpg_df %&gt;% arrange(manufacturer, displ, cty ) ## # A tibble: 234 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 quattro 1.8 1999 4 auto(l5) 4 16 25 p compact ## 2 audi a4 1.8 1999 4 auto(l5) f 18 29 p compact ## 3 audi a4 quattro 1.8 1999 4 manual(m5) 4 18 26 p compact ## 4 audi a4 1.8 1999 4 manual(m5) f 21 29 p compact ## 5 audi a4 quattro 2 2008 4 auto(s6) 4 19 27 p compact ## 6 audi a4 2 2008 4 manual(m6) f 20 31 p compact ## 7 audi a4 quattro 2 2008 4 manual(m6) 4 20 28 p compact ## 8 audi a4 2 2008 4 auto(av) f 21 30 p compact ## 9 audi a4 quattro 2.8 1999 6 auto(l5) 4 15 25 p compact ## 10 audi a6 quattro 2.8 1999 6 auto(l5) 4 15 24 p midsize ## # … with 224 more rows 5.3.1 desc() helper function To invert the standard order, we can use the ‘descending’ desc() helper function. To find the most fuel-efficient vehicles when on the highway, we could use: mpg_df %&gt;% arrange(desc(hwy)) ## # A tibble: 234 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 volkswagen jetta 1.9 1999 4 manual(m5) f 33 44 d compact ## 2 volkswagen new beetle 1.9 1999 4 manual(m5) f 35 44 d subcompact ## 3 volkswagen new beetle 1.9 1999 4 auto(l4) f 29 41 d subcompact ## 4 toyota corolla 1.8 2008 4 manual(m5) f 28 37 r compact ## 5 honda civic 1.8 2008 4 auto(l5) f 25 36 r subcompact ## 6 honda civic 1.8 2008 4 auto(l5) f 24 36 c subcompact ## 7 toyota corolla 1.8 1999 4 manual(m5) f 26 35 r compact ## 8 toyota corolla 1.8 2008 4 auto(l4) f 26 35 r compact ## 9 honda civic 1.8 2008 4 manual(m5) f 26 34 r subcompact ## 10 honda civic 1.6 1999 4 manual(m5) f 28 33 r subcompact ## # … with 224 more rows 5.4 Chaining dplyr functions Coding from left-to-right using the pipe %&gt;% allows us to make ‘chains’ of commands to achieve very specific results. Let’s filter for the midsize vehicles, then select the columns class, manufacturer, displ and year, and arrange on engine size (displ): mpg_df %&gt;% filter(class==&#39;midsize&#39;) %&gt;% select(class,manufacturer,displ,year) %&gt;% arrange(displ) ## # A tibble: 41 x 4 ## class manufacturer displ year ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 midsize volkswagen 1.8 1999 ## 2 midsize volkswagen 1.8 1999 ## 3 midsize volkswagen 2 2008 ## 4 midsize volkswagen 2 2008 ## 5 midsize toyota 2.2 1999 ## 6 midsize toyota 2.2 1999 ## 7 midsize chevrolet 2.4 1999 ## 8 midsize chevrolet 2.4 2008 ## 9 midsize hyundai 2.4 1999 ## 10 midsize hyundai 2.4 1999 ## # … with 31 more rows Using line-breaks makes the order of operations very easy to read (and fix if necessary). Once we’re happy with the output of this chain of functions, we can assign it to a new object (aka variable) in the environment: mpg_slim &lt;- mpg_df %&gt;% filter(class==&#39;midsize&#39;) %&gt;% select(class,manufacturer,displ,year) %&gt;% arrange(displ) Note that all of the functions will be performed before the output is assigned into mpg_slim. Therefore even though mpg_slim is at the top of the code, it will contain the final output dataframe. 5.5 Writing data to a file The new mpg_slim data frame could be saved to a file outside of the R session using write_tsv() write_tsv() creates a tab-separated file that can be read by applications like Excel. We first give the variable name, then the file name (ideally with a full directory location): On Mac: write_tsv(mpg_slim, &#39;~/Desktop/mpg_slim_dataframe.tsv&#39;) On PC: write_tsv(mpg_slim, &#39;C:/Users/ansell.b/Desktop/mpg_slim_dataframe.tsv&#39;) We will learn how to read data in to R in the next chapter. 5.6 Chaining dplyr and ggplot We can also send the dplyr output directly into ggplot! mpg_df %&gt;% filter(class==&#39;midsize&#39;) %&gt;% select(class,manufacturer,displ,year) %&gt;% arrange(displ) %&gt;% ggplot(aes(x=class,y=displ)) + geom_boxplot() Whereas this is very useful for quickly manipulating and plotting data, for readability you might prefer to separate the dplyr commands from the ggplot commands like so: #first create smaller dataset mpg_slim &lt;- mpg_df %&gt;% filter(class==&#39;midsize&#39;) %&gt;% select(class,manufacturer,displ,year) %&gt;% arrange(displ) #then plot the distribution of engine volumes of &#39;midsize&#39; cars mpg_slim %&gt;% ggplot(aes(x=class,y=displ)) + geom_boxplot() 5.7 mutate() Whereas the the verbs we’ve covered so far modify the dimensions and order of the existing data frame, mutate() adds new columns of data, thus ‘mutating’ the contents and dimensions of the input data frame. To explore mutate we will use the diamond_df data frame from earlier. You can recreate if necessary: diamond_df &lt;- ggplot2::diamonds The price column for these diamonds is in US dollars. If we want to convert the price to Australian dollars we can (optimistically) multiply USD by 1.25. Here we create a new column called AUD, which will contain a new column where each row = price * 1.25. Because the number of columns is expanding, to easily see the results we can first drop the x/y/z dimension columns using select() diamond_df %&gt;% select(-x, -y, -z) %&gt;% mutate(AUD = price * 1.25) ## # A tibble: 53,940 x 8 ## carat cut color clarity depth table price AUD ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 408. ## 2 0.21 Premium E SI1 59.8 61 326 408. ## 3 0.23 Good E VS1 56.9 65 327 409. ## 4 0.29 Premium I VS2 62.4 58 334 418. ## 5 0.31 Good J SI2 63.3 58 335 419. ## 6 0.24 Very Good J VVS2 62.8 57 336 420 ## 7 0.24 Very Good I VVS1 62.3 57 336 420 ## 8 0.26 Very Good H SI1 61.9 55 337 421. ## 9 0.22 Fair E VS2 65.1 61 337 421. ## 10 0.23 Very Good H VS1 59.4 61 338 422. ## # … with 53,930 more rows We can also perform operations using only the data in existing columns. Here as above, the newly created column will contain the results of a mathematical operation, performed row by row. Let’s calculate the US dollars per carat (‘ppc’) by dividing the price column by the carat column diamond_df %&gt;% select(-x,-y,-z) %&gt;% mutate(ppc = price/carat) ## # A tibble: 53,940 x 8 ## carat cut color clarity depth table price ppc ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 1417. ## 2 0.21 Premium E SI1 59.8 61 326 1552. ## 3 0.23 Good E VS1 56.9 65 327 1422. ## 4 0.29 Premium I VS2 62.4 58 334 1152. ## 5 0.31 Good J SI2 63.3 58 335 1081. ## 6 0.24 Very Good J VVS2 62.8 57 336 1400 ## 7 0.24 Very Good I VVS1 62.3 57 336 1400 ## 8 0.26 Very Good H SI1 61.9 55 337 1296. ## 9 0.22 Fair E VS2 65.1 61 337 1532. ## 10 0.23 Very Good H VS1 59.4 61 338 1470. ## # … with 53,930 more rows 5.7.1 Challenge One carat weighs 0.2 grams. Can you chain multiple mutate() functions together to calculate for each diamond, the Australian Dollars per gram? 5.7.2 Solution diamond_df %&gt;% select(-x,-y,-z) %&gt;% mutate(grams = 0.2 * carat) %&gt;% mutate(AUD = price * 1.25) %&gt;% mutate(aud_per_gram = AUD/grams) ## # A tibble: 53,940 x 10 ## carat cut color clarity depth table price grams AUD aud_per_gram ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 0.046 408. 8859. ## 2 0.21 Premium E SI1 59.8 61 326 0.042 408. 9702. ## 3 0.23 Good E VS1 56.9 65 327 0.046 409. 8886. ## 4 0.29 Premium I VS2 62.4 58 334 0.058 418. 7198. ## 5 0.31 Good J SI2 63.3 58 335 0.062 419. 6754. ## 6 0.24 Very Good J VVS2 62.8 57 336 0.048 420 8750 ## 7 0.24 Very Good I VVS1 62.3 57 336 0.048 420 8750 ## 8 0.26 Very Good H SI1 61.9 55 337 0.052 421. 8101. ## 9 0.22 Fair E VS2 65.1 61 337 0.044 421. 9574. ## 10 0.23 Very Good H VS1 59.4 61 338 0.046 422. 9185. ## # … with 53,930 more rows 5.7.3 ifelse() helper The mutate() function is very useful for making a new column of labels for the existing data. For example, to label outliers, or a sub-set of genes with particular characteristics. This is where ifelse() comes in. ifelse() is a function that tests each value in a column of data for a particular condition (a logical test), and returns one answer when the condition==TRUE, and another when the condition==FALSE. Specifically, ifelse() takes three commands: the condition to test, the output when TRUE, and the output when FALSE. To see how this works let’s create a label for each diamond depending on whether we consider it ‘expensive’ (&gt; $5000) or ‘cheap’ (&lt; $5000). diamond_df %&gt;% select(-x,-y,-z) %&gt;% mutate(price_label = ifelse(price &gt; 5000, &#39;expensive&#39;, &#39;cheap&#39;)) ## # A tibble: 53,940 x 8 ## carat cut color clarity depth table price price_label ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 cheap ## 2 0.21 Premium E SI1 59.8 61 326 cheap ## 3 0.23 Good E VS1 56.9 65 327 cheap ## 4 0.29 Premium I VS2 62.4 58 334 cheap ## 5 0.31 Good J SI2 63.3 58 335 cheap ## 6 0.24 Very Good J VVS2 62.8 57 336 cheap ## 7 0.24 Very Good I VVS1 62.3 57 336 cheap ## 8 0.26 Very Good H SI1 61.9 55 337 cheap ## 9 0.22 Fair E VS2 65.1 61 337 cheap ## 10 0.23 Very Good H VS1 59.4 61 338 cheap ## # … with 53,930 more rows Remember that we need two closing brackets, one for the mutate() function, and one for the ifelse() inside it. It seems that the ifelse() function has worked. All the rows we can see are price &lt; 5000 and labelled ‘cheap’. But how can we be sure? One option to check the new labels is to plot the price column as a histogram, and fill the bars according to price_label: diamond_df %&gt;% select(-x,-y,-z) %&gt;% mutate(price_label = ifelse(price &gt; 5000,&#39;expensive&#39;,&#39;cheap&#39;)) %&gt;% ggplot(aes(x=price, fill = price_label)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Now we can be confident that ifelse() command has worked as intended. Another option for checking output is to use count(), which will be introduced below. 5.7.4 case_when() helper This function is useful but quite involved. I’m including it here for completeness, however beginners can feel free to skip down to the summarize() section and return to case_when() later. At times we want to create a label column that tests multiple conditions. We can either put multiple ifelse() commands inside each other (and go mad), or use case_when()! This command takes multiple conditions and tests them in order. This is important to remember as all rows that satisfy the first condition will be tagged as such. There may be rows that satisfy more than one condition, so you should order the tests from specific to general, and keep track of how those ambiguous rows are being treated. case_when() takes a conditional command in the same format as the first command in ifelse(), however only the action for the TRUE condition is given, separated with a tilde ~. The catch-all command for rows that do not satisfy any other conditions, is given at the end. Let’s use case_when() to make a label for diamonds based on their clarity super-groups. For simplicity, we select only the clarity column as input. The current clarity categories are: IF: internally flawless VVS1 and 2: very very slight impurity 1 and 2 VS1 and 2: very slight impurity 1 and 2 SI1 and 2: slight impurity 1 and 2 I1: impurity Note that we are searching for similar conditions (‘VVS’ contains ‘VS’) and will have to be careful with the order of conditions. To create the super-groupings we will use a combination of str_detect() and equality == conditions. diamond_df %&gt;% select(clarity) %&gt;% mutate(clarity_group = case_when(clarity == &#39;IF&#39; ~ &#39;flawless&#39;, str_detect(clarity, &#39;VVS&#39;) ~ &#39;VV_slight&#39;, str_detect(clarity, &#39;VS&#39;) ~ &#39;V_slight&#39;, str_detect(clarity, &#39;SI&#39;) ~ &#39;slight&#39;, clarity == &#39;I1&#39; ~ &#39;impurity&#39;, TRUE ~ &#39;other&#39;)) ## # A tibble: 53,940 x 2 ## clarity clarity_group ## &lt;ord&gt; &lt;chr&gt; ## 1 SI2 slight ## 2 SI1 slight ## 3 VS1 V_slight ## 4 VS2 V_slight ## 5 SI2 slight ## 6 VVS2 VV_slight ## 7 VVS1 VV_slight ## 8 SI1 slight ## 9 VS2 V_slight ## 10 VS1 V_slight ## # … with 53,930 more rows Note that both VS1 and VS2 diamonds are now tagged as ‘V_slight’, and similarly VVS1 and VVS2 are tagged as ‘VV_slight’. Because we have captured all clarity categories within the list of conditions, we don’t expect the catch-all output, “other”, to be present in the clarity_group column. We could use %&gt;% count(clarity_group), introduced below, to check for the presence of unintended values such as ‘other’ or NA. These super-groups could now be used for colouring or faceting data in a plot, or creating summary statistics (see below). 5.8 summarize() The last of the dplyr verbs is summarize(), which as the name suggests, creates individual summary statistics from larger data sets. As for mutate(), the output of summarize() is qualitatively different from the input: it is generally a smaller dataframe with a reduced representation of the input data. Importantly, even though the output of summarize() can be very small, it is still a dataframe. Although not essential, it is also a good idea to specify new column names for the summary statistics that this function creates. First we will calculate the mean price for the diamond_df dataframe by specifying a name for the new data, and then the function we want to apply to the price column: diamond_df %&gt;% summarize(mean_price = mean(price)) ## # A tibble: 1 x 1 ## mean_price ## &lt;dbl&gt; ## 1 3933. The output is the smallest possible dataframe: 1 row X 1 column. We can create additional summary statistics by adding them in a comma-separated sequence. For example, to calculate the standard deviation, minimum and maximum values, we create three additional columns: “sd_price”, “min_price”, and “max_price” diamond_df %&gt;% summarize(mean_price = mean(price), sd_price = sd(price), min_price = min(price), max_price = max(price)) ## # A tibble: 1 x 4 ## mean_price sd_price min_price max_price ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 3933. 3989. 326 18823 5.8.1 n() helper When using summarize(), we can also count the number of rows being summarized, which can be important for interpreting the associated statistics. The simple function n() never takes any additional code, but simply counts rows: diamond_df %&gt;% summarize(mean_price = mean(price), sd_price = sd(price), min_price = min(price), max_price = max(price), n_rows = n()) ## # A tibble: 1 x 5 ## mean_price sd_price min_price max_price n_rows ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 3933. 3989. 326 18823 53940 So far so good, however this seems like quite a lot of code to get the simple summary statistics. The power of this function is really amplified in conjunction with the group_by() helper. 5.9 group_by() helper Although I’ve called group_by() a helper function, it is key to unleashing the power of nearly all dplyr functions. group_by() allows us to create sub-groups based on labels in a particular column, and to run subsequent functions on all sub-groups. It is conceptually similar to facet_wrap() in ggplot, which applies the same plotting command to multiple subsets of the input dataframe. For example the figure below is using group_by() as the first arrow, and summarize() as the second arrow. Three sub-groups, corresponding to e.g. three categories in column 1, are represented in the light grey, blue and green rows. A summarize() command is then run on each sub-group, producing a results dataframe with only three rows, and new (dark blue) column names indicating the summary statistic. For those interested in more details, group_by() is essentially creating a separate dataframe for each category in a specified column. To see this at work, look the structure str() of the diamonds data before and after grouping: diamond_df %&gt;% str() ## tibble[,10] [53,940 × 10] (S3: tbl_df/tbl/data.frame) ## $ carat : num [1:53940] 0.23 0.21 0.23 0.29 0.31 0.24 0.24 0.26 0.22 0.23 ... ## $ cut : Ord.factor w/ 5 levels &quot;Fair&quot;&lt;&quot;Good&quot;&lt;..: 5 4 2 4 2 3 3 3 1 3 ... ## $ color : Ord.factor w/ 7 levels &quot;D&quot;&lt;&quot;E&quot;&lt;&quot;F&quot;&lt;&quot;G&quot;&lt;..: 2 2 2 6 7 7 6 5 2 5 ... ## $ clarity: Ord.factor w/ 8 levels &quot;I1&quot;&lt;&quot;SI2&quot;&lt;&quot;SI1&quot;&lt;..: 2 3 5 4 2 6 7 3 4 5 ... ## $ depth : num [1:53940] 61.5 59.8 56.9 62.4 63.3 62.8 62.3 61.9 65.1 59.4 ... ## $ table : num [1:53940] 55 61 65 58 58 57 57 55 61 61 ... ## $ price : int [1:53940] 326 326 327 334 335 336 336 337 337 338 ... ## $ x : num [1:53940] 3.95 3.89 4.05 4.2 4.34 3.94 3.95 4.07 3.87 4 ... ## $ y : num [1:53940] 3.98 3.84 4.07 4.23 4.35 3.96 3.98 4.11 3.78 4.05 ... ## $ z : num [1:53940] 2.43 2.31 2.31 2.63 2.75 2.48 2.47 2.53 2.49 2.39 ... We have a single dataframe with 54K rows. Now we group by cut: diamond_df %&gt;% group_by(cut) %&gt;% str() ## grouped_df[,10] [53,940 × 10] (S3: grouped_df/tbl_df/tbl/data.frame) ## $ carat : num [1:53940] 0.23 0.21 0.23 0.29 0.31 0.24 0.24 0.26 0.22 0.23 ... ## $ cut : Ord.factor w/ 5 levels &quot;Fair&quot;&lt;&quot;Good&quot;&lt;..: 5 4 2 4 2 3 3 3 1 3 ... ## $ color : Ord.factor w/ 7 levels &quot;D&quot;&lt;&quot;E&quot;&lt;&quot;F&quot;&lt;&quot;G&quot;&lt;..: 2 2 2 6 7 7 6 5 2 5 ... ## $ clarity: Ord.factor w/ 8 levels &quot;I1&quot;&lt;&quot;SI2&quot;&lt;&quot;SI1&quot;&lt;..: 2 3 5 4 2 6 7 3 4 5 ... ## $ depth : num [1:53940] 61.5 59.8 56.9 62.4 63.3 62.8 62.3 61.9 65.1 59.4 ... ## $ table : num [1:53940] 55 61 65 58 58 57 57 55 61 61 ... ## $ price : int [1:53940] 326 326 327 334 335 336 336 337 337 338 ... ## $ x : num [1:53940] 3.95 3.89 4.05 4.2 4.34 3.94 3.95 4.07 3.87 4 ... ## $ y : num [1:53940] 3.98 3.84 4.07 4.23 4.35 3.96 3.98 4.11 3.78 4.05 ... ## $ z : num [1:53940] 2.43 2.31 2.31 2.63 2.75 2.48 2.47 2.53 2.49 2.39 ... ## - attr(*, &quot;groups&quot;)= tibble[,2] [5 × 2] (S3: tbl_df/tbl/data.frame) ## ..$ cut : Ord.factor w/ 5 levels &quot;Fair&quot;&lt;&quot;Good&quot;&lt;..: 1 2 3 4 5 ## ..$ .rows: list&lt;int&gt; [1:5] ## .. ..$ : int [1:1610] 9 92 98 124 125 129 130 205 228 242 ... ## .. ..$ : int [1:4906] 3 5 11 18 19 21 36 37 38 43 ... ## .. ..$ : int [1:12082] 6 7 8 10 20 22 23 24 25 26 ... ## .. ..$ : int [1:13791] 2 4 13 15 16 27 46 54 55 57 ... ## .. ..$ : int [1:21551] 1 12 14 17 40 41 42 52 53 56 ... ## .. ..@ ptype: int(0) ## ..- attr(*, &quot;.drop&quot;)= logi TRUE The output of group_by() is a ‘grouped_df’ and all functions following will be applied separately to each sub-dataframe. 5.9.1 group_by() %&gt;% summarize() Returning to the above summarize() function, we can now quickly generate summary statistics for the diamonds in each clarity category by first grouping on this column name. diamond_df %&gt;% group_by(clarity) %&gt;% summarize(mean_price = mean(price), sd_price = sd(price), min_price = min(price), max_price = max(price), n_rows = n()) ## # A tibble: 8 x 6 ## clarity mean_price sd_price min_price max_price n_rows ## &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 I1 3924. 2807. 345 18531 741 ## 2 SI2 5063. 4260. 326 18804 9194 ## 3 SI1 3996. 3799. 326 18818 13065 ## 4 VS2 3925. 4042. 334 18823 12258 ## 5 VS1 3839. 4012. 327 18795 8171 ## 6 VVS2 3284. 3822. 336 18768 5066 ## 7 VVS1 2523. 3335. 336 18777 3655 ## 8 IF 2865. 3920. 369 18806 1790 Huzzah! By adding this simple command before summarize() we’ve created detailed statistics on each clarity category. We could split the input data further by grouping on more than one column. For example, what are the summary statistics for each clarity category within each cut? diamond_df %&gt;% group_by(clarity, cut) %&gt;% summarize(mean_price = mean(price), sd_price = sd(price), min_price = min(price), max_price = max(price), n_rows = n()) ## `summarise()` has grouped output by &#39;clarity&#39;. You can override using the `.groups` argument. ## # A tibble: 40 x 7 ## # Groups: clarity [8] ## clarity cut mean_price sd_price min_price max_price n_rows ## &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 I1 Fair 3704. 3099. 584 18531 210 ## 2 I1 Good 3597. 2285. 361 11548 96 ## 3 I1 Very Good 4078. 2720. 511 15984 84 ## 4 I1 Premium 3947. 2827. 345 16193 205 ## 5 I1 Ideal 4336. 2671. 413 16538 146 ## 6 SI2 Fair 5174. 3928. 536 18308 466 ## 7 SI2 Good 4580. 3901. 335 18788 1081 ## 8 SI2 Very Good 4989. 4126. 383 18692 2100 ## 9 SI2 Premium 5546. 4488. 345 18784 2949 ## 10 SI2 Ideal 4756. 4252. 326 18804 2598 ## # … with 30 more rows We now have 40 rows of summary statistics which gives a higher-resolution representation of the input data. 5.9.2 group_by() %&gt;% mutate() As mentioned, group_by() is compatible with all other dplyr functions. Sometimes we want both the original data and the summary statistics in the output data frame. To do this, group_by() can be combined with mutate(), to make a new column of summary statistics (repeated many times) corresponding to the sub-grouping of interest. The new column of summary statistics is represented in darker colours in the right panel below. To create a column containing the mean price for diamonds in each cut category in addition to the input data, we can use group_by() before mutate(): diamond_df %&gt;% select(-x,-y,-z) %&gt;% group_by(cut) %&gt;% mutate(cut_meanprice = mean(price)) ## # A tibble: 53,940 x 8 ## # Groups: cut [5] ## carat cut color clarity depth table price cut_meanprice ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3458. ## 2 0.21 Premium E SI1 59.8 61 326 4584. ## 3 0.23 Good E VS1 56.9 65 327 3929. ## 4 0.29 Premium I VS2 62.4 58 334 4584. ## 5 0.31 Good J SI2 63.3 58 335 3929. ## 6 0.24 Very Good J VVS2 62.8 57 336 3982. ## 7 0.24 Very Good I VVS1 62.3 57 336 3982. ## 8 0.26 Very Good H SI1 61.9 55 337 3982. ## 9 0.22 Fair E VS2 65.1 61 337 4359. ## 10 0.23 Very Good H VS1 59.4 61 338 3982. ## # … with 53,930 more rows The new column now contains one of five possible values depending on the cut column. From this we could then use a second mutate() to calculate the difference between each diamond price and the mean price for its cut category: diamond_df %&gt;% select(-x,-y,-z) %&gt;% group_by(cut) %&gt;% mutate(cut_meanprice = mean(price)) %&gt;% mutate(price_diff = price - cut_meanprice) ## # A tibble: 53,940 x 9 ## # Groups: cut [5] ## carat cut color clarity depth table price cut_meanprice price_diff ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3458. -3132. ## 2 0.21 Premium E SI1 59.8 61 326 4584. -4258. ## 3 0.23 Good E VS1 56.9 65 327 3929. -3602. ## 4 0.29 Premium I VS2 62.4 58 334 4584. -4250. ## 5 0.31 Good J SI2 63.3 58 335 3929. -3594. ## 6 0.24 Very Good J VVS2 62.8 57 336 3982. -3646. ## 7 0.24 Very Good I VVS1 62.3 57 336 3982. -3646. ## 8 0.26 Very Good H SI1 61.9 55 337 3982. -3645. ## 9 0.22 Fair E VS2 65.1 61 337 4359. -4022. ## 10 0.23 Very Good H VS1 59.4 61 338 3982. -3644. ## # … with 53,930 more rows 5.9.3 ungroup() helper When running longer dplyr chains it is good practice to ungroup the data after the group_by() operations are run. To do this simply add %&gt;% ungroup() at the end of the code block. Inappropriate preservation of groupings can sometimes cause your code to run very slowly and give unexpected results. 5.9.4 count() helper count() is a shortcut function that combines group_by() and summarize(), which is useful for counting ‘character data’, e.g. labels. To quickly count the number of diamonds in each cut category: diamond_df %&gt;% count(cut) ## # A tibble: 5 x 2 ## cut n ## &lt;ord&gt; &lt;int&gt; ## 1 Fair 1610 ## 2 Good 4906 ## 3 Very Good 12082 ## 4 Premium 13791 ## 5 Ideal 21551 And to count the number of diamonds in each cut and clarity category: diamond_df %&gt;% count(cut,clarity) ## # A tibble: 40 x 3 ## cut clarity n ## &lt;ord&gt; &lt;ord&gt; &lt;int&gt; ## 1 Fair I1 210 ## 2 Fair SI2 466 ## 3 Fair SI1 408 ## 4 Fair VS2 261 ## 5 Fair VS1 170 ## 6 Fair VVS2 69 ## 7 Fair VVS1 17 ## 8 Fair IF 9 ## 9 Good I1 96 ## 10 Good SI2 1081 ## # … with 30 more rows Note that the count summary output column name is ‘n’. This reflects that count() is running summarize(n = n()) in the background. 5.9.5 sample_n() helper The final helper for this session is sample_n() which takes a random sample of rows according to the number specified. To sample 10 rows from the entire diamond_df dataset: diamond_df %&gt;% sample_n(10) ## # A tibble: 10 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.4 Very Good E VVS2 63 55 849 4.72 4.74 2.98 ## 2 0.51 Very Good G VS1 62.9 58 1656 5.05 5.1 3.19 ## 3 1.75 Premium J VS1 62.2 59 10619 7.74 7.7 4.8 ## 4 0.7 Ideal I VVS1 62.3 55 2536 5.7 5.64 3.53 ## 5 0.42 Very Good I VS1 60.4 60 791 4.82 4.88 2.93 ## 6 0.31 Good I SI1 63.3 53 408 4.3 4.32 2.73 ## 7 1.07 Ideal E SI2 61.7 57 4374 6.59 6.56 4.06 ## 8 1.01 Good H SI2 63.9 58 3959 6.35 6.32 4.05 ## 9 1.56 Premium G VS1 60.9 58 14268 7.53 7.49 4.57 ## 10 1.01 Premium F SI2 62.2 59 4497 6.42 6.38 3.98 It can be more useful to sample rows from within sub-groups, by combining group_by() and sample_n(). Let’s take 2 rows at random from each cut category: diamond_df %&gt;% group_by(cut) %&gt;% sample_n(2) ## # A tibble: 10 x 10 ## # Groups: cut [5] ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2.01 Fair H SI2 66.7 56 10772 7.8 7.76 5.19 ## 2 1.5 Fair H SI1 65.9 56 7211 7.11 7.04 4.66 ## 3 0.91 Good G VVS2 64.1 58 4543 6.06 6.1 3.9 ## 4 1 Good F VS1 64.8 59 5829 6.17 6.23 4.02 ## 5 0.33 Very Good G SI2 59.4 59 434 4.5 4.52 2.68 ## 6 0.5 Very Good E VVS2 61.5 59 2105 5.08 5.1 3.13 ## 7 1.69 Premium F VS2 58.7 59 16583 7.87 7.78 4.59 ## 8 0.3 Premium G VS1 61.9 59 776 4.32 4.28 2.66 ## 9 1.57 Ideal E VS2 60.5 57 17548 7.53 7.57 4.57 ## 10 0.52 Ideal G SI1 61.7 56 1266 5.18 5.22 3.21 5.10 Challenges What is the weight of the most expensive diamond in each clarity category? Summarize the standard deviation of diamond weight in each cut category. A z score is the (sample value - mean)/sd. Can you create a z score for the weight of each diamond relative to others of that cut? What does the density distribution of z scores look like for each cut? 5.11 Solutions diamond_df %&gt;% group_by(clarity) %&gt;% summarize(maxPrice = max(price)) ## # A tibble: 8 x 2 ## clarity maxPrice ## &lt;ord&gt; &lt;int&gt; ## 1 I1 18531 ## 2 SI2 18804 ## 3 SI1 18818 ## 4 VS2 18823 ## 5 VS1 18795 ## 6 VVS2 18768 ## 7 VVS1 18777 ## 8 IF 18806 diamond_df %&gt;% group_by(cut) %&gt;% summarize(sdWt = sd(carat)) ## # A tibble: 5 x 2 ## cut sdWt ## &lt;ord&gt; &lt;dbl&gt; ## 1 Fair 0.516 ## 2 Good 0.454 ## 3 Very Good 0.459 ## 4 Premium 0.515 ## 5 Ideal 0.433 weight_z &lt;- diamond_df %&gt;% group_by(cut) %&gt;% mutate(meanWt=mean(carat), sdWt = sd(carat), z = (carat - meanWt)/sdWt) weight_z %&gt;% ggplot(aes(x=z)) + geom_density(aes(col=cut)) 5.12 Summary Now you have worked through the key verbs of dplyr, and the associated helper functions which, together, allow you to efficiently subset, transform and summarize your data. Whereas the diamond_df and mpg_df dataframes we have worked with so far are self-contained, readily available within R and clean, in the next chapter we will learn to read in external datasets, join different datasets and clean data. 5.13 Cheat sheets! Most of the figures in this chapter are taken from the dplyr cheat sheet. You can pull up a number of cheat sheets by clicking e.g. Help &gt;&gt; Cheatsheets &gt;&gt; Data Visualization with ggplot2 These are fantastic resources compiled by RStudio contributors. You could print these and have them on hand during your R coding work. While these cheat sheets are packed with information, its not immediate obvious how to use them. 5.13.1 ggplot example Say you want to try out geom_text() from the ‘Two Variables’ family of geoms in page 1. The pictogram at left gives a simple example of the shape of this geom, in place of a text description. To test out this geom, we first have to create the variable ‘e’ in bold text. At the top of the panel there is a code snippet for creating e: e &lt;- ggplot(mpg, aes(cty,hwy)) Next we can run the bold code and everything between the bold brackets for geom_text(): e + geom_text(aes(label = cty), nudge_x = 1, nudge_y = 1, check_overlap = TRUE) After the bold brackets are a list of sub-commands (known as ‘arguments’) that can be modified for geom_text(). x, y, alpha and colour will be familiar to you from Week 1. There are many additional arguments we don’t have space to cover, but which have example code in the ?geom_text() Help page. Having created ‘e’, you can also test out geom_quantile(), geom_rug() etc. 5.13.2 dplyr example Now pull up the dplyr cheat sheet: Help &gt;&gt; Cheatsheets &gt;&gt; Data Transformation with dplyr To take the example of sample_n in page 1 of the dplyr cheat sheet. There is a lot of text here, but it can be split up into three parts: The bold text indicates the function name: sample_n. The text inside the bold brackets are the main sub-commands (known as ‘arguments’) that the function requires: sample_n(tbl, size, replace = FALSE, weight = NULL, .env = parent.frame()) The first argument is often tbl, .tbl or .data, referring to the input data frame. The values (= FALSE, = NULL etc.) following each argument are the ‘default’ values - they will be set this way unless the user changes their value. You will see the same argument structure at the top of the Help tab if you run ?sample_n() in RStudio. The normal font text briefly describes what the function does: ‘Randomly select size rows.’ NB this doesn’t really make sense in isolation but will become clearer. The italic font text gives a toy example of working code for this function. If you run the italic code in R you should get a result. The iris, mpg and diamonds data sets come pre-packaged with R, and are ready for use despite not being displayed in the Environment pane. These are the most common data-sets used in the cheat sheets. Note that in this book, the input data is given first, followed by a pipe %&gt;% into a particular function. It is also possible (and more compact) to give the input dataframe as the first argument, which is how the cheat sheet examples are written. sample_n(iris, 10, replace = TRUE) #This can also be written as: iris %&gt;% sample_n(10, replace = TRUE) So based on the cheat sheet explanation, the more elaborate code for sample_n() would be: sample_n(tbl = iris, size = 10, replace = TRUE, weight = NULL, .env = NULL) Finally, although the explanation in 2. is hard to understand, look for ‘size’ in the function argument names, and where that argument appears in the example code. It is set to 10, and the example code returns 10 rows. Given more space, the explanation might read: ‘Randomly select a sample of rows from an input dataframe, of size (n rows) as specified in the size = argument’. 5.14 Extra resources There are several great resources for consolidating and building on the material above. R for Data Science Ch. 5 ‘Data transformation’ Tidyverse resources Introduction to open data science (Ocean Health Index) Jenny Bryan’s STAT545 course notes "],["week-3.html", "Week 3", " Week 3 "],["reading-tidying-joining-data.html", "6 Reading, tidying &amp; joining data 6.1 Reading in data 6.2 Reshaping data 6.3 Separating and uniting columns 6.4 Removing variables 6.5 Joining dataframes 6.6 Plotting challenge 6.7 Solution 6.8 Summary", " 6 Reading, tidying &amp; joining data This session will focus on reading information into R and ‘tidying’ it into a form that makes manipulation and plotting as easy as possible. The tidyr functions within the eponymous tidyverse are designed to help users to convert data into a ‘tidy format’. There are three simple principals for tidy data: each column represents a single measurement type each row represents a single observation each cell contains a single value The context for this session is that your colleague hears that you have successfully completed the first sessions of the WEHI tidyverse R course 😊, and asks you to plot some data for their upcoming lab talk. They send you results from a differential gene expression experiment, and want you to plot the significant genes according to their Gene Ontology (GO) terms. They send you four files: entrez_logFC.xlsx, a results table containing the entrez gene ID, log2 fold-change (logFC) and adjusted P value for each significant gene (Microsoft Excel format) Hs_entrez_annot.csv, the gene names and descriptions for each entrez gene ID (comma-separated values) GO_entrez.txt, the entrez IDs corresponding to different GO terms (space-separated values); and, GO_term_defin.tsv, a table of descriptions for each GO term (tab-separated values) To access these files, download and unzip this folder into your Desktop WEHI_tidyR_course folder. Feel free to open the text files (.csv ; .txt ; .tsv) in TextEdit or another editor to see the data, but make sure not to make any changes. Unfortunately not all of the files come in a tidy form, so we will need to improve them according to the tidy data principals using the functions below, and then join them together to make the final plot. First let’s create a new .R text file, save as ‘Week_3_tidyverse.R’ in the WEHI_tidyR_course folder, and load the tidyverse package library(tidyverse) Now we can read the data files into R. 6.1 Reading in data 6.1.1 read_excel() Broadly speaking there are two ways to read an excel file into R. You can click ‘Import Dataset’ in the Environment tab (top right pane) &gt;&gt; ‘From Excel…’ &gt;&gt; ‘Browse…’ &gt;&gt; navigate to your WEHI_tidyR_course folder and select the file ‘entrez_logFC.xlsx’. In the ‘Options’ section check ‘First row as names’, then click ‘Import’. The excel table is now imported into a variable called ‘entrez_logFC’ and you will see that code appears in the console similar to this: library(readxl) entrez_logFC &lt;- read_excel(&quot;~/Desktop/WEHI_tidyR_course/data_files/entrez_logFC.xlsx&quot;) You can copy and paste this code into your R text file so that next time you run your code, the table is imported without you having to go through the point-and-click route. The alternative way is to directly type and run the code as it appears above. Importantly, although the readxl library is part of the tidyverse package, it is not active unless we load it directly, using library(readxl). Your colleague has also provide text files in the form of csv (comma-separated values), tsv (tab-separated values), and txt (space-separated values), which require slightly different read functions. 6.1.2 read_csv() The read_csv() function from tidyr is used when you select ‘Import Dataset’ &gt;&gt; ‘From text (readr)…’ and set the ‘Import Options’ Delimiter to ‘comma’. Alternatively you can directly call read_csv() as follows, and assign the output into a new variable ‘Hs_entrez_annot’ Hs_entrez_annot &lt;- read_csv(&quot;~/Desktop/WEHI_tidyR_course/data_files/Hs_entrez_annot.csv&quot;) ## ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────────── ## cols( ## entrez_id = col_double(), ## annot_type = col_character(), ## annot_text = col_character() ## ) This message indicates the names and type of data that has been assigned for each column. col_double() denotes a type of numeric data. 6.1.3 read_delim() For the white space-separated file “GO_entrez.txt” (which is far from tidy), it is best to use a more flexible read function called read_delim(). This function allows us to directly specify the delimiter (i.e., the character used to separate the columns). In this case we will use delim=' ' to indicate that the columns are separated by a white space, and assign the output into a new variable ‘GO_entrez’ GO_entrez &lt;- read_delim(&#39;~/Desktop/WEHI_tidyR_course/data_files/GO_entrez.txt&#39;, delim = &#39; &#39;) ## ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────────── ## cols( ## rowname = col_double(), ## go_entrez = col_character() ## ) We can see that the GO_entrez variable contains two columns, ‘rowname’ and ‘go_entrez’. 6.1.4 read_tsv() Lastly we will read the “GO_term_defin.tsv” which is tab-separated (aka ‘tab-delimited’), using read_tsv(). The data will be assigned to a new variable ‘GO_terms’ GO_terms &lt;- read_tsv(&#39;~/Desktop/WEHI_tidyR_course/data_files/GO_term_defin.tsv&#39;) ## ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────────── ## cols( ## GOID = col_character(), ## DEFINITION = col_character(), ## BP = col_character(), ## CC = col_character(), ## MF = col_character() ## ) We see that the new variable contains a dataframe with five columns, all of which are character data. Note that this tsv file could also be read in using read_delim(), specifying the tab delimiter as delim = '\\t'. The .csv file could be read using the same function, with delim = ','. 6.2 Reshaping data Let’s have a look at the newly created dataframes. Starting with entrez_logFC entrez_logFC %&gt;% head() ## # A tibble: 6 x 3 ## entrez_id logFC adj_Pval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 722 3.54 0.00113 ## 2 725 5.62 0.0295 ## 3 1378 3.46 0.0315 ## 4 2302 3.37 0.0486 ## 5 5777 3.93 0.0204 ## 6 55061 2.76 0.0225 This dataframe conforms to the tidy data principals. Each row represents an ‘observation’ (a different entrez gene ID), and each column represents a different measurement type (log fold-change in RNA abundance, and adjusted p. value). Further, each cell contains a single value. This is what we are aiming for with the other data sets. Now to check Hs_entrez_annot Hs_entrez_annot %&gt;% head() ## # A tibble: 6 x 3 ## entrez_id annot_type annot_text ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 21 symbol ABCA3 ## 2 21 gene_name ATP binding cassette subfamily A member 3 ## 3 90 symbol ACVR1 ## 4 90 gene_name activin A receptor type 1 ## 5 91 symbol ACVR1B ## 6 91 gene_name activin A receptor type 1B This is not tidy, because each observation (the entrez_id) is duplicated into 2 rows. The annotation type (‘annot_type’: symbol or gene name) should ideally be individual columns, containing the corresponding annotation_text (‘annot_text’). 6.2.1 pivot_wider() To modify this table so that it conforms to the tidy principals, we need to ‘reshape’ it. We need a function that can convert the labels in the ‘annot_type’ column into two new column names, and assort the data in ‘annot_text’ according to their respective new column names. The function for this job is pivot_wider() thinkr.fr/wp-content/uploads/long_wide.png pivot_wider() requires two commands, both of which are column names in the original table. names_from indicates the column containing the labels which will be come the new column names. values from indicates the column containing the values that will populate the the new columns. To transform the illustrative table above at left (df_long) into the result at right, would require: df_long %&gt;% pivot_wider(names_from = V1, values_from = V2). Note that the ‘shape’ of the dataframe is being converted from longer (more rows) to wider (more columns). In our case, to reshape Hs_entrez_annot, we will use the column names annot_type, and annot_text: Hs_entrez_annot %&gt;% pivot_wider(names_from = annot_type, values_from = annot_text) ## # A tibble: 153 x 3 ## entrez_id symbol gene_name ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 21 ABCA3 ATP binding cassette subfamily A member 3 ## 2 90 ACVR1 activin A receptor type 1 ## 3 91 ACVR1B activin A receptor type 1B ## 4 156 ADRBK1 adrenergic, beta, receptor kinase 1 ## 5 207 AKT1 v-akt murine thymoma viral oncogene homolog 1 ## 6 566 AZU1 azurocidin 1 ## 7 596 BCL2 B-cell CLL/lymphoma 2 ## 8 655 BMP7 bone morphogenetic protein 7 ## 9 722 C4BPA complement component 4 binding protein alpha ## 10 725 C4BPB complement component 4 binding protein beta ## # … with 143 more rows Whereas the original table has 306 rows, the output of pivot_wider() has only 153 rows. This is because the rows are de-duplicated as the new columns are created. Given that the output is in ‘tidy’ format, we can assign it to a new variable ‘Hs_entz_annot_tidy’ Hs_entz_annot_tidy &lt;- Hs_entrez_annot %&gt;% pivot_wider(names_from = annot_type, values_from = annot_text) Note that because we only have two labels in the annot_type column, we are replacing the existing two columns with only two new columns. As such the shape of the output technically isn’t any wider than the input dataframe. However when there are more than two unique labels in the names_from column, the output will be wider than the input. 6.2.2 pivot_longer() The function that complements pivot_wider() is of course pivot_longer(). This function does not create tidy data, because it duplicates rows. However the ‘long format’ output from pivot_longer() is often required for ggplot, where each aesthetic or facet category must be a single column of values; and for left_join(), introduced below. thinkr.fr/wp-content/uploads/wide_long.png pivot_longer() takes three commands, specifying a vector of the names of the columns to convert to labels in long form cols =, a name for the new column containing the labels from 1: names_to =, a name for the new column containing the values corresponding to 1: values_to = Note that pivot_wider(), requires the new column names in quotes. So for the figure above, to convert from the left table (df_wide) to the long table at right, would require: df_wide %&gt;% pivot_longer(cols = c(X2,X3,X4), names_to = 'V1', values_to = 'V2') Let’s see how this can be applied to the GO_terms dataframe GO_terms ## # A tibble: 12 x 5 ## GOID DEFINITION BP CC MF ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 GO:190… Any process that stops, prevents or reduce… negative regulation of vesicl… &lt;NA&gt; &lt;NA&gt; ## 2 GO:004… The directed movement of a vesicle along a… vesicle transport along micro… &lt;NA&gt; &lt;NA&gt; ## 3 GO:001… The phosphorylation of peptidyl-threonine … peptidyl-threonine phosphoryl… &lt;NA&gt; &lt;NA&gt; ## 4 GO:000… Any process that stops, prevents, or reduc… negative regulation of humora… &lt;NA&gt; &lt;NA&gt; ## 5 GO:006… The series of molecular signals initiated … Wnt signaling pathway involve… &lt;NA&gt; &lt;NA&gt; ## 6 GO:000… The chemical reactions and pathways involv… ubiquinone metabolic process &lt;NA&gt; &lt;NA&gt; ## 7 GO:009… The lipid bilayer surrounding a lamellar b… &lt;NA&gt; lamellar … &lt;NA&gt; ## 8 GO:001… The cell cycle process in which genetic ma… female meiosis chromosome seg… &lt;NA&gt; &lt;NA&gt; ## 9 GO:003… Catalysis of the transfer of an amino grou… &lt;NA&gt; &lt;NA&gt; kynurenine amin… ## 10 GO:190… Any process that activates or increases th… positive regulation of protei… &lt;NA&gt; &lt;NA&gt; ## 11 GO:001… The chemical reactions and pathways result… fucose catabolic process &lt;NA&gt; &lt;NA&gt; ## 12 GO:004… Catalysis of the reaction: RS-CH2-CH(NH3+)… &lt;NA&gt; &lt;NA&gt; cysteine-S-conj… The BP, CC and MF columns relate to ‘Biological Process’, ‘Cellular Component’ and ‘Molecular Function’ ontologies within the Gene Ontology framework. We can see there are many NA values in these columns, as each GOID relates to a single type of ontology. That is, if there is text in BP, then CC and MF will be NA values. If we consider the text in this table as individual ‘values’ then the table is technically tidy, but the information is sparsely populated throughout. To eliminate the NA values we first use pivot_longer(), with the aim of converting to long format those columns containing ontology descriptions: BP,CC, and MF. The new column for labels will be ‘ONTOLOGY’, and the new column containing the associated text will be ‘DESCRIPTION’ GO_terms %&gt;% pivot_longer(cols = c(BP,CC,MF), names_to = &#39;ONTOLOGY&#39;, values_to = &#39;DESCRIPTION&#39;) ## # A tibble: 36 x 4 ## GOID DEFINITION ONTOLOGY DESCRIPTION ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 GO:1901… Any process that stops, prevents or reduces the f… BP negative regulation of vesicle transport… ## 2 GO:1901… Any process that stops, prevents or reduces the f… CC &lt;NA&gt; ## 3 GO:1901… Any process that stops, prevents or reduces the f… MF &lt;NA&gt; ## 4 GO:0047… The directed movement of a vesicle along a microt… BP vesicle transport along microtubule ## 5 GO:0047… The directed movement of a vesicle along a microt… CC &lt;NA&gt; ## 6 GO:0047… The directed movement of a vesicle along a microt… MF &lt;NA&gt; ## 7 GO:0018… The phosphorylation of peptidyl-threonine to form… BP peptidyl-threonine phosphorylation ## 8 GO:0018… The phosphorylation of peptidyl-threonine to form… CC &lt;NA&gt; ## 9 GO:0018… The phosphorylation of peptidyl-threonine to form… MF &lt;NA&gt; ## 10 GO:0002… Any process that stops, prevents, or reduces the … BP negative regulation of humoral immune re… ## # … with 26 more rows Now the data is in long form, with the GOID and DEFINITION columns duplicated. All of the NA values are now in a single column (DESCRIPTION). We can easily filter out these NA values, and assign the new dataframe to a variable ‘GO_terms_long’ GO_terms_long &lt;- GO_terms %&gt;% pivot_longer(cols = c(BP, CC, MF), names_to = &#39;ONTOLOGY&#39;, values_to = &#39;DESCRIPTION&#39;) %&gt;% filter(!is.na(DESCRIPTION)) Importantly, in cases where there are 10s of column names to convert to long format, it is simpler to use cols = to specify those columns that we don’t want to convert, which are usually the left-most columns. This is done with the - symbol we previously used with select(), and for negative vector sub-setting. To achieve the same result as above using this approach: GO_terms_long &lt;- GO_terms %&gt;% pivot_longer(cols = -c(GOID, DEFINITION), names_to = &#39;ONTOLOGY&#39;, values_to = &#39;DESCRIPTION&#39;) %&gt;% filter(!is.na(DESCRIPTION)) cols can also take the other helpers used with select(), such as starts_with(), contains() etc. 6.3 Separating and uniting columns So far we have reshaped data where the input conforms to the third principal of ‘tidiness’: each cell contains a single value. When this is not the case, we may need to split values into several columns, using separate(); or combine values into a single column using unite(). GO_entrez is certainly the messiest of the datasets we have been provided. Let’s take look: GO_entrez %&gt;% head() ## # A tibble: 6 x 2 ## rowname go_entrez ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 GO_0002924_722,725,1378,2302,5777,55061 ## 2 2 GO_0006743_3156,4704,10229,23590,27235,29914,51004,51117,51805,56997,57017,57107,84274 ## 3 3 GO_0016321_4292,5347,728637 ## 4 4 GO_0018107_90,91,156,207,566,596,655,790,801,805,808,817,983,1020,1111,1116,1195,1859,1950,2011,2039,2… ## 5 5 GO_0019317_2523,2524,2526,2527,2528,2529,2530,10690,84750 ## 6 6 GO_0036137_883,2806,51166,56267 The dataframe has two columns: ‘rownames’ which is a meaningless sequence of integers, and ‘go_entrez’ which appears to contain GO IDs interspersed with underscores, and a long string of comma-separated entrez IDs. We will need to make several changes to produce a long-format table of GO terms and corresponding entrez IDs in consecutive rows. First, we should separate the go_entrez column into three, containing the ‘GO’ prefix, the code, and the string of entrez IDs. 6.3.1 separate() The tidyr separate() function takes a column name as the first command, and separates it into a number of new columns (a vector of names of our choosing, in quotes), according to a particular character delimiter, the ‘separator’ or ‘sep’. The sep = command has the same role as delim = in read_delim() above. Let’s split the go_entrez column into three new columns named ‘prefix’,‘code_only’ and ‘entrez_multi’, according to the underscore _ character: GO_entrez %&gt;% separate(go_entrez, into = c(&#39;prefix&#39;,&#39;code_only&#39;,&#39;entrez_multi&#39;), sep = &#39;_&#39;) ## # A tibble: 11 x 4 ## rowname prefix code_only entrez_multi ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 GO 0002924 722,725,1378,2302,5777,55061 ## 2 2 GO 0006743 3156,4704,10229,23590,27235,29914,51004,51117,51805,56997,57017,57107,84274 ## 3 3 GO 0016321 4292,5347,728637 ## 4 4 GO 0018107 90,91,156,207,566,596,655,790,801,805,808,817,983,1020,1111,1116,1195,1859,1950,2011… ## 5 5 GO 0019317 2523,2524,2526,2527,2528,2529,2530,10690,84750 ## 6 6 GO 0036137 883,2806,51166,56267 ## 7 7 GO 0047496 1176,1201,1780,2647,3064,3799,5048,5590,5861,6845,8120,8546,8943,9001,9371,10125,102… ## 8 8 GO 0061289 2625,55366 ## 9 9 GO 0097232 21,27074 ## 10 10 GO 1901609 254263 ## 11 11 GO 1903638 9141 Note that the code_only column contains only integers but remains encoded as ‘character data’. Its possible to allow R to guess the data types for newly created columns by including convert = TRUE at the end of the above command. Here however we want to preserve the leading 0s in code_only which would be dropped if this column was converted to the numeric data type. Let’s store the output of separate() as a new variable named ‘GO_entrez_sep’ GO_entrez_sep &lt;- GO_entrez %&gt;% separate(go_entrez, into = c(&#39;prefix&#39;,&#39;code_only&#39;,&#39;entrez_multi&#39;), sep = &#39;_&#39;) Next we have to deal with the long string of entrez IDs in the ‘entrez_multi’ column. This is particularly tricky as there are uneven numbers of entrez IDs associated with each GO term. This column violates the tidy data principle of one value per cell. Using a separate() function will run in to problems when columns are highly uneven, and the maximum number of values is unknown. 6.3.2 separate_rows() Hopefully you will rarely come across a dataset this messy, but when you do, separate_rows() will be a lifesaver. A previous version of this book introduced str_split() and unnest() which were very involved, and have been superseded by separate_rows() to the relief of R users and instructors alike. separate_rows() creates a new row for each value in an ‘untidy’ column like entrez_multi. Each individual entrez ID will be inserted into its own row, and the data in other columns will be duplicated in each new row. In this way, separate_rows() essentially performs a pivot_longer() function in order to tidy all of the previously combined, and unusable data. This function requires the column to be separated and converted into long-format, as well as the value separator (comma, in this case). GO_entrez_sep %&gt;% separate_rows(entrez_multi , sep=&#39;,&#39;) ## # A tibble: 155 x 4 ## rowname prefix code_only entrez_multi ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 GO 0002924 722 ## 2 1 GO 0002924 725 ## 3 1 GO 0002924 1378 ## 4 1 GO 0002924 2302 ## 5 1 GO 0002924 5777 ## 6 1 GO 0002924 55061 ## 7 2 GO 0006743 3156 ## 8 2 GO 0006743 4704 ## 9 2 GO 0006743 10229 ## 10 2 GO 0006743 23590 ## # … with 145 more rows We can see that e.g. the six genes (entrez IDs) associated with the GO code 0002924 each now occupy their own row. The data is tidy, in long format. 6.3.3 rename() Given that the entrez_multi column no longer contains multiple entrez IDs per row, we can rename it using the rename() function. It simply takes the form ‘new column name’ = ‘existing name’: GO_entrez_sep %&gt;% separate_rows(entrez_multi, sep = &quot;,&quot;) %&gt;% rename(entrez_id = entrez_multi) ## # A tibble: 155 x 4 ## rowname prefix code_only entrez_id ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 GO 0002924 722 ## 2 1 GO 0002924 725 ## 3 1 GO 0002924 1378 ## 4 1 GO 0002924 2302 ## 5 1 GO 0002924 5777 ## 6 1 GO 0002924 55061 ## 7 2 GO 0006743 3156 ## 8 2 GO 0006743 4704 ## 9 2 GO 0006743 10229 ## 10 2 GO 0006743 23590 ## # … with 145 more rows We can write the results of this chain of commands into a new variable ‘GO_entrez_sep_long’ GO_entrez_sep_long &lt;- GO_entrez_sep %&gt;% separate_rows(entrez_multi,sep=&quot;,&quot;) %&gt;% rename(entrez_id = entrez_multi) 6.3.4 unite() The final step is to combine the GO prefix (‘GO’) and the code_only columns to produce a GO ID in the same form as that in the GOID column of GO_terms_long (created above). To check the desired output: GO_terms_long %&gt;% select(GOID) ## # A tibble: 12 x 1 ## GOID ## &lt;chr&gt; ## 1 GO:1901609 ## 2 GO:0047496 ## 3 GO:0018107 ## 4 GO:0002924 ## 5 GO:0061289 ## 6 GO:0006743 ## 7 GO:0097232 ## 8 GO:0016321 ## 9 GO:0036137 ## 10 GO:1903638 ## 11 GO:0019317 ## 12 GO:0047804 The unite() function is the complement of separate(), and requires two arguments: a name for the new column that will contain the united values, and a vector of the names of the columns to unite. We can optionally provide a separator (sep =) to insert between the combined values. If we don’t add a command here the values will be separated by underscores _. In this case we want to insert a colon : to reproduce the desired GOID GO_entrez_sep_long %&gt;% unite(GOID, c(prefix, code_only), sep=&quot;:&quot;) ## # A tibble: 155 x 3 ## rowname GOID entrez_id ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 GO:0002924 722 ## 2 1 GO:0002924 725 ## 3 1 GO:0002924 1378 ## 4 1 GO:0002924 2302 ## 5 1 GO:0002924 5777 ## 6 1 GO:0002924 55061 ## 7 2 GO:0006743 3156 ## 8 2 GO:0006743 4704 ## 9 2 GO:0006743 10229 ## 10 2 GO:0006743 23590 ## # … with 145 more rows Now we can drop the meaningless rowname column, store the result as “GO_entrez_long”, and we’re finally done with GO_entrez! GO_entrez_long &lt;- GO_entrez_sep_long %&gt;% unite(GOID, c(prefix, code_only), sep=&quot;:&quot;) %&gt;% select(-rowname) 6.4 Removing variables In the process of tidying up the data we created several variables in intermediates states of completeness. We can now remove these variables together with the original untidy input data, using the rm() function. Happily because all of our commands are saved in a text file (and backed up!!) we can reproduce these variables later on if required. rm(Hs_entrez_annot) rm(GO_terms) rm(GO_entrez) rm(GO_entrez_sep) rm(GO_entrez_sep_long) 6.5 Joining dataframes Now that we have converted the three untidy input datasets into tidy format (Hs_entz_annot_tidy), or long format (GO_entrez_long, GO_terms_long) we can begin joining them together into a single dataframe from which to plot the fold-change per gene, coloured by GO term. 6.5.1 left_join() Joining two or more different datasets can be a very tricky task in standard spread-sheeting programs, but is vastly simplified in the tidyverse. The main requirement is to have a ‘joint key’, that is, a column in both dataframes that contains at least one identical value. left_join() is the workhorse of the tidy R joining functions, so called because the first dataframe that is specified (in code from left to right) appears in the left-most columns of the resulting dataframe. In the image below, the dataframe ‘b’ is being joined to ‘a’ using left_join(), and the ‘joint key’ is x1. Note that the x1 column contains two identical values (A and B), but C is unique to ‘a’ and D is unique to ‘b’. The output of left_join(), will contain the entire left-side dataframe (‘a’), and the additional columns from ‘b’ populated with values for all rows where the joint key is matching. NA will appear in cells for which there is no match in ‘b’. The other important thing about left_join() is that any rows where the joint key is duplicated in the right-side dataframe, will also be duplicated in the left-side. For example, if ‘b’ contained the rows ‘B’ ‘F’ ‘B’ ‘T’ then the result would include the rows ‘B’ ‘2’ ‘F’ ‘B’ ‘2’ ‘T’ Our first task is to join the the entrez_logFC results table with the gene annotations in Hs_entz_annot_tidy. We will use the joint key ‘entrez_id’ (outlined in black). Consistent with the previous sections, we will use the pipe %&gt;% to ‘send’ the left-side dataframe (entrez_logFC) into a left_join() where we specify the right-side dataframe. We give the column name of the joint key, in quotes, in the by = command. entrez_logFC %&gt;% left_join(Hs_entz_annot_tidy, by = &#39;entrez_id&#39;) ## # A tibble: 19 x 5 ## entrez_id logFC adj_Pval symbol gene_name ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 722 3.54 0.00113 C4BPA complement component 4 binding protein alpha ## 2 725 5.62 0.0295 C4BPB complement component 4 binding protein beta ## 3 1378 3.46 0.0315 CR1 complement component 3b/4b receptor 1 (Knops blood group) ## 4 2302 3.37 0.0486 FOXJ1 forkhead box J1 ## 5 5777 3.93 0.0204 PTPN6 protein tyrosine phosphatase, non-receptor type 6 ## 6 55061 2.76 0.0225 SUSD4 sushi domain containing 4 ## 7 2523 -1.53 0.00091 FUT1 fucosyltransferase 1 (H blood group) ## 8 2524 -1.38 0.0434 FUT2 fucosyltransferase 2 ## 9 2526 -1.46 0.0268 FUT4 fucosyltransferase 4 ## 10 2527 -0.930 0.00605 FUT5 fucosyltransferase 5 ## 11 2528 -2.91 0.0494 FUT6 fucosyltransferase 6 ## 12 2529 -0.767 0.0185 FUT7 fucosyltransferase 7 (alpha (1,3) fucosyltransferase) ## 13 2530 -0.705 0.0213 FUT8 fucosyltransferase 8 (alpha (1,6) fucosyltransferase) ## 14 10690 -1.32 0.0396 FUT9 fucosyltransferase 9 (alpha (1,3) fucosyltransferase) ## 15 84750 -0.756 0.00960 FUT10 fucosyltransferase 10 (alpha (1,3) fucosyltransferase) ## 16 883 9.95 0.0483 CCBL1 cysteine conjugate-beta lyase, cytoplasmic ## 17 2806 4.26 0.0179 GOT2 glutamic-oxaloacetic transaminase 2 ## 18 51166 4.1 0.0417 AADAT aminoadipate aminotransferase ## 19 56267 3.73 0.0406 CCBL2 cysteine conjugate-beta lyase 2 The result contains the symbols and gene_names columns from Hs_entz_annot_tidy, appended to the entire entrez_logFC dataframe. We will store this result in a new variable ‘entrez_logFC_annot’ entrez_logFC_annot &lt;- entrez_logFC %&gt;% left_join(Hs_entz_annot_tidy, by = &#39;entrez_id&#39;) Let’s try the second of three left_join()s required to complete the data set. We will use the same code to join entrez_logFC_annot and GO_entrez_long, also using ‘entrez_id’ as the joint key. entrez_logFC_annot %&gt;% left_join(GO_entrez_long, by = &#39;entrez_id&#39;) ## Error: Can&#39;t join on `x$entrez_id` x `y$entrez_id` because of incompatible types. ## ℹ `x$entrez_id` is of type &lt;double&gt;&gt;. ## ℹ `y$entrez_id` is of type &lt;character&gt;&gt;. Okay that didn’t work 😬 It looks like somewhere along the line the entrez_id in GO_entrez_long was converted from numeric data into character data. The joint key has to contain at least one identical value, down to the data type. To remedy this we will use mutate() to convert the entrez_id column in GO_entrez_long into numeric data, and overwrite the variable. GO_entrez_long &lt;- GO_entrez_long %&gt;% mutate(entrez_id = as.numeric(entrez_id)) ! Always be careful when overwriting variables. If you make a mistake it can produce incorrect results downstream. Now let’s try the left_join() using the identical data type for the joint key. entrez_logFC_annot %&gt;% left_join(GO_entrez_long, by = &#39;entrez_id&#39;) ## # A tibble: 19 x 6 ## entrez_id logFC adj_Pval symbol gene_name GOID ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 722 3.54 0.00113 C4BPA complement component 4 binding protein alpha GO:0002924 ## 2 725 5.62 0.0295 C4BPB complement component 4 binding protein beta GO:0002924 ## 3 1378 3.46 0.0315 CR1 complement component 3b/4b receptor 1 (Knops blood group) GO:0002924 ## 4 2302 3.37 0.0486 FOXJ1 forkhead box J1 GO:0002924 ## 5 5777 3.93 0.0204 PTPN6 protein tyrosine phosphatase, non-receptor type 6 GO:0002924 ## 6 55061 2.76 0.0225 SUSD4 sushi domain containing 4 GO:0002924 ## 7 2523 -1.53 0.00091 FUT1 fucosyltransferase 1 (H blood group) GO:0019317 ## 8 2524 -1.38 0.0434 FUT2 fucosyltransferase 2 GO:0019317 ## 9 2526 -1.46 0.0268 FUT4 fucosyltransferase 4 GO:0019317 ## 10 2527 -0.930 0.00605 FUT5 fucosyltransferase 5 GO:0019317 ## 11 2528 -2.91 0.0494 FUT6 fucosyltransferase 6 GO:0019317 ## 12 2529 -0.767 0.0185 FUT7 fucosyltransferase 7 (alpha (1,3) fucosyltransferase) GO:0019317 ## 13 2530 -0.705 0.0213 FUT8 fucosyltransferase 8 (alpha (1,6) fucosyltransferase) GO:0019317 ## 14 10690 -1.32 0.0396 FUT9 fucosyltransferase 9 (alpha (1,3) fucosyltransferase) GO:0019317 ## 15 84750 -0.756 0.00960 FUT10 fucosyltransferase 10 (alpha (1,3) fucosyltransferase) GO:0019317 ## 16 883 9.95 0.0483 CCBL1 cysteine conjugate-beta lyase, cytoplasmic GO:0036137 ## 17 2806 4.26 0.0179 GOT2 glutamic-oxaloacetic transaminase 2 GO:0036137 ## 18 51166 4.1 0.0417 AADAT aminoadipate aminotransferase GO:0036137 ## 19 56267 3.73 0.0406 CCBL2 cysteine conjugate-beta lyase 2 GO:0036137 Now we have a GO ID column, the gene annotations and the original entrez_logFC data. Let’s store the result of left_join() as a variable ‘entrez_logFC_GO’ entrez_logFC_GO &lt;- entrez_logFC_annot %&gt;% left_join(GO_entrez_long, by = &#39;entrez_id&#39;) Finally, we will create a variable ‘complete_table’ by joining in the GO term descriptions in GO_terms_long. This time, the joint key will be the ‘GOID’ column complete_table &lt;- entrez_logFC_GO %&gt;% left_join(GO_terms_long, by = &#39;GOID&#39;) 6.6 Plotting challenge With the input data tidied and joined we have all of the information required to make a nice plot illustrating the change in gene expression for genes belonging to different Gene Ontolgies. Your colleague has sketched out an idea for a plot. Can you now produce the plot below using complete_table and ggplot? 6.7 Solution complete_table %&gt;% ggplot(aes(x = logFC, y = symbol)) + geom_col(aes(fill = DESCRIPTION), show.legend = FALSE) + geom_vline(xintercept = 0, lty=2) + facet_wrap(~DESCRIPTION, scales=&#39;free_y&#39;, ncol=1) + xlim(-10,10) 6.8 Summary Once you have finished the  your grateful colleague has bought you, consider the skills you have acquired so far. You can make a wide variety of plots from datasets large and small; subset, transform and summarize data with dplyr, and tidy and join uncooperative datasets. Together these skills allow you to answer interesting questions about your data more quickly, and if necessary, reproduce hours of work instantly and exactly. The final piece of the puzzle is to be able to automate the drudge work of cleaning data and running the same analysis on multiple data sets — the subject of Week 4. "],["week-4-part-1.html", "Week 4. Part 1", " Week 4. Part 1 "],["automating-your-work.html", "7 Automating your work 7.1 Experimental design 7.2 For loops 7.3 paste() 7.4 Catching loop results", " 7 Automating your work Now that we have covered plotting, manipulating and tidying data in R, in this session we will combine those aspects of data analysis with some very basic programming to automate a series of repetitive tasks. In this session we will work with a series of results files from the WEHI drug screening facility, available here. Please save the screening_plates folder into your Desktop folder named WEHI_tidyR_course. Next create and save a new .R file, ‘Week_4_tidyverse.R’ in your Desktop WEHI_tidyR_course folder. 7.1 Experimental design Cells from a cancer cell line are grown in 1536-well plates. Each test well contains a different potential anti-cancer compound. There are also positive and negative control wells in each plate. After 24 hours, a cell viability reagent is added and the luminescence in each well, corresponding to cell viability, is measured. Our task is to identify the screening ‘hits’ in each plate by: a) making a plot displaying cell viability per well, and b) calculating simple statistics to identify significant deviations from control cell viability. 7.2 For loops Before embarking on this task, let’s get familiar with a little function called the ‘for loop’. This is a staple of computer programming in any language, and allows us to perform the same task on any number of input values or datasets, known as ‘looping through inputs’. The for loop in R has a special structure requiring both standard () and curly brackets {}. A vector of values for which the repetitive function is performed, is given within standard brackets. The job to perform on each dataset is given in curly brackets. A single value in the input vector is referred to as i. The value stored in this ‘i’ variable changes as the function ‘loops through’ the vector. Furthermore, the result calculated within the curly brackets must be ‘printed’ out the console using the print() function. Let’s make a very simple for loop to multiply a series of input values by 50. First, we will get the code working for a single input: the number 3. This value, stored in ‘i’, will be multiplied by 50, and the result assigned to a variable. Then the result variable will be printed so that we can see the answer. i &lt;- 3 result &lt;- i * 50 print(result) ## [1] 150 Now let’s create a vector called ‘loop_values’ that contains several values to loop through. loop_values &lt;- c(1,3,5,8,13) Finally we write the for loop for( i in loop_values){ result &lt;- i * 50 print(result)} ## [1] 50 ## [1] 150 ## [1] 250 ## [1] 400 ## [1] 650 Take a look at the value of i in your Environment pane. It now contains 13, not 3. This is because the for loop has run to completion, and so i contains the last value in the loop_values vector. Around 1 minute into this clip Sheldon uses a similar loop function (not strictly a for loop) to identify a mutually agreeable activity to pursue with a new friend, Kripke. He is ‘iterating’ over a set of inputs (Kripke's interests) and calculating {if he wants to participate}. 7.3 paste() OK now before we get sucked into a youtube vortex let’s cover a second function that’s very handy for automating tasks. paste() is used to combine values into a single value, in a similar fashion to unite() from Week 3. paste() is not part of the tidyverse, but is often used to create variable names and values. This function requires two values, separated by a comma. By default the output value will contain a space separating the input values, however users can choose a different separator using the sep = command. To state Kripke’s interests, we can paste two character values together to form a sentence : paste(&#39;Kripke prefers&#39;, &#39;horseriding&#39;) ## [1] &quot;Kripke prefers horseriding&quot; paste() is more useful in the context of a for loop, where it can add context to the results by adding a fixed value (usually text) to a variable. Here we create a vector of Kripke’s interests, and loop through them using paste(), to produce multiple sentences. interests &lt;- c(&#39;horseriding&#39;,&#39;swimming&#39;,&#39;ventriloquism&#39;) for(i in interests){ result &lt;- paste(&#39;Kripke prefers&#39;, i) print(result) } ## [1] &quot;Kripke prefers horseriding&quot; ## [1] &quot;Kripke prefers swimming&quot; ## [1] &quot;Kripke prefers ventriloquism&quot; 7.4 Catching loop results Although not required for this session, readers will eventually want to store the results of a for loop together in a single variable. Beginners can skip down to Part 2, but for completeness, here we will look at two ways to ‘catch’ all results from a for loop. 7.4.1 Catch in vector In order to catch results as a vector, we first need to set up an empty variable. As the loop progresses, this variable should accumulate the values resulting from each step. To create an empty vector, we use the function vector() loop_output_v &lt;- vector() To make it clearer, the result generated by each step of the loop (a single-value vector), is now assigned to a variable named ‘step_result_v’. The trick is to concatenate each step result to the loop output vector, using c(). Crucially, at each step, loop_output_v is being overwritten to contain both itself, and one additional value: the step_result_v. loop_output_v &lt;- vector() for(i in interests){ step_result_v &lt;- paste(&#39;Kripke prefers&#39;, i) #retain the print() command to check that the loop is working print(step_result_v) #overwrite loop_output_v to contain itself and one extra value loop_output_v &lt;- c(loop_output_v, step_result_v) } ## [1] &quot;Kripke prefers horseriding&quot; ## [1] &quot;Kripke prefers swimming&quot; ## [1] &quot;Kripke prefers ventriloquism&quot; We can now check the contents of the output loop_output_v ## [1] &quot;Kripke prefers horseriding&quot; &quot;Kripke prefers swimming&quot; &quot;Kripke prefers ventriloquism&quot; 7.4.2 Catch in data frame Alternatively, its possible to catch the loop output as a data frame. The main differences are that the step_result must be assigned into a dataframe rather than a vector, and we use bind_rows() instead of c(), to add rows to the output. First load the tidyverse: library(tidyverse) Then create an empty data frame: loop_output_df &lt;- data_frame() Now write a loop which includes a step to create a 1x1 dataframe, using the data_frame() function. This dataframe stores step_result_v as a row in the column. The 1 x 1 dataframe is then appended or ‘bound’ to the loop_output_df using bind_rows(). for(i in interests){ #same as above step_result_v &lt;- paste(&#39;Kripke prefers&#39;, i) #make 1 column x 1-row dataframe: # The column name is &#39;sentence&#39; # The row contains the text in step_result_v step_result_df &lt;- data_frame(&#39;sentence&#39; = step_result_v) #check that each step is working print(step_result_df) #overwrite the output dataframe with itself, and the extra row loop_output_df &lt;- bind_rows(loop_output_df, step_result_df) } Readers trying to achieve more complex loop function results with dataframes can check out the map functions in R for Data Science. "],["week-4-part-2.html", "Week 4. Part 2 7.5 Analyse Plate 1 7.6 Plotting the data 7.7 Statistical summary 7.8 Identify hits", " Week 4. Part 2 7.5 Analyse Plate 1 With the skills for automation in hand, we will now analyse the first plate from the screening assay. We aim to identify the screening ‘hits’ using both data visualization and statistics. First we load the tidyverse library and read the raw data (in .csv format) into a variable called ‘screen_plate’ library(tidyverse) screen_plate &lt;- read_csv(&#39;~/Desktop/WEHI_tidyR_course/screening_plates/PLATE1.csv&#39;) We can check the dimensions of the data frame using dim(), and read the first 6 rows using head() screen_plate %&gt;% dim() ## [1] 32 49 screen_plate %&gt;% head() ## # A tibble: 6 x 49 ## ROW C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 C11 C12 C13 C14 C15 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 R1 6174. 187493. 211526 205900 197694 209756 201435 174091 205579 196761 204813 208347 211597 205923 204272 ## 2 R2 6368. 197641. 190814 200780 216758 214997 185684 203572 199878 201356 198175 182754 208372 197970 208768 ## 3 R3 6959. 193279. 215258 197533 217146 191428 200699 198098 184296 194705 186234 192012 203523 169934 208062 ## 4 R4 6106. 185390. 186948 210031 213270 208650 175096 195469 194506 200694 223320 184593 213273 206714 187451 ## 5 R5 5919. 201540. 204239 185185 217024 195054 164089 209650 190217 190350 229037 190626 186747 297238 210835 ## 6 R6 5408. 203746. 220773 197154 204712 166208 194040 176697 218824 199691 194497 201629 190948 186914 196896 ## # … with 33 more variables: C16 &lt;dbl&gt;, C17 &lt;dbl&gt;, C18 &lt;dbl&gt;, C19 &lt;dbl&gt;, C20 &lt;dbl&gt;, C21 &lt;dbl&gt;, C22 &lt;dbl&gt;, ## # C23 &lt;dbl&gt;, C24 &lt;dbl&gt;, C25 &lt;dbl&gt;, C26 &lt;dbl&gt;, C27 &lt;dbl&gt;, C28 &lt;dbl&gt;, C29 &lt;dbl&gt;, C30 &lt;dbl&gt;, C31 &lt;dbl&gt;, ## # C32 &lt;dbl&gt;, C33 &lt;dbl&gt;, C34 &lt;dbl&gt;, C35 &lt;dbl&gt;, C36 &lt;dbl&gt;, C37 &lt;dbl&gt;, C38 &lt;dbl&gt;, C39 &lt;dbl&gt;, C40 &lt;dbl&gt;, ## # C41 &lt;dbl&gt;, C42 &lt;dbl&gt;, C43 &lt;dbl&gt;, C44 &lt;dbl&gt;, C45 &lt;dbl&gt;, C46 &lt;dbl&gt;, C47 &lt;dbl&gt;, C48 &lt;dbl&gt; So we have a 32-row x 49-column data frame, and using head() we can see that all except the first column are numeric data (you should double-check this using the str() command, which reveals the type of data in each column). The column names are designated C1, C2, C3 etc, and row identifier column ROW contains R1, R2, R3 etc. 7.6 Plotting the data Its good practice to look at your entire dataset rather than just relying on statistical summaries. Data visualization will reveal things about your data that basic summary statistics will not. For a nice exposition of this idea, see this dinasaur-related blog post. https://fluotics.com/wp-content/uploads/2018/12/1536-plate-2.jpg Given that the 1536-well plate is a grid, we want to make a plot that retains the 2-dimensional features of the plate, showing the relative location of each well. The ggplot geom_tile() is the best solution for doing this. Let’s grab the example code from the help page ?geom_tile() #Copy and paste the code to make a toy data frame df &lt;- data.frame( x = rep(c(2, 5, 7, 9, 12), 2), y = rep(c(1, 2), each = 5), z = factor(rep(1:5, each = 2)), w = rep(diff(c(0, 4, 6, 8, 10, 14)), 2) ) #Run the 2nd example ggplot(df, aes(x, y, width = w)) + geom_tile(aes(fill = z), colour = &quot;grey50&quot;) For screen_plate, we want the ROW ID of the dataframe represented on the y axis, and the columns along the x axis. The raw luminescence values will be used as the colour fill for each tile (as for column ‘z’ above). Therefore we need a dataframe with only 3 columns: corresponding to the x, y, and fill aesthetics. To achieve this we need to reshape the dataframe. Let’s use pivot_longer() to create a long-format version of the data (“plate_long”). We keep the ROW column as is, and create two new columns: containing the current column IDs (‘COL’), and the respective luminescence values (‘LUMIN’). plate_long &lt;- screen_plate %&gt;% pivot_longer(cols = starts_with(&#39;C&#39;), names_to = &#39;COL&#39;, values_to = &#39;LUMIN&#39;) Now we can make the first plot plate_long %&gt;% ggplot(aes(x=COL,y=ROW)) + geom_tile(aes(fill=LUMIN)) The structure in the data is clear, but the rows and columns are all jumbled. This is because they are currently character data, and would work better as integers (numeric data). 7.6.1 str_remove() helper To convert the ROW and COL data to numeric, its easiest to remove the letters from the data using str_remove(). str_remove() requires first the column name to modify, and the ‘pattern’ (in our case the letter) to remove. This function, and other str_ family functions, are often used inside mutate() to create a new column containing the resulting data. However, they can be used to modify a vector of text values, as you will see later in the extract filenames section. plate_long %&gt;% mutate(ROW_num = str_remove(ROW,&#39;R&#39;)) ## # A tibble: 1,536 x 4 ## ROW COL LUMIN ROW_num ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 R1 C1 6174. 1 ## 2 R1 C2 187493. 1 ## 3 R1 C3 211526 1 ## 4 R1 C4 205900 1 ## 5 R1 C5 197694 1 ## 6 R1 C6 209756 1 ## 7 R1 C7 201435 1 ## 8 R1 C8 174091 1 ## 9 R1 C9 205579 1 ## 10 R1 C10 196761 1 ## # … with 1,526 more rows 7.6.2 as.numeric() helper ROW_num is still character data! We need to run a second mutate with as.numeric() to convert ROW_num into numeric data: plate_long %&gt;% mutate(ROW_num = str_remove(ROW,&#39;R&#39;)) %&gt;% mutate(ROW_num = as.numeric(ROW_num)) ## # A tibble: 1,536 x 4 ## ROW COL LUMIN ROW_num ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 R1 C1 6174. 1 ## 2 R1 C2 187493. 1 ## 3 R1 C3 211526 1 ## 4 R1 C4 205900 1 ## 5 R1 C5 197694 1 ## 6 R1 C6 209756 1 ## 7 R1 C7 201435 1 ## 8 R1 C8 174091 1 ## 9 R1 C9 205579 1 ## 10 R1 C10 196761 1 ## # … with 1,526 more rows We now add two more mutate commands to achieve the same result for the COL IDs, and assign the results to plate_long_num plate_long_num &lt;- plate_long %&gt;% mutate(ROW_num = str_remove(ROW,&#39;R&#39;)) %&gt;% mutate(ROW_num = as.numeric(ROW_num)) %&gt;% mutate(COL_num = str_remove(COL,&#39;C&#39;)) %&gt;% mutate(COL_num = as.numeric(COL_num)) Now let’s run ggplot using the ROW_num and COl_num columns: plate_long_num %&gt;% ggplot(aes(x=COL_num,y=ROW_num)) + geom_tile(aes(fill=LUMIN)) This is looking better. Finally for this plot we can use two scaling commands to a) change the fill colours a colour-blind-friendly palette that accentuates the high and low values: scale_fill_viridis_c(), b) and reverse the y axis to mimic the plate coordinates: scale_y_reverse() plate_long_num %&gt;% ggplot(aes(x=COL_num,y=ROW_num)) + geom_tile(aes(fill=LUMIN)) + scale_fill_viridis_c() + scale_y_reverse() Now please create a new folder within WEHI_tidyR_course/ for the analysis results, called ‘screening_results’. Let’s save the current plot into the new folder using ggsave() ggsave(&#39;~/Desktop/WEHI_tidyR_course/screening_results/plate_tileplot.pdf&#39;, width=6, height=3.5) 7.7 Statistical summary We can now see there are four entire columns of very low luminescence in screen_plate, corresponding to dead cells. These are the positive controls in columns 1,23,25 and 47. There are also four negative control columns (DMSO-treated cells) at positions 2, 24, 26 and 48. These should be happy and healthy. Our task is to identify wells with luminescence values &gt; 4 standard deviations from the mean (defined by negative controls), corresponding to a p value &lt; 0.01. To find these we should first label the columns in the long-format dataframe as ‘test’, ‘posCTRL’ or ‘negCTRL’. Here we use case_when() and the %in% helper to create a column of labels named ‘well_tag’: plate_long_num %&gt;% mutate(well_tag = case_when(COL_num %in% c(1,23,25,47) ~ &#39;posCTRL&#39;, COL_num %in% c(2,24,26,48) ~ &#39;negCTRL&#39;, TRUE ~ &#39;test&#39;)) ## # A tibble: 1,536 x 6 ## ROW COL LUMIN ROW_num COL_num well_tag ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 R1 C1 6174. 1 1 posCTRL ## 2 R1 C2 187493. 1 2 negCTRL ## 3 R1 C3 211526 1 3 test ## 4 R1 C4 205900 1 4 test ## 5 R1 C5 197694 1 5 test ## 6 R1 C6 209756 1 6 test ## 7 R1 C7 201435 1 7 test ## 8 R1 C8 174091 1 8 test ## 9 R1 C9 205579 1 9 test ## 10 R1 C10 196761 1 10 test ## # … with 1,526 more rows Let’s store the new data_frame as plate_tagged, and count the number of each type of well. plate_tagged &lt;- plate_long_num %&gt;% mutate(well_tag = case_when(COL_num %in% c(1,23,25,47) ~ &#39;posCTRL&#39;, COL_num %in% c(2,24,26,48) ~ &#39;negCTRL&#39;, TRUE ~ &#39;test&#39;)) plate_tagged %&gt;% count(well_tag) ## # A tibble: 3 x 2 ## well_tag n ## &lt;chr&gt; &lt;int&gt; ## 1 negCTRL 128 ## 2 posCTRL 128 ## 3 test 1280 Now we calculate the mean and standard deviation for the negative control wells only, and assign this summary to ‘neg_summ’ neg_summ &lt;- plate_tagged %&gt;% filter(well_tag==&#39;negCTRL&#39;) %&gt;% summarize(mean_neg = mean(LUMIN), sd_neg= sd(LUMIN)) 7.7.1 pull() For a single round of analysis, we might copy these statistics directly into an equation. However here we want the entire analysis to be repeatable on different input datasets, and so can’t have any ‘hard-coded’ numeric values. To allow the mean and sd to have different values according to the input data, they have to be stored in variables which are then used in a z-score calculation. We need to extract each into a single-value vector. The pull() function is a handy way to ‘pull’ the values in a dataframe column out into a vector. meanNeg &lt;- neg_summ %&gt;% pull(mean_neg) sdNeg &lt;- neg_summ %&gt;% pull(sd_neg) 7.8 Identify hits Now let’s use the single values calculated for the mean and standard deviation of negative control wells in a mutate() command and calculate the z score for each well plate_tagged %&gt;% filter(well_tag==&#39;test&#39;) %&gt;% mutate(z_score = (LUMIN - meanNeg) / sdNeg) ## # A tibble: 1,280 x 7 ## ROW COL LUMIN ROW_num COL_num well_tag z_score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 R1 C3 211526 1 3 test 1.24 ## 2 R1 C4 205900 1 4 test 0.684 ## 3 R1 C5 197694 1 5 test -0.130 ## 4 R1 C6 209756 1 6 test 1.07 ## 5 R1 C7 201435 1 7 test 0.241 ## 6 R1 C8 174091 1 8 test -2.47 ## 7 R1 C9 205579 1 9 test 0.652 ## 8 R1 C10 196761 1 10 test -0.222 ## 9 R1 C11 204813 1 11 test 0.576 ## 10 R1 C12 208347 1 12 test 0.927 ## # … with 1,270 more rows We can store the result in a data frame ‘plate_zScores’, and make a quick density plot of the z scores to check the distribution (it should be normal and centred on 0) plate_zScores &lt;- plate_tagged %&gt;% filter(well_tag==&#39;test&#39;) %&gt;% mutate(z_score = (LUMIN - meanNeg) / sdNeg) Lastly we will create a results table called ‘hits’ for the wells with z scores &lt; -4. These are the wells where the cells are dead or dying. There may also be wells where cells are growing better than controls (z &gt; 4). We will not consider those wells here. #use &lt; (-4) to avoid typing the assignment operator hits &lt;- plate_zScores %&gt;% filter(z_score &lt; (-4) ) And use write_csv() to save it in the to the screening_results folder: write_csv(hits, path = &#39;~/Desktop/WEHI_tidyR_course/screening_results/plate_hits.csv&#39;) "],["week-4-part-3.html", "Week 4. Part 3 7.9 list.files() 7.10 Extract filenames 7.11 Variable inputs &amp; outputs 7.12 Looping through plates", " Week 4. Part 3 Now that we are happy with the code to analyse and visualize screening plate 1, it’s time to make a few small tweaks to turn the analysis script into a loop. Remember to load the tidyverse package if you are starting in a fresh Rstudio session: library(tidyverse) 7.9 list.files() list.files() is used to check the names of all files in a particular folder. In order to ‘loop through’ all five screening results files, we first need to store the file names in a variable. list.files(&#39;~/Desktop/WEHI_tidyR_course/screening_plates/&#39;) ## [1] &quot;PLATE1.csv&quot; &quot;PLATE2.csv&quot; &quot;PLATE3.csv&quot; &quot;PLATE4.csv&quot; &quot;PLATE5.csv&quot; list.files() returns a vector of character values corresponding to file names. To show only the .csv files, we can use pattern = '.csv'. Let’s assign this vector to a variable ‘plate_files’ plate_files &lt;- list.files(&#39;~/Desktop/WEHI_tidyR_course/screening_plates/&#39;, pattern=&#39;.csv&#39;) 7.10 Extract filenames Downstream we want to write pdf files from ggsave(). Therefore we want to use the file names but not the ‘.csv’ extension. Let’s remove it using str_remove(). The modified values can be assigned to ‘plate_names’ plate_names &lt;- str_remove(plate_files, pattern = &quot;.csv&quot;) 7.11 Variable inputs &amp; outputs After setting up the plate_names vector, it remains to use paste() in place of fixed file names, so that the input and output file names will change as the for loop progresses. Let’s get a test for loop running, to paste ’_test’ after each filename: for(i in plate_names){ result_test &lt;- paste(i, &#39;test&#39;, sep=&quot;_&quot;) print(result_test) } ## [1] &quot;PLATE1_test&quot; ## [1] &quot;PLATE2_test&quot; ## [1] &quot;PLATE3_test&quot; ## [1] &quot;PLATE4_test&quot; ## [1] &quot;PLATE5_test&quot; The inputs to this script that must vary are the raw data file names (PLATEx.csv). The outputs that must vary are the filenames given to the ggsave(), and write_csv() commands. Remember that the input files and output files live in different sub-folders. For convenience these lines are reproduced below (no need to run this code): screen_plate &lt;- read_csv(&#39;~/Desktop/WEHI_tidyR_course/screening_plates/PLATE1.csv&#39;) ggsave(&#39;~/Desktop/WEHI_tidyR_course/screening_results/plate_tileplot.pdf&#39;, width=6, height=3.5) write_csv(hits, path = &#39;~/Desktop/WEHI_tidyR_course/screening_results/plate_hits.csv&#39;) How can we use paste to allow the input and output file names to vary? To avoid overwriting the results files as the loop progresses, as for the input file name, each output file name must be produced by a paste() command that includes the variable ‘i’. We can write a for loop that creates a different input file name, and two respective output file names, for each value (‘i’) in the plate_names vector. The three file names will be stored in variables ‘in_file’, ‘out_plot’ and ‘out_table’. Given that we want filenames without white space, we will set the paste(sep = ) command to \"\", i.e. no space. for(i in plate_names){ in_file &lt;- paste(&quot;~/Desktop/WEHI_tidyR_course/screening_plates/&quot;, i,&#39;.csv&#39;, sep=&quot;&quot;) out_plot &lt;- paste(&quot;~/Desktop/WEHI_tidyR_course/screening_results/&quot;, i,&#39;_tileplot.pdf&#39;, sep=&quot;&quot;) out_table &lt;- paste(&quot;~/Desktop/WEHI_tidyR_course/screening_results/&quot;, i,&#39;_hits.csv&#39;, sep=&quot;&quot;) print (c(in_file, out_plot, out_table)) } ## [1] &quot;~/Desktop/WEHI_tidyR_course/screening_plates/PLATE1.csv&quot; ## [2] &quot;~/Desktop/WEHI_tidyR_course/screening_results/PLATE1_tileplot.pdf&quot; ## [3] &quot;~/Desktop/WEHI_tidyR_course/screening_results/PLATE1_hits.csv&quot; ## [1] &quot;~/Desktop/WEHI_tidyR_course/screening_plates/PLATE2.csv&quot; ## [2] &quot;~/Desktop/WEHI_tidyR_course/screening_results/PLATE2_tileplot.pdf&quot; ## [3] &quot;~/Desktop/WEHI_tidyR_course/screening_results/PLATE2_hits.csv&quot; ## [1] &quot;~/Desktop/WEHI_tidyR_course/screening_plates/PLATE3.csv&quot; ## [2] &quot;~/Desktop/WEHI_tidyR_course/screening_results/PLATE3_tileplot.pdf&quot; ## [3] &quot;~/Desktop/WEHI_tidyR_course/screening_results/PLATE3_hits.csv&quot; ## [1] &quot;~/Desktop/WEHI_tidyR_course/screening_plates/PLATE4.csv&quot; ## [2] &quot;~/Desktop/WEHI_tidyR_course/screening_results/PLATE4_tileplot.pdf&quot; ## [3] &quot;~/Desktop/WEHI_tidyR_course/screening_results/PLATE4_hits.csv&quot; ## [1] &quot;~/Desktop/WEHI_tidyR_course/screening_plates/PLATE5.csv&quot; ## [2] &quot;~/Desktop/WEHI_tidyR_course/screening_results/PLATE5_tileplot.pdf&quot; ## [3] &quot;~/Desktop/WEHI_tidyR_course/screening_results/PLATE5_hits.csv&quot; 7.12 Looping through plates Now it’s simply a matter of ‘wrapping’ the existing analysis code within the curly brackets of the for loop, and replacing the file name code with the in_file, out_plot and out_table variables. Note that the intermediate plots, and the code steps from Part 2 that don’t create new variables, are omitted below. You could create a new .R script called Week_4_analysis_loop.R, copy in the code below and fire away! library(tidyverse) plate_files &lt;- list.files(&#39;~/Desktop/WEHI_tidyR_course/screening_plates/&#39;, pattern=&#39;.csv&#39;) plate_names &lt;- str_remove(plate_files, pattern = &quot;.csv&quot;) for(i in plate_names){ #set up the variable file names in_file &lt;- paste(&quot;~/Desktop/WEHI_tidyR_course/screening_plates/&quot;, i,&#39;.csv&#39;, sep=&quot;&quot;) out_plot &lt;- paste(&quot;~/Desktop/WEHI_tidyR_course/screening_results/&quot;, i,&#39;_tileplot.pdf&#39;, sep=&quot;&quot;) out_table &lt;- paste(&quot;~/Desktop/WEHI_tidyR_course/screening_results/&quot;, i,&#39;_hits.csv&#39;, sep=&quot;&quot;) #analysis code screen_plate &lt;- read_csv(in_file) plate_long &lt;- screen_plate %&gt;% pivot_longer(cols = starts_with(&#39;C&#39;), names_to = &#39;COL&#39;, values_to = &#39;LUMIN&#39;) plate_long_num &lt;- plate_long %&gt;% mutate(ROW_num = str_remove(ROW,&#39;R&#39;)) %&gt;% mutate(ROW_num = as.numeric(ROW_num)) %&gt;% mutate(COL_num = str_remove(COL,&#39;C&#39;)) %&gt;% mutate(COL_num = as.numeric(COL_num)) plate_long_num %&gt;% ggplot(aes(x=COL_num,y=ROW_num)) + geom_tile(aes(fill=LUMIN)) + scale_fill_viridis_c() + scale_y_reverse() #plot output ggsave(out_plot, width=6, height=3.5) plate_tagged &lt;- plate_long_num %&gt;% mutate(well_tag = case_when(COL_num %in% c(1,23,25,47) ~ &#39;posCTRL&#39;, COL_num %in% c(2,24,26,48) ~ &#39;negCTRL&#39;, TRUE ~ &#39;test&#39;)) neg_summ &lt;- plate_tagged %&gt;% filter(well_tag==&#39;negCTRL&#39;) %&gt;% summarize(mean_neg = mean(LUMIN), sd_neg= sd(LUMIN)) meanNeg &lt;- neg_summ %&gt;% pull(mean_neg) sdNeg &lt;- neg_summ %&gt;% pull(sd_neg) plate_zScores &lt;- plate_tagged %&gt;% filter(well_tag==&#39;test&#39;) %&gt;% mutate(z_score = (LUMIN - meanNeg) / sdNeg) hits &lt;- plate_zScores %&gt;% filter(z_score &lt; (-4) | z_score &gt; 4) #table output write_csv(hits, path = out_table) } You just processed 6400 experimental results in a couple of seconds 🎉. You can use the time you would have spent copying sheets and formulas in Excel to check the screening_results folder, and start planning the validation experiments for your potential anti-cancer compounds! "],["factors.html", "Factors", " Factors "],["what-the-factor.html", "8 What the factor? 8.1 Factors in plots 8.2 Summary", " 8 What the factor? Sooner or later in your R learning journey you will come face to face with factors. Factors are something I prefer to shield beginners from, but there’s no avoiding this element of R. Understanding how to handle factors is often the key to in travelling the ‘last mile’ to make your plots exactly the way you want them. Factors can also be extremely important for correctly setting up statistical models, although we will not cover that here. So what are factors? Essentially they are ordered labels for data values. Consider the numbers 1 to 3. In elementary school, grade 1 is lower than grade 3. In the context of a running race however, place 1 is higher/better than place 3. We intuitively use different ‘ordering labels’ in our heads for the same numbers, according to these two contexts. Another example is the flow of seasons throughout the calendar year. In the northern hemisphere the seasons follow Winter &gt; Spring &gt; Summer &gt; Autumn. In the southern hemisphere the seasons flow Summer &gt; Autumn &gt; Winter &gt; Spring. Spring should sit at position 2 in the Canadian context, and position 4 in the Australian context. In R we give ordered labels to data values by creating factors. To see what happens to a column of data when it is converted to a factor, we use the str() command, which stands for ‘data structure’. Let’s load the tidyverse and mutate the number of engine cylinders in the mpg data into factor. library(tidyverse) mpg %&gt;% mutate(cyl_factor = factor(cyl)) ## # A tibble: 234 x 12 ## manufacturer model displ year cyl trans drv cty hwy fl class cyl_factor ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; ## 1 audi a4 1.8 1999 4 auto(l5) f 18 29 p compact 4 ## 2 audi a4 1.8 1999 4 manual(m5) f 21 29 p compact 4 ## 3 audi a4 2 2008 4 manual(m6) f 20 31 p compact 4 ## 4 audi a4 2 2008 4 auto(av) f 21 30 p compact 4 ## 5 audi a4 2.8 1999 6 auto(l5) f 16 26 p compact 6 ## 6 audi a4 2.8 1999 6 manual(m5) f 18 26 p compact 6 ## 7 audi a4 3.1 2008 6 auto(av) f 18 27 p compact 6 ## 8 audi a4 quattro 1.8 1999 4 manual(m5) 4 18 26 p compact 4 ## 9 audi a4 quattro 1.8 1999 4 auto(l5) 4 16 25 p compact 4 ## 10 audi a4 quattro 2 2008 4 manual(m6) 4 20 28 p compact 4 ## # … with 224 more rows Notice that the cyl_factor column now has the factor data type, whereas the original cyl column is integer data. We can get a summary view of the data types in each column (i.e., the ‘structure’ of the data) by piping the code output into str() mpg %&gt;% mutate(cyl_factor = factor(cyl)) %&gt;% str() ## tibble[,12] [234 × 12] (S3: tbl_df/tbl/data.frame) ## $ manufacturer: chr [1:234] &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; ... ## $ model : chr [1:234] &quot;a4&quot; &quot;a4&quot; &quot;a4&quot; &quot;a4&quot; ... ## $ displ : num [1:234] 1.8 1.8 2 2 2.8 2.8 3.1 1.8 1.8 2 ... ## $ year : int [1:234] 1999 1999 2008 2008 1999 1999 2008 1999 1999 2008 ... ## $ cyl : int [1:234] 4 4 4 4 6 6 6 4 4 4 ... ## $ trans : chr [1:234] &quot;auto(l5)&quot; &quot;manual(m5)&quot; &quot;manual(m6)&quot; &quot;auto(av)&quot; ... ## $ drv : chr [1:234] &quot;f&quot; &quot;f&quot; &quot;f&quot; &quot;f&quot; ... ## $ cty : int [1:234] 18 21 20 21 16 18 18 18 16 20 ... ## $ hwy : int [1:234] 29 29 31 30 26 26 27 26 25 28 ... ## $ fl : chr [1:234] &quot;p&quot; &quot;p&quot; &quot;p&quot; &quot;p&quot; ... ## $ class : chr [1:234] &quot;compact&quot; &quot;compact&quot; &quot;compact&quot; &quot;compact&quot; ... ## $ cyl_factor : Factor w/ 4 levels &quot;4&quot;,&quot;5&quot;,&quot;6&quot;,&quot;8&quot;: 1 1 1 1 3 3 3 1 1 1 ... Some more information is revealed about the newly created cyl_factor data. Specifically, it is a factor with 4 levels. The levels indicate the order of the unique values in the factor. For example, level 1 is the ‘4’ cyl category, level 2 is the ‘5’ cyl and so forth. You will also notice the sequence of numbers after the levels: 1111333111. This indicates that the values in each of the first 10 rows are a mix of the level 1 (value = 4) and level 3 (value = 6) factor. Let’s verify this in the first 6 rows using head(). mpg %&gt;% mutate(cyl_factor=factor(cyl)) %&gt;% head() ## # A tibble: 6 x 12 ## manufacturer model displ year cyl trans drv cty hwy fl class cyl_factor ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; ## 1 audi a4 1.8 1999 4 auto(l5) f 18 29 p compact 4 ## 2 audi a4 1.8 1999 4 manual(m5) f 21 29 p compact 4 ## 3 audi a4 2 2008 4 manual(m6) f 20 31 p compact 4 ## 4 audi a4 2 2008 4 auto(av) f 21 30 p compact 4 ## 5 audi a4 2.8 1999 6 auto(l5) f 16 26 p compact 6 ## 6 audi a4 2.8 1999 6 manual(m5) f 18 26 p compact 6 Both the cyl and cyl_factor columns contain 4 4 4 4 6 6. If we first arrange the mpg data frame by cyl, how does the data structure for cyl_factor change? mpg %&gt;% arrange(cyl) %&gt;% mutate(cyl_factor = factor(cyl)) %&gt;% str() ## tibble[,12] [234 × 12] (S3: tbl_df/tbl/data.frame) ## $ manufacturer: chr [1:234] &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; ... ## $ model : chr [1:234] &quot;a4&quot; &quot;a4&quot; &quot;a4&quot; &quot;a4&quot; ... ## $ displ : num [1:234] 1.8 1.8 2 2 1.8 1.8 2 2 2.4 2.4 ... ## $ year : int [1:234] 1999 1999 2008 2008 1999 1999 2008 2008 1999 2008 ... ## $ cyl : int [1:234] 4 4 4 4 4 4 4 4 4 4 ... ## $ trans : chr [1:234] &quot;auto(l5)&quot; &quot;manual(m5)&quot; &quot;manual(m6)&quot; &quot;auto(av)&quot; ... ## $ drv : chr [1:234] &quot;f&quot; &quot;f&quot; &quot;f&quot; &quot;f&quot; ... ## $ cty : int [1:234] 18 21 20 21 18 16 20 19 19 22 ... ## $ hwy : int [1:234] 29 29 31 30 26 25 28 27 27 30 ... ## $ fl : chr [1:234] &quot;p&quot; &quot;p&quot; &quot;p&quot; &quot;p&quot; ... ## $ class : chr [1:234] &quot;compact&quot; &quot;compact&quot; &quot;compact&quot; &quot;compact&quot; ... ## $ cyl_factor : Factor w/ 4 levels &quot;4&quot;,&quot;5&quot;,&quot;6&quot;,&quot;8&quot;: 1 1 1 1 1 1 1 1 1 1 ... The level order is the same, but note that the sequence of numbers for the first 10 rows now only contains the factor level 1 (corresponding to 4). 8.1 Factors in plots The role of factors can be appreciated when making ggplots. In general, controlling the order of appearance of axis values or facets, requires manipulating the factor levels in the input data frame column given to aes(), or facet_wrap( ~ ) respectively. First let’s make a scatter plot of the number of engine cylinders (x axis) vs city mileage (y axis) for each car. Each point is also coloured by the number of cylinders in that car: mpg %&gt;% ggplot(aes(x=cyl,y=cty)) + geom_point(aes(col=cyl)) The colour scale is a dark-light gradient, which is appropriate because in the original mpg data frame, cyl contains numerical data. That is, the ascending number of cylinders are represented as progressively lighter colours. But when the cylinders are converted to factors… mpg %&gt;% mutate(cyl_factor=factor(cyl)) %&gt;% ggplot(aes(x=cyl_factor, y=cty)) + geom_point(aes(col=cyl_factor)) Now the colour scale is divergent, or discrete. This is because when cyl is a factor, the numbers 5,6,7,8 are simply treated as labels. They no longer have numerical meaning. We would see a similar plot if cyl was converted to character data using e.g. cyl_chr = as.character(cyl) To illustrate this difference in data type, try summing the numbers 4 through 8 when encoded as numeric data, and factor data respectively: numeric_vector &lt;- c(4,5,6,7,8) factor_vector &lt;- factor(c(4,5,6,7,8)) sum(numeric_vector) ## [1] 30 sum(factor_vector) ## Error in Summary.factor(structure(1:5, .Label = c(&quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;, : &#39;sum&#39; not meaningful for factors The order of the labels (termed ‘factor levels’) can be controlled using the forcats library which is available in the tidyverse. All of the forcats functions begin with fct_. Here we will reorder the levels of cyl_factor using fct_relevel() and observe the result. This function takes the name of the factor column, followed by the desired order of its unique values (≈ ‘factor levels’). mpg_cyl_relevel &lt;- mpg %&gt;% mutate(cyl_factor=factor(cyl)) %&gt;% mutate(cyl_factor = fct_relevel( cyl_factor, &#39;8&#39;,&#39;6&#39;,&#39;5&#39;,&#39;4&#39;)) mpg_cyl_relevel %&gt;% str() ## tibble[,12] [234 × 12] (S3: tbl_df/tbl/data.frame) ## $ manufacturer: chr [1:234] &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; ... ## $ model : chr [1:234] &quot;a4&quot; &quot;a4&quot; &quot;a4&quot; &quot;a4&quot; ... ## $ displ : num [1:234] 1.8 1.8 2 2 2.8 2.8 3.1 1.8 1.8 2 ... ## $ year : int [1:234] 1999 1999 2008 2008 1999 1999 2008 1999 1999 2008 ... ## $ cyl : int [1:234] 4 4 4 4 6 6 6 4 4 4 ... ## $ trans : chr [1:234] &quot;auto(l5)&quot; &quot;manual(m5)&quot; &quot;manual(m6)&quot; &quot;auto(av)&quot; ... ## $ drv : chr [1:234] &quot;f&quot; &quot;f&quot; &quot;f&quot; &quot;f&quot; ... ## $ cty : int [1:234] 18 21 20 21 16 18 18 18 16 20 ... ## $ hwy : int [1:234] 29 29 31 30 26 26 27 26 25 28 ... ## $ fl : chr [1:234] &quot;p&quot; &quot;p&quot; &quot;p&quot; &quot;p&quot; ... ## $ class : chr [1:234] &quot;compact&quot; &quot;compact&quot; &quot;compact&quot; &quot;compact&quot; ... ## $ cyl_factor : Factor w/ 4 levels &quot;8&quot;,&quot;6&quot;,&quot;5&quot;,&quot;4&quot;: 4 4 4 4 2 2 2 4 4 4 ... Now ‘8’ will be level 1, ‘6’ will be level 2 etc. Importantly, we dont have to type out every unique value in the factor column. Those factor levels which are not specified will follow in a default order (alphabetical for character data; ascending for numerical data). Now we plot the updated cyl_factor on the x axis: mpg_cyl_relevel %&gt;% ggplot(aes(x=cyl_factor, y=cty)) + geom_point(aes(col=cyl_factor)) The numerical order of the x axis has been reversed because ‘8’ is level 1. Similarly, the data for 8 cylinder cars is now coloured red, which is the first of the default 4-colour scheme for ggplot. 8.1.1 Factors and facets Factors are a useful way to control the order of facets as well. Say we want to plot the city vs highway mileage for each car, faceted by class. We want the compact and subcompact cars to appear next to each other in the facet order. We can create a class_factor column, and then assign these two car types to level 1 and 2 as follows: mpg_class_factor &lt;- mpg %&gt;% mutate(class_factor = factor(class)) %&gt;% mutate(class_factor = fct_relevel(class_factor, levels = &#39;compact&#39;, &#39;subcompact&#39;)) mpg_class_factor %&gt;% ggplot(aes(x=cty,y=hwy)) + geom_point(aes(col=class_factor)) + facet_wrap(~class_factor, scales=&#39;free&#39;) The compact and subcompact facets now appear first, whereas they would usually be far apart due to their distance in alphabetical order. 8.1.2 Factors and bar charts A special case where handling factors is particularly important is horizontal bar charts. These have the delightful quirk of inverting the alphabetical or numerical order of the y axis. If a simple reversal of the axis order is what you need, try adding the ggplot command scale_y_discrete(limits=rev). If you need something more bespoke, then changing the factor levels of the data represented on the y axis may be required. To see the problem let’s make a simple horizontal bar chart counting the number of cars per class mpg %&gt;% ggplot(aes(y=class)) + geom_bar() The y order from top to bottom is descending alphabetical followed by the numerical ‘2seater’. Say we want to bring the compact and subcompact classes to the top of the y axis, followed by other the values in numerical, then alphabetical order. This is a two-step problem. The simplest way to go about it is to 1) bring compact and subcompact cars to the front of the factor levels using fct_relevel() as above; then, 2) reverse the levels of the newly created factor levels using fct_rev(). mpg_class_relevel &lt;- mpg %&gt;% mutate(class_factor= factor(class)) %&gt;% mutate(class_factor_relevel = fct_relevel(class_factor,&#39;compact&#39;,&#39;subcompact&#39;)) mpg_class_relevel %&gt;% ggplot(aes(y=class_factor_relevel)) + geom_bar() The (sub-)compact classes now appear at the bottom of the y axis (indicating that they are the first two levels in the factor… I hope you’ve had a coffee recently!). Next we reverse the levels of the factor, to bring our classes of interest to the top: mpg_class_relevel_rev &lt;- mpg_class_relevel %&gt;% mutate(class_factor_relevel_rev = fct_rev(class_factor_relevel)) mpg_class_relevel_rev %&gt;% ggplot(aes(y=class_factor_relevel_rev)) + geom_bar() Done! The last piece of this puzzle is to deal with the colour legend order. mpg_class_relevel_rev %&gt;% ggplot(aes(y=class_factor_relevel_rev)) + geom_bar(aes(fill=class_factor_relevel_rev)) R has helpfully reordered the y axis but not the colour legend. To handle this we will use a quick fix, which is to simply reverse the order of colour legend as part of the ggplot command. Specifically this requires the guides() function, that can modify specific aspects of the plot appearance (independent of the contents of the input data frame). We will use this function to reverse the legend, which displays the values in the fill aesthetic given to geom_bar(). You can read more about guides here. mpg_class_relevel_rev %&gt;% ggplot(aes(y=class_factor_relevel_rev)) + geom_bar(aes(fill=class_factor_relevel_rev)) + guides(fill = guide_legend( reverse=T )) 8.1.3 Reordering gene plots The y axis order of the gene family bar chart that we created in week 3, can be improved using a similar approach. First if complete_table is not currently in your R Environment, re-run the week 3 code to generate this data frame. We left the plot at this stage: complete_table %&gt;% ggplot(aes(x = logFC, y = symbol)) + geom_col(aes(fill = DESCRIPTION), show.legend = FALSE) + geom_vline(xintercept = 0, lty=2) + facet_wrap(~DESCRIPTION, scales=&#39;free_y&#39;, ncol=1) + xlim(-10,10) Note that the FUT genes in particular are not in numerical order on the y axis. To update the order let’s first create a vector of the FUT genes in the desired order. To do this we will take advantage of the paste() function from week 3. Also note there is no FUT3 gene in the data list. FUT_genes &lt;- paste(&#39;FUT&#39;, c(1,2,4:10), sep=&quot;&quot;) Now we can create a new column of gene symbols in factor form, and relevel with the FUT_genes as the first factor levels. Remember that the remaining gene symbols will follow in alphabetical order. complete_table_relvl &lt;- complete_table %&gt;% mutate(sym_fct = factor(symbol)) %&gt;% mutate(sym_fct_relevel = fct_relevel(sym_fct, FUT_genes)) Use str() to check that fct_relevel has worked: complete_table_relvl %&gt;% select(contains(&#39;sym&#39;)) %&gt;% str() ## tibble[,3] [19 × 3] (S3: tbl_df/tbl/data.frame) ## $ symbol : chr [1:19] &quot;C4BPA&quot; &quot;C4BPB&quot; &quot;CR1&quot; &quot;FOXJ1&quot; ... ## $ sym_fct : Factor w/ 19 levels &quot;AADAT&quot;,&quot;C4BPA&quot;,..: 2 3 6 7 18 19 8 10 11 12 ... ## $ sym_fct_relevel: Factor w/ 19 levels &quot;FUT1&quot;,&quot;FUT2&quot;,..: 11 12 15 16 18 19 1 2 3 4 ... So far so good, FUT1 and FUT2 are the first two levels. Lastly we will use fct_rev() to reverse the sym_fct_relevel column which gets around the default inversion of the y axis for bar charts: complete_table_update &lt;- complete_table_relvl %&gt;% mutate(sym_fct_rev = fct_rev(sym_fct_relevel)) Now the gene symbols should appear in a sensible alphabetical and numeric order! As a final touch we also add a sensible label for the y axis. complete_table_update %&gt;% ggplot(aes(x = logFC, y = sym_fct_rev)) + geom_col(aes(fill = DESCRIPTION), show.legend = FALSE) + geom_vline(xintercept = 0, lty=2) + facet_wrap(~DESCRIPTION, scales=&#39;free_y&#39;, ncol=1) + xlim(-10,10) + ylab(&#39;symbol&#39;) 8.2 Summary Handling factors in R can be hard work, but mastering factors will allow you to control nearly every aspect of ggplot, as well as clarifying they way that many base R functions and statistical operations work. This chapter has provided the tools to overcome some common frustrating hurdles in ggplot. You can learn more about the uses and manipulation of factors in R for Data Science. With even a basic understanding of factors under your belt, you are well on your way to mastering R. "],["odds-ends.html", "Odds &amp; Ends", " Odds &amp; Ends TBC "]]
